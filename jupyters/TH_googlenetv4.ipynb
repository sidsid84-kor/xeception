{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRMMLWSJC1rw",
        "outputId": "4b0b36bf-2051-46f1-a4d6-fab14c265b24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cgac/anaconda3/envs/contactlensEB/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from typing import Any\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy\n",
        "import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "from torchmetrics.classification import MultilabelAccuracy, Accuracy\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchsummary import summary\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm8lfnbhC1rx"
      },
      "outputs": [],
      "source": [
        "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
        "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
        "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
        "#image broken check\n",
        "def check_jpeg_eoi(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        f.seek(-2, 2) # 파일의 끝에서 두 바이트 전으로 이동합니다.\n",
        "        return f.read() == b'\\xff\\xd9'\n",
        "\n",
        "\n",
        "def is_image_valid(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path) # 이미지를 열어봅니다.\n",
        "        img.verify() # verify() 메소드는 파일이 손상되었는지 확인합니다.\n",
        "        return True\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        print('Invalid image: ', image_path, '\\n'+ e) # 손상된 이미지에 대한 에러 메시지를 출력합니다.\n",
        "        return False\n",
        "\n",
        "#image validation(exist and broken file)\n",
        "def validate_dataset(df, img_dir):\n",
        "    count = 0\n",
        "    df_bar = tqdm.tqdm(df.itertuples(), desc=\"validating all images\", total=len(df))\n",
        "    for rows in df_bar:\n",
        "        if os.path.isfile(img_dir+'/'+ rows.id):\n",
        "            if is_image_valid(img_dir+'/'+ rows.id) and check_jpeg_eoi(img_dir+'/'+ rows.id):\n",
        "                continue\n",
        "            else:\n",
        "                count += 1\n",
        "                df.drop(df[df['id'] == rows.id].index, inplace=True)\n",
        "        else:\n",
        "            count += 1\n",
        "            df.drop(df[df['id'] == rows.id].index, inplace=True)\n",
        "        print(\"Not founded images (Num) : \",count)\n",
        "    return df\n",
        "\n",
        "#csv에서 데이터 가져옴\n",
        "def get_data_from_csv(csv_path, train_ratio, img_dir, randoms_state=42):\n",
        "    ###### columns example : ['id', 'good', 'b_edge', 'burr', 'borken', 'b_bubble', 'etc', 'no_lens']\n",
        "\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = validate_dataset(df=df,img_dir=img_dir)\n",
        "    train_df , temp_df = train_test_split(df, test_size=1-train_ratio, random_state=randoms_state)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=randoms_state)\n",
        "\n",
        "\n",
        "    # 'good' 열을 데이터 프레임에서 제거 및 클래스 재정렬\n",
        "    cls_list = ['no_lens', 'etc', 'burr', 'borken', 'b_edge', 'b_bubble']\n",
        "    train_df = train_df.drop(columns=['good'])\n",
        "    train_df = train_df[['id'] + cls_list]\n",
        "    val_df = val_df.drop(columns=['good'])\n",
        "    val_df = val_df[['id'] + cls_list]\n",
        "    test_df = test_df.drop(columns=['good'])\n",
        "    test_df = test_df[['id'] + cls_list]\n",
        "\n",
        "\n",
        "    print('num of train_df',len(train_df))\n",
        "    print('num of val_df',len(val_df))\n",
        "    print('num of test_df',len(test_df))\n",
        "\n",
        "    num_cls = len(train_df.columns) - 1  # because, it is multi-label\n",
        "\n",
        "    print('number of class: ', num_cls)\n",
        "    # cls_list = list(train_df.columns)\n",
        "    # cls_list.remove('id')\n",
        "\n",
        "    print(cls_list)\n",
        "\n",
        "    return train_df, val_df, test_df, num_cls, cls_list\n",
        "\n",
        "#데이터셋 클래스 정의\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, image_dir, num_classes, class_list, transforms=None, img_resize = False, img_dsize = (640,640)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.image_ids = dataframe['id'].unique() # 이미지 고유 ID\n",
        "        self.df = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.img_resize = img_resize\n",
        "        self.img_dsize = img_dsize\n",
        "        self.class_list = class_list\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    #데이터 길이 검증\n",
        "    def validate_data_records(self):\n",
        "        for idx, image_id in enumerate(self.image_ids):\n",
        "            records = self.df[self.df['id'] == image_id]\n",
        "            target = np.array(records[self.class_list].values).astype(np.float32)\n",
        "            if target.shape[1] != len(self.class_list):\n",
        "                print(f\"Index {idx} with image_id {image_id} has mismatched target size. Expected {len(self.class_list)}, but got {target.shape[1]}\")\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        # 이미지 index로 아이템 불러오기\n",
        "\n",
        "        image_id = self.image_ids[index]\n",
        "        records = self.df[self.df['id'] == image_id]\n",
        "\n",
        "        image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
        "\n",
        "        # OpenCV가 컬러를 저장하는 방식인 BGR을 RGB로 변환\n",
        "        if self.img_resize:\n",
        "            image = cv2.resize(image, self.img_dsize)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0 # 0 ~ 1로 스케일링\n",
        "\n",
        "        target = np.array(records[self.class_list].values).astype(np.float32)\n",
        "        target = target.reshape(-1)\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.image_ids.shape[0]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "\n",
        "    # Find the maximum target length\n",
        "    max_len = max([len(t) for t in targets])\n",
        "\n",
        "    # Pad each target to the maximum length\n",
        "    targets_padded = [torch.cat([torch.tensor(t), torch.zeros(max_len - len(t))]) for t in targets]\n",
        "\n",
        "    targets = torch.stack(targets_padded, 0)\n",
        "    return images, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwkxaBiiC1ry"
      },
      "outputs": [],
      "source": [
        "#####################기타####################\n",
        "def create_directory(save_path):\n",
        "    i = 1\n",
        "    while True:\n",
        "        dir_name = os.path.join('models/'+save_path+ str(i) +'/')\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "            os.makedirs(dir_name+'/result')\n",
        "            return dir_name\n",
        "            break\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uLPt6crC1ry"
      },
      "outputs": [],
      "source": [
        "\n",
        "####################################### 모델구조정의 ##########################################\n",
        "####################################### 모델구조정의 ##########################################\n",
        "####################################### 모델구조정의 ##########################################\n",
        "class TH_InceptionV4(nn.Module):\n",
        "\n",
        "    def __init__(self, k=192, l=224, m=256, n=384, num_classes=7):\n",
        "        super(TH_InceptionV4, self).__init__()\n",
        "\n",
        "        self.stem = InceptionV4Stem(3)\n",
        "\n",
        "        self.inceptionA1 = InceptionA(384)\n",
        "        self.inceptionA2 = InceptionA(384)\n",
        "        self.inceptionA3 = InceptionA(384)\n",
        "        self.inceptionA4 = InceptionA(384)\n",
        "        self.no_etc_output_linear = nn.Linear(384, 2)\n",
        "\n",
        "        self.reductionA = ReductionA(384, k, l, m, n)\n",
        "\n",
        "        self.inceptionB1 = InceptionB(1024)\n",
        "        self.inceptionB2 = InceptionB(1024)\n",
        "        self.inceptionB3 = InceptionB(1024)\n",
        "        self.inceptionB4 = InceptionB(1024)\n",
        "        self.inceptionB5 = InceptionB(1024)\n",
        "        self.inceptionB6 = InceptionB(1024)\n",
        "        self.inceptionB7 = InceptionB(1024)\n",
        "\n",
        "        self.burr_broken_output_linear = nn.Linear(1024, 2)\n",
        "\n",
        "        self.reductionB = ReductionB(1024)\n",
        "\n",
        "        self.inceptionC1 = InceptionC(1536)\n",
        "        self.inceptionC2 = InceptionC(1536)\n",
        "        self.inceptionC3 = InceptionC(1536)\n",
        "\n",
        "        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(1536, 1)\n",
        "\n",
        "        # Initialize neural network weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        x = self.stem(x)\n",
        "\n",
        "        x1 = self.inceptionA1(x)\n",
        "        x2 = self.inceptionA2(x1)\n",
        "        x3 = self.inceptionA3(x2)\n",
        "        x4 = self.inceptionA4(x3)\n",
        "\n",
        "        #no_lens와 etc 클래스 output\n",
        "        no_etc_output = self.global_average_pooling(x4)\n",
        "        no_etc_output = torch.flatten(no_etc_output, 1)\n",
        "        no_etc_output = self.no_etc_output_linear(no_etc_output)\n",
        "        outputs.append(no_etc_output)\n",
        "\n",
        "        x_redA = self.reductionA(x4)\n",
        "\n",
        "        xB1 = self.inceptionB1(x_redA)\n",
        "        xB2 = self.inceptionB2(xB1)\n",
        "        xB3 = self.inceptionB3(xB2)\n",
        "        xB4 = self.inceptionB4(xB3)\n",
        "        xB5 = self.inceptionB5(xB4)\n",
        "        xB6 = self.inceptionB6(xB5)\n",
        "        xB7 = self.inceptionB7(xB6)\n",
        "\n",
        "        burr_broken_output = self.global_average_pooling(xB7)\n",
        "        burr_broken_output = torch.flatten(burr_broken_output, 1)\n",
        "        burr_broken_output = self.burr_broken_output_linear(burr_broken_output)\n",
        "        outputs.append(burr_broken_output)\n",
        "\n",
        "        #b_edge분기 - broken에서 받음\n",
        "        x_redB = self.reductionB(xB7)\n",
        "\n",
        "        xC1 = self.inceptionC1(x_redB)\n",
        "        xC2 = self.inceptionC2(xC1)\n",
        "        xC3 = self.inceptionC3(xC2)\n",
        "\n",
        "        b_edge_output = self.global_average_pooling(xC3)\n",
        "        b_edge_output = torch.flatten(b_edge_output, 1)\n",
        "        b_edge_output = self.linear(b_edge_output)\n",
        "        outputs.append(b_edge_output)\n",
        "\n",
        "        #b_bubble분기 - 완전히 따로 내려옴\n",
        "        x_redA_2 = self.reductionA(x4)\n",
        "\n",
        "        xB1_2 = self.inceptionB1(x_redA_2)\n",
        "        xB2_2 = self.inceptionB2(xB1_2)\n",
        "        xB3_2 = self.inceptionB3(xB2_2)\n",
        "        xB4_2 = self.inceptionB4(xB3_2)\n",
        "        xB5_2 = self.inceptionB5(xB4_2)\n",
        "        xB6_2 = self.inceptionB6(xB5_2)\n",
        "        xB7_2 = self.inceptionB7(xB6_2)\n",
        "\n",
        "        x_redB_2 = self.reductionB(xB7_2)\n",
        "\n",
        "        xC1_2 = self.inceptionC1(x_redB_2)\n",
        "        xC2_2 = self.inceptionC2(xC1_2)\n",
        "        xC3_2 = self.inceptionC3(xC2_2)\n",
        "\n",
        "        b_bubble_output = self.global_average_pooling(xC3_2)\n",
        "        b_bubble_output = torch.flatten(b_bubble_output, 1)\n",
        "        b_bubble_output = self.linear(b_bubble_output)\n",
        "        outputs.append(b_bubble_output)\n",
        "\n",
        "        final_outputs = torch.cat(outputs, dim=1)\n",
        "        return final_outputs\n",
        "\n",
        "    def _initialize_weights(self) -> None:\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "                stddev = float(module.stddev) if hasattr(module, \"stddev\") else 0.1\n",
        "                torch.nn.init.trunc_normal_(module.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nn.init.constant_(module.weight, 1)\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "        self.relu = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class InceptionV4Stem(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(InceptionV4Stem, self).__init__()\n",
        "        self.conv2d_1a_3x3 = BasicConv2d(in_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
        "\n",
        "        self.conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0))\n",
        "        self.conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "        self.mixed_3a_branch_0 = nn.MaxPool2d((3, 3), (2, 2))\n",
        "        self.mixed_3a_branch_1 = BasicConv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
        "\n",
        "        self.mixed_4a_branch_0 = nn.Sequential(\n",
        "            BasicConv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
        "        )\n",
        "        self.mixed_4a_branch_1 = nn.Sequential(\n",
        "            BasicConv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
        "            BasicConv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
        "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0))\n",
        "        )\n",
        "\n",
        "        self.mixed_5a_branch_0 = BasicConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
        "        self.mixed_5a_branch_1 = nn.MaxPool2d((3, 3), (2, 2))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        out = self.conv2d_1a_3x3(x)\n",
        "        out = self.conv2d_2a_3x3(out)\n",
        "        out = self.conv2d_2b_3x3(out)\n",
        "\n",
        "        mixed_3a_branch_0 = self.mixed_3a_branch_0(out)\n",
        "        mixed_3a_branch_1 = self.mixed_3a_branch_1(out)\n",
        "        mixed_3a_out = torch.cat([mixed_3a_branch_0, mixed_3a_branch_1], 1)\n",
        "\n",
        "        mixed_4a_branch_0 = self.mixed_4a_branch_0(mixed_3a_out)\n",
        "        mixed_4a_branch_1 = self.mixed_4a_branch_1(mixed_3a_out)\n",
        "        mixed_4a_out = torch.cat([mixed_4a_branch_0, mixed_4a_branch_1], 1)\n",
        "\n",
        "        mixed_5a_branch_0 = self.mixed_5a_branch_0(mixed_4a_out)\n",
        "        mixed_5a_branch_1 = self.mixed_5a_branch_1(mixed_4a_out)\n",
        "        mixed_5a_out = torch.cat([mixed_5a_branch_0, mixed_5a_branch_1], 1)\n",
        "\n",
        "        return mixed_5a_out\n",
        "\n",
        "class InceptionV4ResNetStem(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(InceptionV4ResNetStem, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
        "            BasicConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.MaxPool2d((3, 3), (2, 2)),\n",
        "            BasicConv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
        "            nn.MaxPool2d((3, 3), (2, 2)),\n",
        "        )\n",
        "        self.branch_0 = BasicConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.branch_1 = nn.Sequential(\n",
        "            BasicConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
        "        )\n",
        "        self.branch_2 = nn.Sequential(\n",
        "            BasicConv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            BasicConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "        )\n",
        "        self.branch_3 = nn.Sequential(\n",
        "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
        "            BasicConv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        branch_0 = self.branch_0(features)\n",
        "        branch_1 = self.branch_1(features)\n",
        "        branch_2 = self.branch_2(features)\n",
        "        branch_3 = self.branch_3(features)\n",
        "\n",
        "        out = torch.cat([branch_0, branch_1, branch_2, branch_3], 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class InceptionA(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(InceptionA, self).__init__()\n",
        "        self.branch_0 = BasicConv2d(in_channels, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.branch_1 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "        )\n",
        "        self.branch_2 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            BasicConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "        )\n",
        "        self.brance_3 = nn.Sequential(\n",
        "            nn.AvgPool2d((3, 3), (1, 1), (1, 1), count_include_pad=False),\n",
        "            BasicConv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        branch_0 = self.branch_0(x)\n",
        "        branch_1 = self.branch_1(x)\n",
        "        branch_2 = self.branch_2(x)\n",
        "        brance_3 = self.brance_3(x)\n",
        "\n",
        "        out = torch.cat([branch_0, branch_1, branch_2, brance_3], 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ReductionA(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "            k: int,\n",
        "            l: int,\n",
        "            m: int,\n",
        "            n: int,\n",
        "    ) -> None:\n",
        "        super(ReductionA, self).__init__()\n",
        "        self.branch_0 = BasicConv2d(in_channels, n, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
        "        self.branch_1 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, k, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(k, l, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            BasicConv2d(l, m, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
        "        )\n",
        "        self.branch_2 = nn.MaxPool2d((3, 3), (2, 2))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        branch_0 = self.branch_0(x)\n",
        "        branch_1 = self.branch_1(x)\n",
        "        branch_2 = self.branch_2(x)\n",
        "\n",
        "        out = torch.cat([branch_0, branch_1, branch_2], 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class InceptionB(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(InceptionB, self).__init__()\n",
        "        self.branch_0 = BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.branch_1 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
        "            BasicConv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
        "        )\n",
        "        self.branch_2 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
        "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
        "            BasicConv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
        "            BasicConv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
        "        )\n",
        "        self.branch_3 = nn.Sequential(\n",
        "            nn.AvgPool2d((3, 3), (1, 1), (1, 1), count_include_pad=False),\n",
        "            BasicConv2d(in_channels, 128, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        branch_0 = self.branch_0(x)\n",
        "        branch_1 = self.branch_1(x)\n",
        "        branch_2 = self.branch_2(x)\n",
        "        branch_3 = self.branch_3(x)\n",
        "\n",
        "        out = torch.cat([branch_0, branch_1, branch_2, branch_3], 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ReductionB(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(ReductionB, self).__init__()\n",
        "        self.branch_0 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
        "        )\n",
        "        self.branch_1 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
        "            BasicConv2d(256, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
        "            BasicConv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
        "        )\n",
        "        self.branch_2 = nn.MaxPool2d((3, 3), (2, 2))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        branch_0 = self.branch_0(x)\n",
        "        branch_1 = self.branch_1(x)\n",
        "        branch_2 = self.branch_2(x)\n",
        "\n",
        "        out = torch.cat([branch_0, branch_1, branch_2], 1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class InceptionC(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int,\n",
        "    ) -> None:\n",
        "        super(InceptionC, self).__init__()\n",
        "        self.branch_0 = BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "\n",
        "        self.branch_1 = BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.branch_1_1 = BasicConv2d(384, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
        "        self.branch_1_2 = BasicConv2d(384, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch_2 = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
        "            BasicConv2d(384, 448, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            BasicConv2d(448, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n",
        "        )\n",
        "        self.branch_2_1 = BasicConv2d(512, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
        "        self.branch_2_2 = BasicConv2d(512, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
        "\n",
        "        self.branch_3 = nn.Sequential(\n",
        "            nn.AvgPool2d((3, 3), (1, 1), (1, 1)),\n",
        "            BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        branch_0 = self.branch_0(x)\n",
        "        branch_1 = self.branch_1(x)\n",
        "\n",
        "        branch_1_1 = self.branch_1_1(branch_1)\n",
        "        branch_1_2 = self.branch_1_2(branch_1)\n",
        "        x1 = torch.cat([branch_1_1, branch_1_2], 1)\n",
        "\n",
        "        branch_2 = self.branch_2(x)\n",
        "        branch_2_1 = self.branch_2_1(branch_2)\n",
        "        branch_2_2 = self.branch_2_2(branch_2)\n",
        "        x2 = torch.cat([branch_2_1, branch_2_2], 1)\n",
        "\n",
        "        x3 = self.branch_3(x)\n",
        "\n",
        "        out = torch.cat([branch_0, x1, x2, x3], 1)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM2XFzOqC1rz"
      },
      "outputs": [],
      "source": [
        "########################################## 학습 매커니즘 설정 #####################################\n",
        "########################################## 학습 매커니즘 설정 #####################################\n",
        "########################################## 학습 매커니즘 설정 #####################################\n",
        "\n",
        "# get current lr\n",
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "# function to start training\n",
        "def train_val(model, device, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "    metric_cls_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "        current_lr = get_lr(opt)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{num_epochs-1}\")\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric,train_cls_metric = loss_epoch_multi_output(model, device, loss_func, train_dl, sanity_check, opt)\n",
        "\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric.item())\n",
        "\n",
        "        metric_cls_history['train'].append(train_cls_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric,val_cls_metric = loss_epoch_multi_output(model, device, loss_func, val_dl, sanity_check)\n",
        "\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric.item())\n",
        "\n",
        "        metric_cls_history['val'].append(val_cls_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        if isinstance(model, torch.nn.DataParallel):\n",
        "        # model.module is the original model before DataParallel\n",
        "            torch.save(model.module.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
        "        else:\n",
        "            torch.save(model.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
        "\n",
        "        # torch.save(model.module.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print(f'train loss: {train_loss:.6f}, val loss: {val_loss:.6f}, accuracy: {val_metric:.2f},cls_acc : {val_cls_metric}, time: {(time.time()-start_time)/60:.4f} min')\n",
        "        lossdf = pd.DataFrame(loss_history)\n",
        "        accdf = pd.DataFrame(metric_history)\n",
        "        acc_clsdf = pd.DataFrame(metric_cls_history)\n",
        "\n",
        "        lossdf.to_csv(path2weights + 'result/loss.csv')\n",
        "        accdf.to_csv(path2weights + 'result/acc.csv')\n",
        "        acc_clsdf.to_csv(path2weights + 'result/cls_acc.csv')\n",
        "\n",
        "\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history, metric_cls_history\n",
        "\n",
        "def metric_batch_multi_output(output, target, device):\n",
        "    # output: [batch_size, num_classes], target: [batch_size, num_classes]\n",
        "\n",
        "    pred = output.sigmoid() >= 0.5\n",
        "\n",
        "    num_classes = target.shape[1]\n",
        "    mla_ova = MultilabelAccuracy(num_labels=num_classes).to(device=device)\n",
        "    mla = MultilabelAccuracy(num_labels=num_classes, average=None).to(device=device)\n",
        "\n",
        "    class_accuracies = mla(pred, target)\n",
        "    overall_accuracy = mla_ova(pred, target)\n",
        "\n",
        "    return class_accuracies, overall_accuracy\n",
        "\n",
        "\n",
        "def loss_batch_multi_output(loss_func, output, target, device, opt=None):\n",
        "    # output: [batch_size, num_classes], target: [batch_size, num_classes]\n",
        "    loss_b = loss_func(output, target)\n",
        "    class_metric_b , metric_b = metric_batch_multi_output(output, target, device)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b, class_metric_b\n",
        "\n",
        "def loss_epoch_multi_output(model, device, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    running_class_metrics = torch.zeros(dataset_dl.dataset.num_classes).to(device)\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "    num_classes = dataset_dl.dataset.num_classes\n",
        "    b_count = 0\n",
        "    with tqdm.tqdm(dataset_dl, unit=\"batch\") as tepoch:\n",
        "        for xb, yb in tepoch:\n",
        "            b_count+=1\n",
        "            xb = xb.to(device)\n",
        "            yb = yb.to(device)\n",
        "            output = model(xb)\n",
        "\n",
        "            loss_b, metric_b, class_metric_b = loss_batch_multi_output(loss_func, output, yb, device, opt)\n",
        "\n",
        "            running_loss += loss_b\n",
        "\n",
        "            if metric_b is not None:\n",
        "                running_metric += metric_b\n",
        "\n",
        "            if class_metric_b is not None:\n",
        "                running_class_metrics += class_metric_b\n",
        "\n",
        "            if sanity_check is True:\n",
        "                break\n",
        "\n",
        "    loss = running_loss / b_count\n",
        "    metric = running_metric / b_count # 수정된 부분\n",
        "    class_metrics = {f'class_{i+1}': (running_class_metrics[i] / b_count).item() for i in range(num_classes)}\n",
        "    return loss, metric, class_metrics\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except os.OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZnAE40eC1r0",
        "outputId": "f4ebeba4-7804-4aee-bfc6-d468d6fac082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.reset_max_memory_allocated(device=None)\n",
        "torch.cuda.empty_cache()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN587iLwC1r0"
      },
      "outputs": [],
      "source": [
        "############################# 여기는 전체 데이터셋에서 샘플만 추출하는 과정임 #################################\n",
        "\n",
        "# data_df = pd.read_csv('dataset.csv')\n",
        "# data_df.sum()\n",
        "\n",
        "# categories = ['good', 'b_edge', 'burr', 'borken', 'b_bubble', 'etc', 'no_lens']\n",
        "\n",
        "# resampled_dfs = []\n",
        "# used_indices = set()  # 이미 사용된 인덱스를 추적합니다.\n",
        "\n",
        "# for category in categories:\n",
        "#     # 이미 선택된 샘플을 제외한 데이터프레임을 생성합니다.\n",
        "#     available_data = data_df.drop(index=used_indices)\n",
        "\n",
        "#     # 각 카테고리별로 데이터프레임을 필터링합니다.\n",
        "#     category_df = available_data[available_data[category] == 1] # 카테고리별로 적절한 필터링 조건을 적용해야 합니다.\n",
        "\n",
        "#     # 해당 카테고리에서 사용 가능한 샘플 수가 900개를 초과하는지 확인합니다.\n",
        "#     if len(category_df) > 900:\n",
        "#         category_df = category_df.sample(n=400, random_state=42) # 무작위 샘플 선택\n",
        "#         used_indices.update(category_df.index)  # 선택된 인덱스를 사용된 인덱스 집합에 추가합니다.\n",
        "#     else:\n",
        "#         used_indices.update(category_df.index)  # 남은 모든 샘플 사용\n",
        "\n",
        "#     resampled_dfs.append(category_df)\n",
        "\n",
        "# # 모든 카테고리의 데이터프레임을 하나로 병합합니다.\n",
        "# balanced_df = pd.concat(resampled_dfs, ignore_index=True)\n",
        "\n",
        "# # 결과를 확인합니다.\n",
        "# print(balanced_df.sum())\n",
        "\n",
        "# balanced_df.to_csv('TH_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmXAbrW6C1r0",
        "outputId": "84aac722-3e21-41da-d934-c32176bc83b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Device is not using : NVIDIA DGX Display\n",
            "Let's use 5 GPUs!\n"
          ]
        }
      ],
      "source": [
        "model = TH_InceptionV4()\n",
        "\n",
        "################## gpu사용처리 ######################\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.reset_max_memory_allocated(device=None)\n",
        "torch.cuda.empty_cache()\n",
        "num_device = torch.cuda.device_count()\n",
        "print(device)\n",
        "device_idx = []\n",
        "for i in range(num_device):\n",
        "    if torch.cuda.get_device_name(i) == \"NVIDIA DGX Display\":\n",
        "        print(f\"Device is not using : {torch.cuda.get_device_name(i)}\")\n",
        "    else:\n",
        "        device_idx.append(i)\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\",num_device, \"GPUs!\")\n",
        "    if torch.cuda.device_count() > 4: #for GCT\n",
        "        model=model.to('cuda:0')\n",
        "        model = nn.DataParallel(model, device_ids=device_idx)\n",
        "    else:\n",
        "        model = model.to(device=device)\n",
        "        model = nn.DataParallel(model)\n",
        "else:\n",
        "    model = model.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeOWPLk2C1r0"
      },
      "outputs": [],
      "source": [
        "csv_path = 'TH_dataset.csv'\n",
        "img_dir = './data/images2/'\n",
        "train_ratio = 0.6\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 96\n",
        "EPOCH = 200\n",
        "train_name = create_directory('TH_gnet4_')\n",
        "loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkYOv-RuC1r0",
        "outputId": "c6bc4c6a-3e5f-4835-f05f-d6852012833f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "validating all images: 100%|██████████| 2800/2800 [00:00<00:00, 15221.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of train_df 1680\n",
            "num of val_df 560\n",
            "num of test_df 560\n",
            "number of class:  6\n",
            "['no_lens', 'etc', 'burr', 'borken', 'b_edge', 'b_bubble']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df, NUM_CLS, cls_list = get_data_from_csv(csv_path=csv_path,img_dir=img_dir, train_ratio=train_ratio, randoms_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3iTyldjC1r1"
      },
      "outputs": [],
      "source": [
        "transformation = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Resize(IMG_SIZE)\n",
        "])\n",
        "\n",
        "train_set = CustomDataset(train_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list ,img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
        "train_set.transforms = transformation\n",
        "\n",
        "val_set = CustomDataset(val_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list, img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
        "val_set.transforms = transformation\n",
        "\n",
        "test_set = CustomDataset(test_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list, img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
        "test_set.transforms = transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFjgqwAtC1r1"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn9LSHV0C1r1"
      },
      "outputs": [],
      "source": [
        "params_train = {\n",
        "    'num_epochs':EPOCH,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_loader,\n",
        "    'val_dl':val_loader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':train_name,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeoQQC-FC1r1",
        "outputId": "7c5a8d4f-48ba-4d95-cdf4-e7d457b54313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 319, 319]             864\n",
            "       BatchNorm2d-2         [-1, 32, 319, 319]              64\n",
            "              ReLU-3         [-1, 32, 319, 319]               0\n",
            "       BasicConv2d-4         [-1, 32, 319, 319]               0\n",
            "            Conv2d-5         [-1, 32, 317, 317]           9,216\n",
            "       BatchNorm2d-6         [-1, 32, 317, 317]              64\n",
            "              ReLU-7         [-1, 32, 317, 317]               0\n",
            "       BasicConv2d-8         [-1, 32, 317, 317]               0\n",
            "            Conv2d-9         [-1, 64, 317, 317]          18,432\n",
            "      BatchNorm2d-10         [-1, 64, 317, 317]             128\n",
            "             ReLU-11         [-1, 64, 317, 317]               0\n",
            "      BasicConv2d-12         [-1, 64, 317, 317]               0\n",
            "        MaxPool2d-13         [-1, 64, 158, 158]               0\n",
            "           Conv2d-14         [-1, 96, 158, 158]          55,296\n",
            "      BatchNorm2d-15         [-1, 96, 158, 158]             192\n",
            "             ReLU-16         [-1, 96, 158, 158]               0\n",
            "      BasicConv2d-17         [-1, 96, 158, 158]               0\n",
            "           Conv2d-18         [-1, 64, 158, 158]          10,240\n",
            "      BatchNorm2d-19         [-1, 64, 158, 158]             128\n",
            "             ReLU-20         [-1, 64, 158, 158]               0\n",
            "      BasicConv2d-21         [-1, 64, 158, 158]               0\n",
            "           Conv2d-22         [-1, 96, 156, 156]          55,296\n",
            "      BatchNorm2d-23         [-1, 96, 156, 156]             192\n",
            "             ReLU-24         [-1, 96, 156, 156]               0\n",
            "      BasicConv2d-25         [-1, 96, 156, 156]               0\n",
            "           Conv2d-26         [-1, 64, 158, 158]          10,240\n",
            "      BatchNorm2d-27         [-1, 64, 158, 158]             128\n",
            "             ReLU-28         [-1, 64, 158, 158]               0\n",
            "      BasicConv2d-29         [-1, 64, 158, 158]               0\n",
            "           Conv2d-30         [-1, 64, 158, 158]          28,672\n",
            "      BatchNorm2d-31         [-1, 64, 158, 158]             128\n",
            "             ReLU-32         [-1, 64, 158, 158]               0\n",
            "      BasicConv2d-33         [-1, 64, 158, 158]               0\n",
            "           Conv2d-34         [-1, 64, 158, 158]          28,672\n",
            "      BatchNorm2d-35         [-1, 64, 158, 158]             128\n",
            "             ReLU-36         [-1, 64, 158, 158]               0\n",
            "      BasicConv2d-37         [-1, 64, 158, 158]               0\n",
            "           Conv2d-38         [-1, 96, 156, 156]          55,296\n",
            "      BatchNorm2d-39         [-1, 96, 156, 156]             192\n",
            "             ReLU-40         [-1, 96, 156, 156]               0\n",
            "      BasicConv2d-41         [-1, 96, 156, 156]               0\n",
            "           Conv2d-42          [-1, 192, 77, 77]         331,776\n",
            "      BatchNorm2d-43          [-1, 192, 77, 77]             384\n",
            "             ReLU-44          [-1, 192, 77, 77]               0\n",
            "      BasicConv2d-45          [-1, 192, 77, 77]               0\n",
            "        MaxPool2d-46          [-1, 192, 77, 77]               0\n",
            "  InceptionV4Stem-47          [-1, 384, 77, 77]               0\n",
            "           Conv2d-48           [-1, 96, 77, 77]          36,864\n",
            "      BatchNorm2d-49           [-1, 96, 77, 77]             192\n",
            "             ReLU-50           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-51           [-1, 96, 77, 77]               0\n",
            "           Conv2d-52           [-1, 64, 77, 77]          24,576\n",
            "      BatchNorm2d-53           [-1, 64, 77, 77]             128\n",
            "             ReLU-54           [-1, 64, 77, 77]               0\n",
            "      BasicConv2d-55           [-1, 64, 77, 77]               0\n",
            "           Conv2d-56           [-1, 96, 77, 77]          55,296\n",
            "      BatchNorm2d-57           [-1, 96, 77, 77]             192\n",
            "             ReLU-58           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-59           [-1, 96, 77, 77]               0\n",
            "           Conv2d-60           [-1, 64, 77, 77]          24,576\n",
            "      BatchNorm2d-61           [-1, 64, 77, 77]             128\n",
            "             ReLU-62           [-1, 64, 77, 77]               0\n",
            "      BasicConv2d-63           [-1, 64, 77, 77]               0\n",
            "           Conv2d-64           [-1, 96, 77, 77]          55,296\n",
            "      BatchNorm2d-65           [-1, 96, 77, 77]             192\n",
            "             ReLU-66           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-67           [-1, 96, 77, 77]               0\n",
            "           Conv2d-68           [-1, 96, 77, 77]          82,944\n",
            "      BatchNorm2d-69           [-1, 96, 77, 77]             192\n",
            "             ReLU-70           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-71           [-1, 96, 77, 77]               0\n",
            "        AvgPool2d-72          [-1, 384, 77, 77]               0\n",
            "           Conv2d-73           [-1, 96, 77, 77]          36,864\n",
            "      BatchNorm2d-74           [-1, 96, 77, 77]             192\n",
            "             ReLU-75           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-76           [-1, 96, 77, 77]               0\n",
            "       InceptionA-77          [-1, 384, 77, 77]               0\n",
            "           Conv2d-78           [-1, 96, 77, 77]          36,864\n",
            "      BatchNorm2d-79           [-1, 96, 77, 77]             192\n",
            "             ReLU-80           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-81           [-1, 96, 77, 77]               0\n",
            "           Conv2d-82           [-1, 64, 77, 77]          24,576\n",
            "      BatchNorm2d-83           [-1, 64, 77, 77]             128\n",
            "             ReLU-84           [-1, 64, 77, 77]               0\n",
            "      BasicConv2d-85           [-1, 64, 77, 77]               0\n",
            "           Conv2d-86           [-1, 96, 77, 77]          55,296\n",
            "      BatchNorm2d-87           [-1, 96, 77, 77]             192\n",
            "             ReLU-88           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-89           [-1, 96, 77, 77]               0\n",
            "           Conv2d-90           [-1, 64, 77, 77]          24,576\n",
            "      BatchNorm2d-91           [-1, 64, 77, 77]             128\n",
            "             ReLU-92           [-1, 64, 77, 77]               0\n",
            "      BasicConv2d-93           [-1, 64, 77, 77]               0\n",
            "           Conv2d-94           [-1, 96, 77, 77]          55,296\n",
            "      BatchNorm2d-95           [-1, 96, 77, 77]             192\n",
            "             ReLU-96           [-1, 96, 77, 77]               0\n",
            "      BasicConv2d-97           [-1, 96, 77, 77]               0\n",
            "           Conv2d-98           [-1, 96, 77, 77]          82,944\n",
            "      BatchNorm2d-99           [-1, 96, 77, 77]             192\n",
            "            ReLU-100           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-101           [-1, 96, 77, 77]               0\n",
            "       AvgPool2d-102          [-1, 384, 77, 77]               0\n",
            "          Conv2d-103           [-1, 96, 77, 77]          36,864\n",
            "     BatchNorm2d-104           [-1, 96, 77, 77]             192\n",
            "            ReLU-105           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-106           [-1, 96, 77, 77]               0\n",
            "      InceptionA-107          [-1, 384, 77, 77]               0\n",
            "          Conv2d-108           [-1, 96, 77, 77]          36,864\n",
            "     BatchNorm2d-109           [-1, 96, 77, 77]             192\n",
            "            ReLU-110           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-111           [-1, 96, 77, 77]               0\n",
            "          Conv2d-112           [-1, 64, 77, 77]          24,576\n",
            "     BatchNorm2d-113           [-1, 64, 77, 77]             128\n",
            "            ReLU-114           [-1, 64, 77, 77]               0\n",
            "     BasicConv2d-115           [-1, 64, 77, 77]               0\n",
            "          Conv2d-116           [-1, 96, 77, 77]          55,296\n",
            "     BatchNorm2d-117           [-1, 96, 77, 77]             192\n",
            "            ReLU-118           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-119           [-1, 96, 77, 77]               0\n",
            "          Conv2d-120           [-1, 64, 77, 77]          24,576\n",
            "     BatchNorm2d-121           [-1, 64, 77, 77]             128\n",
            "            ReLU-122           [-1, 64, 77, 77]               0\n",
            "     BasicConv2d-123           [-1, 64, 77, 77]               0\n",
            "          Conv2d-124           [-1, 96, 77, 77]          55,296\n",
            "     BatchNorm2d-125           [-1, 96, 77, 77]             192\n",
            "            ReLU-126           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-127           [-1, 96, 77, 77]               0\n",
            "          Conv2d-128           [-1, 96, 77, 77]          82,944\n",
            "     BatchNorm2d-129           [-1, 96, 77, 77]             192\n",
            "            ReLU-130           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-131           [-1, 96, 77, 77]               0\n",
            "       AvgPool2d-132          [-1, 384, 77, 77]               0\n",
            "          Conv2d-133           [-1, 96, 77, 77]          36,864\n",
            "     BatchNorm2d-134           [-1, 96, 77, 77]             192\n",
            "            ReLU-135           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-136           [-1, 96, 77, 77]               0\n",
            "      InceptionA-137          [-1, 384, 77, 77]               0\n",
            "          Conv2d-138           [-1, 96, 77, 77]          36,864\n",
            "     BatchNorm2d-139           [-1, 96, 77, 77]             192\n",
            "            ReLU-140           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-141           [-1, 96, 77, 77]               0\n",
            "          Conv2d-142           [-1, 64, 77, 77]          24,576\n",
            "     BatchNorm2d-143           [-1, 64, 77, 77]             128\n",
            "            ReLU-144           [-1, 64, 77, 77]               0\n",
            "     BasicConv2d-145           [-1, 64, 77, 77]               0\n",
            "          Conv2d-146           [-1, 96, 77, 77]          55,296\n",
            "     BatchNorm2d-147           [-1, 96, 77, 77]             192\n",
            "            ReLU-148           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-149           [-1, 96, 77, 77]               0\n",
            "          Conv2d-150           [-1, 64, 77, 77]          24,576\n",
            "     BatchNorm2d-151           [-1, 64, 77, 77]             128\n",
            "            ReLU-152           [-1, 64, 77, 77]               0\n",
            "     BasicConv2d-153           [-1, 64, 77, 77]               0\n",
            "          Conv2d-154           [-1, 96, 77, 77]          55,296\n",
            "     BatchNorm2d-155           [-1, 96, 77, 77]             192\n",
            "            ReLU-156           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-157           [-1, 96, 77, 77]               0\n",
            "          Conv2d-158           [-1, 96, 77, 77]          82,944\n",
            "     BatchNorm2d-159           [-1, 96, 77, 77]             192\n",
            "            ReLU-160           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-161           [-1, 96, 77, 77]               0\n",
            "       AvgPool2d-162          [-1, 384, 77, 77]               0\n",
            "          Conv2d-163           [-1, 96, 77, 77]          36,864\n",
            "     BatchNorm2d-164           [-1, 96, 77, 77]             192\n",
            "            ReLU-165           [-1, 96, 77, 77]               0\n",
            "     BasicConv2d-166           [-1, 96, 77, 77]               0\n",
            "      InceptionA-167          [-1, 384, 77, 77]               0\n",
            "AdaptiveAvgPool2d-168            [-1, 384, 1, 1]               0\n",
            "          Linear-169                    [-1, 2]             770\n",
            "          Conv2d-170          [-1, 384, 38, 38]       1,327,104\n",
            "     BatchNorm2d-171          [-1, 384, 38, 38]             768\n",
            "            ReLU-172          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-173          [-1, 384, 38, 38]               0\n",
            "          Conv2d-174          [-1, 192, 77, 77]          73,728\n",
            "     BatchNorm2d-175          [-1, 192, 77, 77]             384\n",
            "            ReLU-176          [-1, 192, 77, 77]               0\n",
            "     BasicConv2d-177          [-1, 192, 77, 77]               0\n",
            "          Conv2d-178          [-1, 224, 77, 77]         387,072\n",
            "     BatchNorm2d-179          [-1, 224, 77, 77]             448\n",
            "            ReLU-180          [-1, 224, 77, 77]               0\n",
            "     BasicConv2d-181          [-1, 224, 77, 77]               0\n",
            "          Conv2d-182          [-1, 256, 38, 38]         516,096\n",
            "     BatchNorm2d-183          [-1, 256, 38, 38]             512\n",
            "            ReLU-184          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-185          [-1, 256, 38, 38]               0\n",
            "       MaxPool2d-186          [-1, 384, 38, 38]               0\n",
            "      ReductionA-187         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-188          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-189          [-1, 384, 38, 38]             768\n",
            "            ReLU-190          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-191          [-1, 384, 38, 38]               0\n",
            "          Conv2d-192          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-193          [-1, 192, 38, 38]             384\n",
            "            ReLU-194          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-195          [-1, 192, 38, 38]               0\n",
            "          Conv2d-196          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-197          [-1, 224, 38, 38]             448\n",
            "            ReLU-198          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-199          [-1, 224, 38, 38]               0\n",
            "          Conv2d-200          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-201          [-1, 256, 38, 38]             512\n",
            "            ReLU-202          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-203          [-1, 256, 38, 38]               0\n",
            "          Conv2d-204          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-205          [-1, 192, 38, 38]             384\n",
            "            ReLU-206          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-207          [-1, 192, 38, 38]               0\n",
            "          Conv2d-208          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-209          [-1, 192, 38, 38]             384\n",
            "            ReLU-210          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-211          [-1, 192, 38, 38]               0\n",
            "          Conv2d-212          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-213          [-1, 224, 38, 38]             448\n",
            "            ReLU-214          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-215          [-1, 224, 38, 38]               0\n",
            "          Conv2d-216          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-217          [-1, 224, 38, 38]             448\n",
            "            ReLU-218          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-219          [-1, 224, 38, 38]               0\n",
            "          Conv2d-220          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-221          [-1, 256, 38, 38]             512\n",
            "            ReLU-222          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-223          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-224         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-225          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-226          [-1, 128, 38, 38]             256\n",
            "            ReLU-227          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-228          [-1, 128, 38, 38]               0\n",
            "      InceptionB-229         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-230          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-231          [-1, 384, 38, 38]             768\n",
            "            ReLU-232          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-233          [-1, 384, 38, 38]               0\n",
            "          Conv2d-234          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-235          [-1, 192, 38, 38]             384\n",
            "            ReLU-236          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-237          [-1, 192, 38, 38]               0\n",
            "          Conv2d-238          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-239          [-1, 224, 38, 38]             448\n",
            "            ReLU-240          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-241          [-1, 224, 38, 38]               0\n",
            "          Conv2d-242          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-243          [-1, 256, 38, 38]             512\n",
            "            ReLU-244          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-245          [-1, 256, 38, 38]               0\n",
            "          Conv2d-246          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-247          [-1, 192, 38, 38]             384\n",
            "            ReLU-248          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-249          [-1, 192, 38, 38]               0\n",
            "          Conv2d-250          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-251          [-1, 192, 38, 38]             384\n",
            "            ReLU-252          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-253          [-1, 192, 38, 38]               0\n",
            "          Conv2d-254          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-255          [-1, 224, 38, 38]             448\n",
            "            ReLU-256          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-257          [-1, 224, 38, 38]               0\n",
            "          Conv2d-258          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-259          [-1, 224, 38, 38]             448\n",
            "            ReLU-260          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-261          [-1, 224, 38, 38]               0\n",
            "          Conv2d-262          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-263          [-1, 256, 38, 38]             512\n",
            "            ReLU-264          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-265          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-266         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-267          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-268          [-1, 128, 38, 38]             256\n",
            "            ReLU-269          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-270          [-1, 128, 38, 38]               0\n",
            "      InceptionB-271         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-272          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-273          [-1, 384, 38, 38]             768\n",
            "            ReLU-274          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-275          [-1, 384, 38, 38]               0\n",
            "          Conv2d-276          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-277          [-1, 192, 38, 38]             384\n",
            "            ReLU-278          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-279          [-1, 192, 38, 38]               0\n",
            "          Conv2d-280          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-281          [-1, 224, 38, 38]             448\n",
            "            ReLU-282          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-283          [-1, 224, 38, 38]               0\n",
            "          Conv2d-284          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-285          [-1, 256, 38, 38]             512\n",
            "            ReLU-286          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-287          [-1, 256, 38, 38]               0\n",
            "          Conv2d-288          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-289          [-1, 192, 38, 38]             384\n",
            "            ReLU-290          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-291          [-1, 192, 38, 38]               0\n",
            "          Conv2d-292          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-293          [-1, 192, 38, 38]             384\n",
            "            ReLU-294          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-295          [-1, 192, 38, 38]               0\n",
            "          Conv2d-296          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-297          [-1, 224, 38, 38]             448\n",
            "            ReLU-298          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-299          [-1, 224, 38, 38]               0\n",
            "          Conv2d-300          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-301          [-1, 224, 38, 38]             448\n",
            "            ReLU-302          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-303          [-1, 224, 38, 38]               0\n",
            "          Conv2d-304          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-305          [-1, 256, 38, 38]             512\n",
            "            ReLU-306          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-307          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-308         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-309          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-310          [-1, 128, 38, 38]             256\n",
            "            ReLU-311          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-312          [-1, 128, 38, 38]               0\n",
            "      InceptionB-313         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-314          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-315          [-1, 384, 38, 38]             768\n",
            "            ReLU-316          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-317          [-1, 384, 38, 38]               0\n",
            "          Conv2d-318          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-319          [-1, 192, 38, 38]             384\n",
            "            ReLU-320          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-321          [-1, 192, 38, 38]               0\n",
            "          Conv2d-322          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-323          [-1, 224, 38, 38]             448\n",
            "            ReLU-324          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-325          [-1, 224, 38, 38]               0\n",
            "          Conv2d-326          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-327          [-1, 256, 38, 38]             512\n",
            "            ReLU-328          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-329          [-1, 256, 38, 38]               0\n",
            "          Conv2d-330          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-331          [-1, 192, 38, 38]             384\n",
            "            ReLU-332          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-333          [-1, 192, 38, 38]               0\n",
            "          Conv2d-334          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-335          [-1, 192, 38, 38]             384\n",
            "            ReLU-336          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-337          [-1, 192, 38, 38]               0\n",
            "          Conv2d-338          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-339          [-1, 224, 38, 38]             448\n",
            "            ReLU-340          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-341          [-1, 224, 38, 38]               0\n",
            "          Conv2d-342          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-343          [-1, 224, 38, 38]             448\n",
            "            ReLU-344          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-345          [-1, 224, 38, 38]               0\n",
            "          Conv2d-346          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-347          [-1, 256, 38, 38]             512\n",
            "            ReLU-348          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-349          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-350         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-351          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-352          [-1, 128, 38, 38]             256\n",
            "            ReLU-353          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-354          [-1, 128, 38, 38]               0\n",
            "      InceptionB-355         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-356          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-357          [-1, 384, 38, 38]             768\n",
            "            ReLU-358          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-359          [-1, 384, 38, 38]               0\n",
            "          Conv2d-360          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-361          [-1, 192, 38, 38]             384\n",
            "            ReLU-362          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-363          [-1, 192, 38, 38]               0\n",
            "          Conv2d-364          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-365          [-1, 224, 38, 38]             448\n",
            "            ReLU-366          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-367          [-1, 224, 38, 38]               0\n",
            "          Conv2d-368          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-369          [-1, 256, 38, 38]             512\n",
            "            ReLU-370          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-371          [-1, 256, 38, 38]               0\n",
            "          Conv2d-372          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-373          [-1, 192, 38, 38]             384\n",
            "            ReLU-374          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-375          [-1, 192, 38, 38]               0\n",
            "          Conv2d-376          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-377          [-1, 192, 38, 38]             384\n",
            "            ReLU-378          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-379          [-1, 192, 38, 38]               0\n",
            "          Conv2d-380          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-381          [-1, 224, 38, 38]             448\n",
            "            ReLU-382          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-383          [-1, 224, 38, 38]               0\n",
            "          Conv2d-384          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-385          [-1, 224, 38, 38]             448\n",
            "            ReLU-386          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-387          [-1, 224, 38, 38]               0\n",
            "          Conv2d-388          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-389          [-1, 256, 38, 38]             512\n",
            "            ReLU-390          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-391          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-392         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-393          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-394          [-1, 128, 38, 38]             256\n",
            "            ReLU-395          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-396          [-1, 128, 38, 38]               0\n",
            "      InceptionB-397         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-398          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-399          [-1, 384, 38, 38]             768\n",
            "            ReLU-400          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-401          [-1, 384, 38, 38]               0\n",
            "          Conv2d-402          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-403          [-1, 192, 38, 38]             384\n",
            "            ReLU-404          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-405          [-1, 192, 38, 38]               0\n",
            "          Conv2d-406          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-407          [-1, 224, 38, 38]             448\n",
            "            ReLU-408          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-409          [-1, 224, 38, 38]               0\n",
            "          Conv2d-410          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-411          [-1, 256, 38, 38]             512\n",
            "            ReLU-412          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-413          [-1, 256, 38, 38]               0\n",
            "          Conv2d-414          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-415          [-1, 192, 38, 38]             384\n",
            "            ReLU-416          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-417          [-1, 192, 38, 38]               0\n",
            "          Conv2d-418          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-419          [-1, 192, 38, 38]             384\n",
            "            ReLU-420          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-421          [-1, 192, 38, 38]               0\n",
            "          Conv2d-422          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-423          [-1, 224, 38, 38]             448\n",
            "            ReLU-424          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-425          [-1, 224, 38, 38]               0\n",
            "          Conv2d-426          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-427          [-1, 224, 38, 38]             448\n",
            "            ReLU-428          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-429          [-1, 224, 38, 38]               0\n",
            "          Conv2d-430          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-431          [-1, 256, 38, 38]             512\n",
            "            ReLU-432          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-433          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-434         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-435          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-436          [-1, 128, 38, 38]             256\n",
            "            ReLU-437          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-438          [-1, 128, 38, 38]               0\n",
            "      InceptionB-439         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-440          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-441          [-1, 384, 38, 38]             768\n",
            "            ReLU-442          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-443          [-1, 384, 38, 38]               0\n",
            "          Conv2d-444          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-445          [-1, 192, 38, 38]             384\n",
            "            ReLU-446          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-447          [-1, 192, 38, 38]               0\n",
            "          Conv2d-448          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-449          [-1, 224, 38, 38]             448\n",
            "            ReLU-450          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-451          [-1, 224, 38, 38]               0\n",
            "          Conv2d-452          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-453          [-1, 256, 38, 38]             512\n",
            "            ReLU-454          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-455          [-1, 256, 38, 38]               0\n",
            "          Conv2d-456          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-457          [-1, 192, 38, 38]             384\n",
            "            ReLU-458          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-459          [-1, 192, 38, 38]               0\n",
            "          Conv2d-460          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-461          [-1, 192, 38, 38]             384\n",
            "            ReLU-462          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-463          [-1, 192, 38, 38]               0\n",
            "          Conv2d-464          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-465          [-1, 224, 38, 38]             448\n",
            "            ReLU-466          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-467          [-1, 224, 38, 38]               0\n",
            "          Conv2d-468          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-469          [-1, 224, 38, 38]             448\n",
            "            ReLU-470          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-471          [-1, 224, 38, 38]               0\n",
            "          Conv2d-472          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-473          [-1, 256, 38, 38]             512\n",
            "            ReLU-474          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-475          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-476         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-477          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-478          [-1, 128, 38, 38]             256\n",
            "            ReLU-479          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-480          [-1, 128, 38, 38]               0\n",
            "      InceptionB-481         [-1, 1024, 38, 38]               0\n",
            "AdaptiveAvgPool2d-482           [-1, 1024, 1, 1]               0\n",
            "          Linear-483                    [-1, 2]           2,050\n",
            "          Conv2d-484          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-485          [-1, 192, 38, 38]             384\n",
            "            ReLU-486          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-487          [-1, 192, 38, 38]               0\n",
            "          Conv2d-488          [-1, 192, 18, 18]         331,776\n",
            "     BatchNorm2d-489          [-1, 192, 18, 18]             384\n",
            "            ReLU-490          [-1, 192, 18, 18]               0\n",
            "     BasicConv2d-491          [-1, 192, 18, 18]               0\n",
            "          Conv2d-492          [-1, 256, 38, 38]         262,144\n",
            "     BatchNorm2d-493          [-1, 256, 38, 38]             512\n",
            "            ReLU-494          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-495          [-1, 256, 38, 38]               0\n",
            "          Conv2d-496          [-1, 256, 38, 38]         458,752\n",
            "     BatchNorm2d-497          [-1, 256, 38, 38]             512\n",
            "            ReLU-498          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-499          [-1, 256, 38, 38]               0\n",
            "          Conv2d-500          [-1, 320, 38, 38]         573,440\n",
            "     BatchNorm2d-501          [-1, 320, 38, 38]             640\n",
            "            ReLU-502          [-1, 320, 38, 38]               0\n",
            "     BasicConv2d-503          [-1, 320, 38, 38]               0\n",
            "          Conv2d-504          [-1, 320, 18, 18]         921,600\n",
            "     BatchNorm2d-505          [-1, 320, 18, 18]             640\n",
            "            ReLU-506          [-1, 320, 18, 18]               0\n",
            "     BasicConv2d-507          [-1, 320, 18, 18]               0\n",
            "       MaxPool2d-508         [-1, 1024, 18, 18]               0\n",
            "      ReductionB-509         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-510          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-511          [-1, 256, 18, 18]             512\n",
            "            ReLU-512          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-513          [-1, 256, 18, 18]               0\n",
            "          Conv2d-514          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-515          [-1, 384, 18, 18]             768\n",
            "            ReLU-516          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-517          [-1, 384, 18, 18]               0\n",
            "          Conv2d-518          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-519          [-1, 256, 18, 18]             512\n",
            "            ReLU-520          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-521          [-1, 256, 18, 18]               0\n",
            "          Conv2d-522          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-523          [-1, 256, 18, 18]             512\n",
            "            ReLU-524          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-525          [-1, 256, 18, 18]               0\n",
            "          Conv2d-526          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-527          [-1, 384, 18, 18]             768\n",
            "            ReLU-528          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-529          [-1, 384, 18, 18]               0\n",
            "          Conv2d-530          [-1, 448, 18, 18]         516,096\n",
            "     BatchNorm2d-531          [-1, 448, 18, 18]             896\n",
            "            ReLU-532          [-1, 448, 18, 18]               0\n",
            "     BasicConv2d-533          [-1, 448, 18, 18]               0\n",
            "          Conv2d-534          [-1, 512, 18, 18]         688,128\n",
            "     BatchNorm2d-535          [-1, 512, 18, 18]           1,024\n",
            "            ReLU-536          [-1, 512, 18, 18]               0\n",
            "     BasicConv2d-537          [-1, 512, 18, 18]               0\n",
            "          Conv2d-538          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-539          [-1, 256, 18, 18]             512\n",
            "            ReLU-540          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-541          [-1, 256, 18, 18]               0\n",
            "          Conv2d-542          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-543          [-1, 256, 18, 18]             512\n",
            "            ReLU-544          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-545          [-1, 256, 18, 18]               0\n",
            "       AvgPool2d-546         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-547          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-548          [-1, 256, 18, 18]             512\n",
            "            ReLU-549          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-550          [-1, 256, 18, 18]               0\n",
            "      InceptionC-551         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-552          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-553          [-1, 256, 18, 18]             512\n",
            "            ReLU-554          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-555          [-1, 256, 18, 18]               0\n",
            "          Conv2d-556          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-557          [-1, 384, 18, 18]             768\n",
            "            ReLU-558          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-559          [-1, 384, 18, 18]               0\n",
            "          Conv2d-560          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-561          [-1, 256, 18, 18]             512\n",
            "            ReLU-562          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-563          [-1, 256, 18, 18]               0\n",
            "          Conv2d-564          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-565          [-1, 256, 18, 18]             512\n",
            "            ReLU-566          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-567          [-1, 256, 18, 18]               0\n",
            "          Conv2d-568          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-569          [-1, 384, 18, 18]             768\n",
            "            ReLU-570          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-571          [-1, 384, 18, 18]               0\n",
            "          Conv2d-572          [-1, 448, 18, 18]         516,096\n",
            "     BatchNorm2d-573          [-1, 448, 18, 18]             896\n",
            "            ReLU-574          [-1, 448, 18, 18]               0\n",
            "     BasicConv2d-575          [-1, 448, 18, 18]               0\n",
            "          Conv2d-576          [-1, 512, 18, 18]         688,128\n",
            "     BatchNorm2d-577          [-1, 512, 18, 18]           1,024\n",
            "            ReLU-578          [-1, 512, 18, 18]               0\n",
            "     BasicConv2d-579          [-1, 512, 18, 18]               0\n",
            "          Conv2d-580          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-581          [-1, 256, 18, 18]             512\n",
            "            ReLU-582          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-583          [-1, 256, 18, 18]               0\n",
            "          Conv2d-584          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-585          [-1, 256, 18, 18]             512\n",
            "            ReLU-586          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-587          [-1, 256, 18, 18]               0\n",
            "       AvgPool2d-588         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-589          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-590          [-1, 256, 18, 18]             512\n",
            "            ReLU-591          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-592          [-1, 256, 18, 18]               0\n",
            "      InceptionC-593         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-594          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-595          [-1, 256, 18, 18]             512\n",
            "            ReLU-596          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-597          [-1, 256, 18, 18]               0\n",
            "          Conv2d-598          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-599          [-1, 384, 18, 18]             768\n",
            "            ReLU-600          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-601          [-1, 384, 18, 18]               0\n",
            "          Conv2d-602          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-603          [-1, 256, 18, 18]             512\n",
            "            ReLU-604          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-605          [-1, 256, 18, 18]               0\n",
            "          Conv2d-606          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-607          [-1, 256, 18, 18]             512\n",
            "            ReLU-608          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-609          [-1, 256, 18, 18]               0\n",
            "          Conv2d-610          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-611          [-1, 384, 18, 18]             768\n",
            "            ReLU-612          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-613          [-1, 384, 18, 18]               0\n",
            "          Conv2d-614          [-1, 448, 18, 18]         516,096\n",
            "     BatchNorm2d-615          [-1, 448, 18, 18]             896\n",
            "            ReLU-616          [-1, 448, 18, 18]               0\n",
            "     BasicConv2d-617          [-1, 448, 18, 18]               0\n",
            "          Conv2d-618          [-1, 512, 18, 18]         688,128\n",
            "     BatchNorm2d-619          [-1, 512, 18, 18]           1,024\n",
            "            ReLU-620          [-1, 512, 18, 18]               0\n",
            "     BasicConv2d-621          [-1, 512, 18, 18]               0\n",
            "          Conv2d-622          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-623          [-1, 256, 18, 18]             512\n",
            "            ReLU-624          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-625          [-1, 256, 18, 18]               0\n",
            "          Conv2d-626          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-627          [-1, 256, 18, 18]             512\n",
            "            ReLU-628          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-629          [-1, 256, 18, 18]               0\n",
            "       AvgPool2d-630         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-631          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-632          [-1, 256, 18, 18]             512\n",
            "            ReLU-633          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-634          [-1, 256, 18, 18]               0\n",
            "      InceptionC-635         [-1, 1536, 18, 18]               0\n",
            "AdaptiveAvgPool2d-636           [-1, 1536, 1, 1]               0\n",
            "          Linear-637                    [-1, 1]           1,537\n",
            "          Conv2d-638          [-1, 384, 38, 38]       1,327,104\n",
            "     BatchNorm2d-639          [-1, 384, 38, 38]             768\n",
            "            ReLU-640          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-641          [-1, 384, 38, 38]               0\n",
            "          Conv2d-642          [-1, 192, 77, 77]          73,728\n",
            "     BatchNorm2d-643          [-1, 192, 77, 77]             384\n",
            "            ReLU-644          [-1, 192, 77, 77]               0\n",
            "     BasicConv2d-645          [-1, 192, 77, 77]               0\n",
            "          Conv2d-646          [-1, 224, 77, 77]         387,072\n",
            "     BatchNorm2d-647          [-1, 224, 77, 77]             448\n",
            "            ReLU-648          [-1, 224, 77, 77]               0\n",
            "     BasicConv2d-649          [-1, 224, 77, 77]               0\n",
            "          Conv2d-650          [-1, 256, 38, 38]         516,096\n",
            "     BatchNorm2d-651          [-1, 256, 38, 38]             512\n",
            "            ReLU-652          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-653          [-1, 256, 38, 38]               0\n",
            "       MaxPool2d-654          [-1, 384, 38, 38]               0\n",
            "      ReductionA-655         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-656          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-657          [-1, 384, 38, 38]             768\n",
            "            ReLU-658          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-659          [-1, 384, 38, 38]               0\n",
            "          Conv2d-660          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-661          [-1, 192, 38, 38]             384\n",
            "            ReLU-662          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-663          [-1, 192, 38, 38]               0\n",
            "          Conv2d-664          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-665          [-1, 224, 38, 38]             448\n",
            "            ReLU-666          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-667          [-1, 224, 38, 38]               0\n",
            "          Conv2d-668          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-669          [-1, 256, 38, 38]             512\n",
            "            ReLU-670          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-671          [-1, 256, 38, 38]               0\n",
            "          Conv2d-672          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-673          [-1, 192, 38, 38]             384\n",
            "            ReLU-674          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-675          [-1, 192, 38, 38]               0\n",
            "          Conv2d-676          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-677          [-1, 192, 38, 38]             384\n",
            "            ReLU-678          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-679          [-1, 192, 38, 38]               0\n",
            "          Conv2d-680          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-681          [-1, 224, 38, 38]             448\n",
            "            ReLU-682          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-683          [-1, 224, 38, 38]               0\n",
            "          Conv2d-684          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-685          [-1, 224, 38, 38]             448\n",
            "            ReLU-686          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-687          [-1, 224, 38, 38]               0\n",
            "          Conv2d-688          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-689          [-1, 256, 38, 38]             512\n",
            "            ReLU-690          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-691          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-692         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-693          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-694          [-1, 128, 38, 38]             256\n",
            "            ReLU-695          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-696          [-1, 128, 38, 38]               0\n",
            "      InceptionB-697         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-698          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-699          [-1, 384, 38, 38]             768\n",
            "            ReLU-700          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-701          [-1, 384, 38, 38]               0\n",
            "          Conv2d-702          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-703          [-1, 192, 38, 38]             384\n",
            "            ReLU-704          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-705          [-1, 192, 38, 38]               0\n",
            "          Conv2d-706          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-707          [-1, 224, 38, 38]             448\n",
            "            ReLU-708          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-709          [-1, 224, 38, 38]               0\n",
            "          Conv2d-710          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-711          [-1, 256, 38, 38]             512\n",
            "            ReLU-712          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-713          [-1, 256, 38, 38]               0\n",
            "          Conv2d-714          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-715          [-1, 192, 38, 38]             384\n",
            "            ReLU-716          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-717          [-1, 192, 38, 38]               0\n",
            "          Conv2d-718          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-719          [-1, 192, 38, 38]             384\n",
            "            ReLU-720          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-721          [-1, 192, 38, 38]               0\n",
            "          Conv2d-722          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-723          [-1, 224, 38, 38]             448\n",
            "            ReLU-724          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-725          [-1, 224, 38, 38]               0\n",
            "          Conv2d-726          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-727          [-1, 224, 38, 38]             448\n",
            "            ReLU-728          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-729          [-1, 224, 38, 38]               0\n",
            "          Conv2d-730          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-731          [-1, 256, 38, 38]             512\n",
            "            ReLU-732          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-733          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-734         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-735          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-736          [-1, 128, 38, 38]             256\n",
            "            ReLU-737          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-738          [-1, 128, 38, 38]               0\n",
            "      InceptionB-739         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-740          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-741          [-1, 384, 38, 38]             768\n",
            "            ReLU-742          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-743          [-1, 384, 38, 38]               0\n",
            "          Conv2d-744          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-745          [-1, 192, 38, 38]             384\n",
            "            ReLU-746          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-747          [-1, 192, 38, 38]               0\n",
            "          Conv2d-748          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-749          [-1, 224, 38, 38]             448\n",
            "            ReLU-750          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-751          [-1, 224, 38, 38]               0\n",
            "          Conv2d-752          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-753          [-1, 256, 38, 38]             512\n",
            "            ReLU-754          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-755          [-1, 256, 38, 38]               0\n",
            "          Conv2d-756          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-757          [-1, 192, 38, 38]             384\n",
            "            ReLU-758          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-759          [-1, 192, 38, 38]               0\n",
            "          Conv2d-760          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-761          [-1, 192, 38, 38]             384\n",
            "            ReLU-762          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-763          [-1, 192, 38, 38]               0\n",
            "          Conv2d-764          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-765          [-1, 224, 38, 38]             448\n",
            "            ReLU-766          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-767          [-1, 224, 38, 38]               0\n",
            "          Conv2d-768          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-769          [-1, 224, 38, 38]             448\n",
            "            ReLU-770          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-771          [-1, 224, 38, 38]               0\n",
            "          Conv2d-772          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-773          [-1, 256, 38, 38]             512\n",
            "            ReLU-774          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-775          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-776         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-777          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-778          [-1, 128, 38, 38]             256\n",
            "            ReLU-779          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-780          [-1, 128, 38, 38]               0\n",
            "      InceptionB-781         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-782          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-783          [-1, 384, 38, 38]             768\n",
            "            ReLU-784          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-785          [-1, 384, 38, 38]               0\n",
            "          Conv2d-786          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-787          [-1, 192, 38, 38]             384\n",
            "            ReLU-788          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-789          [-1, 192, 38, 38]               0\n",
            "          Conv2d-790          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-791          [-1, 224, 38, 38]             448\n",
            "            ReLU-792          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-793          [-1, 224, 38, 38]               0\n",
            "          Conv2d-794          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-795          [-1, 256, 38, 38]             512\n",
            "            ReLU-796          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-797          [-1, 256, 38, 38]               0\n",
            "          Conv2d-798          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-799          [-1, 192, 38, 38]             384\n",
            "            ReLU-800          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-801          [-1, 192, 38, 38]               0\n",
            "          Conv2d-802          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-803          [-1, 192, 38, 38]             384\n",
            "            ReLU-804          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-805          [-1, 192, 38, 38]               0\n",
            "          Conv2d-806          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-807          [-1, 224, 38, 38]             448\n",
            "            ReLU-808          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-809          [-1, 224, 38, 38]               0\n",
            "          Conv2d-810          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-811          [-1, 224, 38, 38]             448\n",
            "            ReLU-812          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-813          [-1, 224, 38, 38]               0\n",
            "          Conv2d-814          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-815          [-1, 256, 38, 38]             512\n",
            "            ReLU-816          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-817          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-818         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-819          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-820          [-1, 128, 38, 38]             256\n",
            "            ReLU-821          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-822          [-1, 128, 38, 38]               0\n",
            "      InceptionB-823         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-824          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-825          [-1, 384, 38, 38]             768\n",
            "            ReLU-826          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-827          [-1, 384, 38, 38]               0\n",
            "          Conv2d-828          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-829          [-1, 192, 38, 38]             384\n",
            "            ReLU-830          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-831          [-1, 192, 38, 38]               0\n",
            "          Conv2d-832          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-833          [-1, 224, 38, 38]             448\n",
            "            ReLU-834          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-835          [-1, 224, 38, 38]               0\n",
            "          Conv2d-836          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-837          [-1, 256, 38, 38]             512\n",
            "            ReLU-838          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-839          [-1, 256, 38, 38]               0\n",
            "          Conv2d-840          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-841          [-1, 192, 38, 38]             384\n",
            "            ReLU-842          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-843          [-1, 192, 38, 38]               0\n",
            "          Conv2d-844          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-845          [-1, 192, 38, 38]             384\n",
            "            ReLU-846          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-847          [-1, 192, 38, 38]               0\n",
            "          Conv2d-848          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-849          [-1, 224, 38, 38]             448\n",
            "            ReLU-850          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-851          [-1, 224, 38, 38]               0\n",
            "          Conv2d-852          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-853          [-1, 224, 38, 38]             448\n",
            "            ReLU-854          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-855          [-1, 224, 38, 38]               0\n",
            "          Conv2d-856          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-857          [-1, 256, 38, 38]             512\n",
            "            ReLU-858          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-859          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-860         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-861          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-862          [-1, 128, 38, 38]             256\n",
            "            ReLU-863          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-864          [-1, 128, 38, 38]               0\n",
            "      InceptionB-865         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-866          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-867          [-1, 384, 38, 38]             768\n",
            "            ReLU-868          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-869          [-1, 384, 38, 38]               0\n",
            "          Conv2d-870          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-871          [-1, 192, 38, 38]             384\n",
            "            ReLU-872          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-873          [-1, 192, 38, 38]               0\n",
            "          Conv2d-874          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-875          [-1, 224, 38, 38]             448\n",
            "            ReLU-876          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-877          [-1, 224, 38, 38]               0\n",
            "          Conv2d-878          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-879          [-1, 256, 38, 38]             512\n",
            "            ReLU-880          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-881          [-1, 256, 38, 38]               0\n",
            "          Conv2d-882          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-883          [-1, 192, 38, 38]             384\n",
            "            ReLU-884          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-885          [-1, 192, 38, 38]               0\n",
            "          Conv2d-886          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-887          [-1, 192, 38, 38]             384\n",
            "            ReLU-888          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-889          [-1, 192, 38, 38]               0\n",
            "          Conv2d-890          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-891          [-1, 224, 38, 38]             448\n",
            "            ReLU-892          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-893          [-1, 224, 38, 38]               0\n",
            "          Conv2d-894          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-895          [-1, 224, 38, 38]             448\n",
            "            ReLU-896          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-897          [-1, 224, 38, 38]               0\n",
            "          Conv2d-898          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-899          [-1, 256, 38, 38]             512\n",
            "            ReLU-900          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-901          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-902         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-903          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-904          [-1, 128, 38, 38]             256\n",
            "            ReLU-905          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-906          [-1, 128, 38, 38]               0\n",
            "      InceptionB-907         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-908          [-1, 384, 38, 38]         393,216\n",
            "     BatchNorm2d-909          [-1, 384, 38, 38]             768\n",
            "            ReLU-910          [-1, 384, 38, 38]               0\n",
            "     BasicConv2d-911          [-1, 384, 38, 38]               0\n",
            "          Conv2d-912          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-913          [-1, 192, 38, 38]             384\n",
            "            ReLU-914          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-915          [-1, 192, 38, 38]               0\n",
            "          Conv2d-916          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-917          [-1, 224, 38, 38]             448\n",
            "            ReLU-918          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-919          [-1, 224, 38, 38]               0\n",
            "          Conv2d-920          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-921          [-1, 256, 38, 38]             512\n",
            "            ReLU-922          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-923          [-1, 256, 38, 38]               0\n",
            "          Conv2d-924          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-925          [-1, 192, 38, 38]             384\n",
            "            ReLU-926          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-927          [-1, 192, 38, 38]               0\n",
            "          Conv2d-928          [-1, 192, 38, 38]         258,048\n",
            "     BatchNorm2d-929          [-1, 192, 38, 38]             384\n",
            "            ReLU-930          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-931          [-1, 192, 38, 38]               0\n",
            "          Conv2d-932          [-1, 224, 38, 38]         301,056\n",
            "     BatchNorm2d-933          [-1, 224, 38, 38]             448\n",
            "            ReLU-934          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-935          [-1, 224, 38, 38]               0\n",
            "          Conv2d-936          [-1, 224, 38, 38]         351,232\n",
            "     BatchNorm2d-937          [-1, 224, 38, 38]             448\n",
            "            ReLU-938          [-1, 224, 38, 38]               0\n",
            "     BasicConv2d-939          [-1, 224, 38, 38]               0\n",
            "          Conv2d-940          [-1, 256, 38, 38]         401,408\n",
            "     BatchNorm2d-941          [-1, 256, 38, 38]             512\n",
            "            ReLU-942          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-943          [-1, 256, 38, 38]               0\n",
            "       AvgPool2d-944         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-945          [-1, 128, 38, 38]         131,072\n",
            "     BatchNorm2d-946          [-1, 128, 38, 38]             256\n",
            "            ReLU-947          [-1, 128, 38, 38]               0\n",
            "     BasicConv2d-948          [-1, 128, 38, 38]               0\n",
            "      InceptionB-949         [-1, 1024, 38, 38]               0\n",
            "          Conv2d-950          [-1, 192, 38, 38]         196,608\n",
            "     BatchNorm2d-951          [-1, 192, 38, 38]             384\n",
            "            ReLU-952          [-1, 192, 38, 38]               0\n",
            "     BasicConv2d-953          [-1, 192, 38, 38]               0\n",
            "          Conv2d-954          [-1, 192, 18, 18]         331,776\n",
            "     BatchNorm2d-955          [-1, 192, 18, 18]             384\n",
            "            ReLU-956          [-1, 192, 18, 18]               0\n",
            "     BasicConv2d-957          [-1, 192, 18, 18]               0\n",
            "          Conv2d-958          [-1, 256, 38, 38]         262,144\n",
            "     BatchNorm2d-959          [-1, 256, 38, 38]             512\n",
            "            ReLU-960          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-961          [-1, 256, 38, 38]               0\n",
            "          Conv2d-962          [-1, 256, 38, 38]         458,752\n",
            "     BatchNorm2d-963          [-1, 256, 38, 38]             512\n",
            "            ReLU-964          [-1, 256, 38, 38]               0\n",
            "     BasicConv2d-965          [-1, 256, 38, 38]               0\n",
            "          Conv2d-966          [-1, 320, 38, 38]         573,440\n",
            "     BatchNorm2d-967          [-1, 320, 38, 38]             640\n",
            "            ReLU-968          [-1, 320, 38, 38]               0\n",
            "     BasicConv2d-969          [-1, 320, 38, 38]               0\n",
            "          Conv2d-970          [-1, 320, 18, 18]         921,600\n",
            "     BatchNorm2d-971          [-1, 320, 18, 18]             640\n",
            "            ReLU-972          [-1, 320, 18, 18]               0\n",
            "     BasicConv2d-973          [-1, 320, 18, 18]               0\n",
            "       MaxPool2d-974         [-1, 1024, 18, 18]               0\n",
            "      ReductionB-975         [-1, 1536, 18, 18]               0\n",
            "          Conv2d-976          [-1, 256, 18, 18]         393,216\n",
            "     BatchNorm2d-977          [-1, 256, 18, 18]             512\n",
            "            ReLU-978          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-979          [-1, 256, 18, 18]               0\n",
            "          Conv2d-980          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-981          [-1, 384, 18, 18]             768\n",
            "            ReLU-982          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-983          [-1, 384, 18, 18]               0\n",
            "          Conv2d-984          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-985          [-1, 256, 18, 18]             512\n",
            "            ReLU-986          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-987          [-1, 256, 18, 18]               0\n",
            "          Conv2d-988          [-1, 256, 18, 18]         294,912\n",
            "     BatchNorm2d-989          [-1, 256, 18, 18]             512\n",
            "            ReLU-990          [-1, 256, 18, 18]               0\n",
            "     BasicConv2d-991          [-1, 256, 18, 18]               0\n",
            "          Conv2d-992          [-1, 384, 18, 18]         589,824\n",
            "     BatchNorm2d-993          [-1, 384, 18, 18]             768\n",
            "            ReLU-994          [-1, 384, 18, 18]               0\n",
            "     BasicConv2d-995          [-1, 384, 18, 18]               0\n",
            "          Conv2d-996          [-1, 448, 18, 18]         516,096\n",
            "     BatchNorm2d-997          [-1, 448, 18, 18]             896\n",
            "            ReLU-998          [-1, 448, 18, 18]               0\n",
            "     BasicConv2d-999          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1000          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1001          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1002          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1003          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1004          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1005          [-1, 256, 18, 18]             512\n",
            "           ReLU-1006          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1007          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1008          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1009          [-1, 256, 18, 18]             512\n",
            "           ReLU-1010          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1011          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1012         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1013          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1014          [-1, 256, 18, 18]             512\n",
            "           ReLU-1015          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1016          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1017         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1018          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1019          [-1, 256, 18, 18]             512\n",
            "           ReLU-1020          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1021          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1022          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1023          [-1, 384, 18, 18]             768\n",
            "           ReLU-1024          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1025          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1026          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1027          [-1, 256, 18, 18]             512\n",
            "           ReLU-1028          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1029          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1030          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1031          [-1, 256, 18, 18]             512\n",
            "           ReLU-1032          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1033          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1034          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1035          [-1, 384, 18, 18]             768\n",
            "           ReLU-1036          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1037          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1038          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-1039          [-1, 448, 18, 18]             896\n",
            "           ReLU-1040          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-1041          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1042          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1043          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1044          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1045          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1046          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1047          [-1, 256, 18, 18]             512\n",
            "           ReLU-1048          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1049          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1050          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1051          [-1, 256, 18, 18]             512\n",
            "           ReLU-1052          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1053          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1054         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1055          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1056          [-1, 256, 18, 18]             512\n",
            "           ReLU-1057          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1058          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1059         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1060          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1061          [-1, 256, 18, 18]             512\n",
            "           ReLU-1062          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1063          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1064          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1065          [-1, 384, 18, 18]             768\n",
            "           ReLU-1066          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1067          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1068          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1069          [-1, 256, 18, 18]             512\n",
            "           ReLU-1070          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1071          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1072          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1073          [-1, 256, 18, 18]             512\n",
            "           ReLU-1074          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1075          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1076          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1077          [-1, 384, 18, 18]             768\n",
            "           ReLU-1078          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1079          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1080          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-1081          [-1, 448, 18, 18]             896\n",
            "           ReLU-1082          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-1083          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1084          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1085          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1086          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1087          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1088          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1089          [-1, 256, 18, 18]             512\n",
            "           ReLU-1090          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1091          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1092          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1093          [-1, 256, 18, 18]             512\n",
            "           ReLU-1094          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1095          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1096         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1097          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1098          [-1, 256, 18, 18]             512\n",
            "           ReLU-1099          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1100          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1101         [-1, 1536, 18, 18]               0\n",
            "AdaptiveAvgPool2d-1102           [-1, 1536, 1, 1]               0\n",
            "         Linear-1103                    [-1, 1]           1,537\n",
            " TH_InceptionV4-1104                    [-1, 6]               0\n",
            "         Conv2d-1105         [-1, 32, 319, 319]             864\n",
            "    BatchNorm2d-1106         [-1, 32, 319, 319]              64\n",
            "           ReLU-1107         [-1, 32, 319, 319]               0\n",
            "    BasicConv2d-1108         [-1, 32, 319, 319]               0\n",
            "         Conv2d-1109         [-1, 32, 317, 317]           9,216\n",
            "    BatchNorm2d-1110         [-1, 32, 317, 317]              64\n",
            "           ReLU-1111         [-1, 32, 317, 317]               0\n",
            "    BasicConv2d-1112         [-1, 32, 317, 317]               0\n",
            "         Conv2d-1113         [-1, 64, 317, 317]          18,432\n",
            "    BatchNorm2d-1114         [-1, 64, 317, 317]             128\n",
            "           ReLU-1115         [-1, 64, 317, 317]               0\n",
            "    BasicConv2d-1116         [-1, 64, 317, 317]               0\n",
            "      MaxPool2d-1117         [-1, 64, 158, 158]               0\n",
            "         Conv2d-1118         [-1, 96, 158, 158]          55,296\n",
            "    BatchNorm2d-1119         [-1, 96, 158, 158]             192\n",
            "           ReLU-1120         [-1, 96, 158, 158]               0\n",
            "    BasicConv2d-1121         [-1, 96, 158, 158]               0\n",
            "         Conv2d-1122         [-1, 64, 158, 158]          10,240\n",
            "    BatchNorm2d-1123         [-1, 64, 158, 158]             128\n",
            "           ReLU-1124         [-1, 64, 158, 158]               0\n",
            "    BasicConv2d-1125         [-1, 64, 158, 158]               0\n",
            "         Conv2d-1126         [-1, 96, 156, 156]          55,296\n",
            "    BatchNorm2d-1127         [-1, 96, 156, 156]             192\n",
            "           ReLU-1128         [-1, 96, 156, 156]               0\n",
            "    BasicConv2d-1129         [-1, 96, 156, 156]               0\n",
            "         Conv2d-1130         [-1, 64, 158, 158]          10,240\n",
            "    BatchNorm2d-1131         [-1, 64, 158, 158]             128\n",
            "           ReLU-1132         [-1, 64, 158, 158]               0\n",
            "    BasicConv2d-1133         [-1, 64, 158, 158]               0\n",
            "         Conv2d-1134         [-1, 64, 158, 158]          28,672\n",
            "    BatchNorm2d-1135         [-1, 64, 158, 158]             128\n",
            "           ReLU-1136         [-1, 64, 158, 158]               0\n",
            "    BasicConv2d-1137         [-1, 64, 158, 158]               0\n",
            "         Conv2d-1138         [-1, 64, 158, 158]          28,672\n",
            "    BatchNorm2d-1139         [-1, 64, 158, 158]             128\n",
            "           ReLU-1140         [-1, 64, 158, 158]               0\n",
            "    BasicConv2d-1141         [-1, 64, 158, 158]               0\n",
            "         Conv2d-1142         [-1, 96, 156, 156]          55,296\n",
            "    BatchNorm2d-1143         [-1, 96, 156, 156]             192\n",
            "           ReLU-1144         [-1, 96, 156, 156]               0\n",
            "    BasicConv2d-1145         [-1, 96, 156, 156]               0\n",
            "         Conv2d-1146          [-1, 192, 77, 77]         331,776\n",
            "    BatchNorm2d-1147          [-1, 192, 77, 77]             384\n",
            "           ReLU-1148          [-1, 192, 77, 77]               0\n",
            "    BasicConv2d-1149          [-1, 192, 77, 77]               0\n",
            "      MaxPool2d-1150          [-1, 192, 77, 77]               0\n",
            "InceptionV4Stem-1151          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1152           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1153           [-1, 96, 77, 77]             192\n",
            "           ReLU-1154           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1155           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1156           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1157           [-1, 64, 77, 77]             128\n",
            "           ReLU-1158           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1159           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1160           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1161           [-1, 96, 77, 77]             192\n",
            "           ReLU-1162           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1163           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1164           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1165           [-1, 64, 77, 77]             128\n",
            "           ReLU-1166           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1167           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1168           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1169           [-1, 96, 77, 77]             192\n",
            "           ReLU-1170           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1171           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1172           [-1, 96, 77, 77]          82,944\n",
            "    BatchNorm2d-1173           [-1, 96, 77, 77]             192\n",
            "           ReLU-1174           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1175           [-1, 96, 77, 77]               0\n",
            "      AvgPool2d-1176          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1177           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1178           [-1, 96, 77, 77]             192\n",
            "           ReLU-1179           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1180           [-1, 96, 77, 77]               0\n",
            "     InceptionA-1181          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1182           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1183           [-1, 96, 77, 77]             192\n",
            "           ReLU-1184           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1185           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1186           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1187           [-1, 64, 77, 77]             128\n",
            "           ReLU-1188           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1189           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1190           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1191           [-1, 96, 77, 77]             192\n",
            "           ReLU-1192           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1193           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1194           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1195           [-1, 64, 77, 77]             128\n",
            "           ReLU-1196           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1197           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1198           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1199           [-1, 96, 77, 77]             192\n",
            "           ReLU-1200           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1201           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1202           [-1, 96, 77, 77]          82,944\n",
            "    BatchNorm2d-1203           [-1, 96, 77, 77]             192\n",
            "           ReLU-1204           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1205           [-1, 96, 77, 77]               0\n",
            "      AvgPool2d-1206          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1207           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1208           [-1, 96, 77, 77]             192\n",
            "           ReLU-1209           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1210           [-1, 96, 77, 77]               0\n",
            "     InceptionA-1211          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1212           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1213           [-1, 96, 77, 77]             192\n",
            "           ReLU-1214           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1215           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1216           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1217           [-1, 64, 77, 77]             128\n",
            "           ReLU-1218           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1219           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1220           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1221           [-1, 96, 77, 77]             192\n",
            "           ReLU-1222           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1223           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1224           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1225           [-1, 64, 77, 77]             128\n",
            "           ReLU-1226           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1227           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1228           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1229           [-1, 96, 77, 77]             192\n",
            "           ReLU-1230           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1231           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1232           [-1, 96, 77, 77]          82,944\n",
            "    BatchNorm2d-1233           [-1, 96, 77, 77]             192\n",
            "           ReLU-1234           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1235           [-1, 96, 77, 77]               0\n",
            "      AvgPool2d-1236          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1237           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1238           [-1, 96, 77, 77]             192\n",
            "           ReLU-1239           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1240           [-1, 96, 77, 77]               0\n",
            "     InceptionA-1241          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1242           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1243           [-1, 96, 77, 77]             192\n",
            "           ReLU-1244           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1245           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1246           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1247           [-1, 64, 77, 77]             128\n",
            "           ReLU-1248           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1249           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1250           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1251           [-1, 96, 77, 77]             192\n",
            "           ReLU-1252           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1253           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1254           [-1, 64, 77, 77]          24,576\n",
            "    BatchNorm2d-1255           [-1, 64, 77, 77]             128\n",
            "           ReLU-1256           [-1, 64, 77, 77]               0\n",
            "    BasicConv2d-1257           [-1, 64, 77, 77]               0\n",
            "         Conv2d-1258           [-1, 96, 77, 77]          55,296\n",
            "    BatchNorm2d-1259           [-1, 96, 77, 77]             192\n",
            "           ReLU-1260           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1261           [-1, 96, 77, 77]               0\n",
            "         Conv2d-1262           [-1, 96, 77, 77]          82,944\n",
            "    BatchNorm2d-1263           [-1, 96, 77, 77]             192\n",
            "           ReLU-1264           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1265           [-1, 96, 77, 77]               0\n",
            "      AvgPool2d-1266          [-1, 384, 77, 77]               0\n",
            "         Conv2d-1267           [-1, 96, 77, 77]          36,864\n",
            "    BatchNorm2d-1268           [-1, 96, 77, 77]             192\n",
            "           ReLU-1269           [-1, 96, 77, 77]               0\n",
            "    BasicConv2d-1270           [-1, 96, 77, 77]               0\n",
            "     InceptionA-1271          [-1, 384, 77, 77]               0\n",
            "AdaptiveAvgPool2d-1272            [-1, 384, 1, 1]               0\n",
            "         Linear-1273                    [-1, 2]             770\n",
            "         Conv2d-1274          [-1, 384, 38, 38]       1,327,104\n",
            "    BatchNorm2d-1275          [-1, 384, 38, 38]             768\n",
            "           ReLU-1276          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1277          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1278          [-1, 192, 77, 77]          73,728\n",
            "    BatchNorm2d-1279          [-1, 192, 77, 77]             384\n",
            "           ReLU-1280          [-1, 192, 77, 77]               0\n",
            "    BasicConv2d-1281          [-1, 192, 77, 77]               0\n",
            "         Conv2d-1282          [-1, 224, 77, 77]         387,072\n",
            "    BatchNorm2d-1283          [-1, 224, 77, 77]             448\n",
            "           ReLU-1284          [-1, 224, 77, 77]               0\n",
            "    BasicConv2d-1285          [-1, 224, 77, 77]               0\n",
            "         Conv2d-1286          [-1, 256, 38, 38]         516,096\n",
            "    BatchNorm2d-1287          [-1, 256, 38, 38]             512\n",
            "           ReLU-1288          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1289          [-1, 256, 38, 38]               0\n",
            "      MaxPool2d-1290          [-1, 384, 38, 38]               0\n",
            "     ReductionA-1291         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1292          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1293          [-1, 384, 38, 38]             768\n",
            "           ReLU-1294          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1295          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1296          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1297          [-1, 192, 38, 38]             384\n",
            "           ReLU-1298          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1299          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1300          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1301          [-1, 224, 38, 38]             448\n",
            "           ReLU-1302          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1303          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1304          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1305          [-1, 256, 38, 38]             512\n",
            "           ReLU-1306          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1307          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1308          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1309          [-1, 192, 38, 38]             384\n",
            "           ReLU-1310          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1311          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1312          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1313          [-1, 192, 38, 38]             384\n",
            "           ReLU-1314          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1315          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1316          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1317          [-1, 224, 38, 38]             448\n",
            "           ReLU-1318          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1319          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1320          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1321          [-1, 224, 38, 38]             448\n",
            "           ReLU-1322          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1323          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1324          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1325          [-1, 256, 38, 38]             512\n",
            "           ReLU-1326          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1327          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1328         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1329          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1330          [-1, 128, 38, 38]             256\n",
            "           ReLU-1331          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1332          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1333         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1334          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1335          [-1, 384, 38, 38]             768\n",
            "           ReLU-1336          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1337          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1338          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1339          [-1, 192, 38, 38]             384\n",
            "           ReLU-1340          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1341          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1342          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1343          [-1, 224, 38, 38]             448\n",
            "           ReLU-1344          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1345          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1346          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1347          [-1, 256, 38, 38]             512\n",
            "           ReLU-1348          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1349          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1350          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1351          [-1, 192, 38, 38]             384\n",
            "           ReLU-1352          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1353          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1354          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1355          [-1, 192, 38, 38]             384\n",
            "           ReLU-1356          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1357          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1358          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1359          [-1, 224, 38, 38]             448\n",
            "           ReLU-1360          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1361          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1362          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1363          [-1, 224, 38, 38]             448\n",
            "           ReLU-1364          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1365          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1366          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1367          [-1, 256, 38, 38]             512\n",
            "           ReLU-1368          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1369          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1370         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1371          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1372          [-1, 128, 38, 38]             256\n",
            "           ReLU-1373          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1374          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1375         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1376          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1377          [-1, 384, 38, 38]             768\n",
            "           ReLU-1378          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1379          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1380          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1381          [-1, 192, 38, 38]             384\n",
            "           ReLU-1382          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1383          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1384          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1385          [-1, 224, 38, 38]             448\n",
            "           ReLU-1386          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1387          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1388          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1389          [-1, 256, 38, 38]             512\n",
            "           ReLU-1390          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1391          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1392          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1393          [-1, 192, 38, 38]             384\n",
            "           ReLU-1394          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1395          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1396          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1397          [-1, 192, 38, 38]             384\n",
            "           ReLU-1398          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1399          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1400          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1401          [-1, 224, 38, 38]             448\n",
            "           ReLU-1402          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1403          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1404          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1405          [-1, 224, 38, 38]             448\n",
            "           ReLU-1406          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1407          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1408          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1409          [-1, 256, 38, 38]             512\n",
            "           ReLU-1410          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1411          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1412         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1413          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1414          [-1, 128, 38, 38]             256\n",
            "           ReLU-1415          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1416          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1417         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1418          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1419          [-1, 384, 38, 38]             768\n",
            "           ReLU-1420          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1421          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1422          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1423          [-1, 192, 38, 38]             384\n",
            "           ReLU-1424          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1425          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1426          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1427          [-1, 224, 38, 38]             448\n",
            "           ReLU-1428          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1429          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1430          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1431          [-1, 256, 38, 38]             512\n",
            "           ReLU-1432          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1433          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1434          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1435          [-1, 192, 38, 38]             384\n",
            "           ReLU-1436          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1437          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1438          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1439          [-1, 192, 38, 38]             384\n",
            "           ReLU-1440          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1441          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1442          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1443          [-1, 224, 38, 38]             448\n",
            "           ReLU-1444          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1445          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1446          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1447          [-1, 224, 38, 38]             448\n",
            "           ReLU-1448          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1449          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1450          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1451          [-1, 256, 38, 38]             512\n",
            "           ReLU-1452          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1453          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1454         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1455          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1456          [-1, 128, 38, 38]             256\n",
            "           ReLU-1457          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1458          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1459         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1460          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1461          [-1, 384, 38, 38]             768\n",
            "           ReLU-1462          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1463          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1464          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1465          [-1, 192, 38, 38]             384\n",
            "           ReLU-1466          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1467          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1468          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1469          [-1, 224, 38, 38]             448\n",
            "           ReLU-1470          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1471          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1472          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1473          [-1, 256, 38, 38]             512\n",
            "           ReLU-1474          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1475          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1476          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1477          [-1, 192, 38, 38]             384\n",
            "           ReLU-1478          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1479          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1480          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1481          [-1, 192, 38, 38]             384\n",
            "           ReLU-1482          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1483          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1484          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1485          [-1, 224, 38, 38]             448\n",
            "           ReLU-1486          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1487          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1488          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1489          [-1, 224, 38, 38]             448\n",
            "           ReLU-1490          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1491          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1492          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1493          [-1, 256, 38, 38]             512\n",
            "           ReLU-1494          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1495          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1496         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1497          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1498          [-1, 128, 38, 38]             256\n",
            "           ReLU-1499          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1500          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1501         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1502          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1503          [-1, 384, 38, 38]             768\n",
            "           ReLU-1504          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1505          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1506          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1507          [-1, 192, 38, 38]             384\n",
            "           ReLU-1508          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1509          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1510          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1511          [-1, 224, 38, 38]             448\n",
            "           ReLU-1512          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1513          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1514          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1515          [-1, 256, 38, 38]             512\n",
            "           ReLU-1516          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1517          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1518          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1519          [-1, 192, 38, 38]             384\n",
            "           ReLU-1520          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1521          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1522          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1523          [-1, 192, 38, 38]             384\n",
            "           ReLU-1524          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1525          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1526          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1527          [-1, 224, 38, 38]             448\n",
            "           ReLU-1528          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1529          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1530          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1531          [-1, 224, 38, 38]             448\n",
            "           ReLU-1532          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1533          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1534          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1535          [-1, 256, 38, 38]             512\n",
            "           ReLU-1536          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1537          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1538         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1539          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1540          [-1, 128, 38, 38]             256\n",
            "           ReLU-1541          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1542          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1543         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1544          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1545          [-1, 384, 38, 38]             768\n",
            "           ReLU-1546          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1547          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1548          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1549          [-1, 192, 38, 38]             384\n",
            "           ReLU-1550          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1551          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1552          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1553          [-1, 224, 38, 38]             448\n",
            "           ReLU-1554          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1555          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1556          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1557          [-1, 256, 38, 38]             512\n",
            "           ReLU-1558          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1559          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1560          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1561          [-1, 192, 38, 38]             384\n",
            "           ReLU-1562          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1563          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1564          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1565          [-1, 192, 38, 38]             384\n",
            "           ReLU-1566          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1567          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1568          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1569          [-1, 224, 38, 38]             448\n",
            "           ReLU-1570          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1571          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1572          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1573          [-1, 224, 38, 38]             448\n",
            "           ReLU-1574          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1575          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1576          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1577          [-1, 256, 38, 38]             512\n",
            "           ReLU-1578          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1579          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1580         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1581          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1582          [-1, 128, 38, 38]             256\n",
            "           ReLU-1583          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1584          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1585         [-1, 1024, 38, 38]               0\n",
            "AdaptiveAvgPool2d-1586           [-1, 1024, 1, 1]               0\n",
            "         Linear-1587                    [-1, 2]           2,050\n",
            "         Conv2d-1588          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1589          [-1, 192, 38, 38]             384\n",
            "           ReLU-1590          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1591          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1592          [-1, 192, 18, 18]         331,776\n",
            "    BatchNorm2d-1593          [-1, 192, 18, 18]             384\n",
            "           ReLU-1594          [-1, 192, 18, 18]               0\n",
            "    BasicConv2d-1595          [-1, 192, 18, 18]               0\n",
            "         Conv2d-1596          [-1, 256, 38, 38]         262,144\n",
            "    BatchNorm2d-1597          [-1, 256, 38, 38]             512\n",
            "           ReLU-1598          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1599          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1600          [-1, 256, 38, 38]         458,752\n",
            "    BatchNorm2d-1601          [-1, 256, 38, 38]             512\n",
            "           ReLU-1602          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1603          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1604          [-1, 320, 38, 38]         573,440\n",
            "    BatchNorm2d-1605          [-1, 320, 38, 38]             640\n",
            "           ReLU-1606          [-1, 320, 38, 38]               0\n",
            "    BasicConv2d-1607          [-1, 320, 38, 38]               0\n",
            "         Conv2d-1608          [-1, 320, 18, 18]         921,600\n",
            "    BatchNorm2d-1609          [-1, 320, 18, 18]             640\n",
            "           ReLU-1610          [-1, 320, 18, 18]               0\n",
            "    BasicConv2d-1611          [-1, 320, 18, 18]               0\n",
            "      MaxPool2d-1612         [-1, 1024, 18, 18]               0\n",
            "     ReductionB-1613         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1614          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1615          [-1, 256, 18, 18]             512\n",
            "           ReLU-1616          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1617          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1618          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1619          [-1, 384, 18, 18]             768\n",
            "           ReLU-1620          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1621          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1622          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1623          [-1, 256, 18, 18]             512\n",
            "           ReLU-1624          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1625          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1626          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1627          [-1, 256, 18, 18]             512\n",
            "           ReLU-1628          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1629          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1630          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1631          [-1, 384, 18, 18]             768\n",
            "           ReLU-1632          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1633          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1634          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-1635          [-1, 448, 18, 18]             896\n",
            "           ReLU-1636          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-1637          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1638          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1639          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1640          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1641          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1642          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1643          [-1, 256, 18, 18]             512\n",
            "           ReLU-1644          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1645          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1646          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1647          [-1, 256, 18, 18]             512\n",
            "           ReLU-1648          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1649          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1650         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1651          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1652          [-1, 256, 18, 18]             512\n",
            "           ReLU-1653          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1654          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1655         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1656          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1657          [-1, 256, 18, 18]             512\n",
            "           ReLU-1658          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1659          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1660          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1661          [-1, 384, 18, 18]             768\n",
            "           ReLU-1662          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1663          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1664          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1665          [-1, 256, 18, 18]             512\n",
            "           ReLU-1666          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1667          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1668          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1669          [-1, 256, 18, 18]             512\n",
            "           ReLU-1670          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1671          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1672          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1673          [-1, 384, 18, 18]             768\n",
            "           ReLU-1674          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1675          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1676          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-1677          [-1, 448, 18, 18]             896\n",
            "           ReLU-1678          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-1679          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1680          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1681          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1682          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1683          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1684          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1685          [-1, 256, 18, 18]             512\n",
            "           ReLU-1686          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1687          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1688          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1689          [-1, 256, 18, 18]             512\n",
            "           ReLU-1690          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1691          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1692         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1693          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1694          [-1, 256, 18, 18]             512\n",
            "           ReLU-1695          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1696          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1697         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1698          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1699          [-1, 256, 18, 18]             512\n",
            "           ReLU-1700          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1701          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1702          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1703          [-1, 384, 18, 18]             768\n",
            "           ReLU-1704          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1705          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1706          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1707          [-1, 256, 18, 18]             512\n",
            "           ReLU-1708          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1709          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1710          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-1711          [-1, 256, 18, 18]             512\n",
            "           ReLU-1712          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1713          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1714          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-1715          [-1, 384, 18, 18]             768\n",
            "           ReLU-1716          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-1717          [-1, 384, 18, 18]               0\n",
            "         Conv2d-1718          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-1719          [-1, 448, 18, 18]             896\n",
            "           ReLU-1720          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-1721          [-1, 448, 18, 18]               0\n",
            "         Conv2d-1722          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-1723          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-1724          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-1725          [-1, 512, 18, 18]               0\n",
            "         Conv2d-1726          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1727          [-1, 256, 18, 18]             512\n",
            "           ReLU-1728          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1729          [-1, 256, 18, 18]               0\n",
            "         Conv2d-1730          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1731          [-1, 256, 18, 18]             512\n",
            "           ReLU-1732          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1733          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-1734         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-1735          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-1736          [-1, 256, 18, 18]             512\n",
            "           ReLU-1737          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-1738          [-1, 256, 18, 18]               0\n",
            "     InceptionC-1739         [-1, 1536, 18, 18]               0\n",
            "AdaptiveAvgPool2d-1740           [-1, 1536, 1, 1]               0\n",
            "         Linear-1741                    [-1, 1]           1,537\n",
            "         Conv2d-1742          [-1, 384, 38, 38]       1,327,104\n",
            "    BatchNorm2d-1743          [-1, 384, 38, 38]             768\n",
            "           ReLU-1744          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1745          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1746          [-1, 192, 77, 77]          73,728\n",
            "    BatchNorm2d-1747          [-1, 192, 77, 77]             384\n",
            "           ReLU-1748          [-1, 192, 77, 77]               0\n",
            "    BasicConv2d-1749          [-1, 192, 77, 77]               0\n",
            "         Conv2d-1750          [-1, 224, 77, 77]         387,072\n",
            "    BatchNorm2d-1751          [-1, 224, 77, 77]             448\n",
            "           ReLU-1752          [-1, 224, 77, 77]               0\n",
            "    BasicConv2d-1753          [-1, 224, 77, 77]               0\n",
            "         Conv2d-1754          [-1, 256, 38, 38]         516,096\n",
            "    BatchNorm2d-1755          [-1, 256, 38, 38]             512\n",
            "           ReLU-1756          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1757          [-1, 256, 38, 38]               0\n",
            "      MaxPool2d-1758          [-1, 384, 38, 38]               0\n",
            "     ReductionA-1759         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1760          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1761          [-1, 384, 38, 38]             768\n",
            "           ReLU-1762          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1763          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1764          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1765          [-1, 192, 38, 38]             384\n",
            "           ReLU-1766          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1767          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1768          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1769          [-1, 224, 38, 38]             448\n",
            "           ReLU-1770          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1771          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1772          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1773          [-1, 256, 38, 38]             512\n",
            "           ReLU-1774          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1775          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1776          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1777          [-1, 192, 38, 38]             384\n",
            "           ReLU-1778          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1779          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1780          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1781          [-1, 192, 38, 38]             384\n",
            "           ReLU-1782          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1783          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1784          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1785          [-1, 224, 38, 38]             448\n",
            "           ReLU-1786          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1787          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1788          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1789          [-1, 224, 38, 38]             448\n",
            "           ReLU-1790          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1791          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1792          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1793          [-1, 256, 38, 38]             512\n",
            "           ReLU-1794          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1795          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1796         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1797          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1798          [-1, 128, 38, 38]             256\n",
            "           ReLU-1799          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1800          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1801         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1802          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1803          [-1, 384, 38, 38]             768\n",
            "           ReLU-1804          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1805          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1806          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1807          [-1, 192, 38, 38]             384\n",
            "           ReLU-1808          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1809          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1810          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1811          [-1, 224, 38, 38]             448\n",
            "           ReLU-1812          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1813          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1814          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1815          [-1, 256, 38, 38]             512\n",
            "           ReLU-1816          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1817          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1818          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1819          [-1, 192, 38, 38]             384\n",
            "           ReLU-1820          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1821          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1822          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1823          [-1, 192, 38, 38]             384\n",
            "           ReLU-1824          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1825          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1826          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1827          [-1, 224, 38, 38]             448\n",
            "           ReLU-1828          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1829          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1830          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1831          [-1, 224, 38, 38]             448\n",
            "           ReLU-1832          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1833          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1834          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1835          [-1, 256, 38, 38]             512\n",
            "           ReLU-1836          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1837          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1838         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1839          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1840          [-1, 128, 38, 38]             256\n",
            "           ReLU-1841          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1842          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1843         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1844          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1845          [-1, 384, 38, 38]             768\n",
            "           ReLU-1846          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1847          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1848          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1849          [-1, 192, 38, 38]             384\n",
            "           ReLU-1850          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1851          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1852          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1853          [-1, 224, 38, 38]             448\n",
            "           ReLU-1854          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1855          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1856          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1857          [-1, 256, 38, 38]             512\n",
            "           ReLU-1858          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1859          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1860          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1861          [-1, 192, 38, 38]             384\n",
            "           ReLU-1862          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1863          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1864          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1865          [-1, 192, 38, 38]             384\n",
            "           ReLU-1866          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1867          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1868          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1869          [-1, 224, 38, 38]             448\n",
            "           ReLU-1870          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1871          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1872          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1873          [-1, 224, 38, 38]             448\n",
            "           ReLU-1874          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1875          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1876          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1877          [-1, 256, 38, 38]             512\n",
            "           ReLU-1878          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1879          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1880         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1881          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1882          [-1, 128, 38, 38]             256\n",
            "           ReLU-1883          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1884          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1885         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1886          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1887          [-1, 384, 38, 38]             768\n",
            "           ReLU-1888          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1889          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1890          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1891          [-1, 192, 38, 38]             384\n",
            "           ReLU-1892          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1893          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1894          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1895          [-1, 224, 38, 38]             448\n",
            "           ReLU-1896          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1897          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1898          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1899          [-1, 256, 38, 38]             512\n",
            "           ReLU-1900          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1901          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1902          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1903          [-1, 192, 38, 38]             384\n",
            "           ReLU-1904          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1905          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1906          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1907          [-1, 192, 38, 38]             384\n",
            "           ReLU-1908          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1909          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1910          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1911          [-1, 224, 38, 38]             448\n",
            "           ReLU-1912          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1913          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1914          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1915          [-1, 224, 38, 38]             448\n",
            "           ReLU-1916          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1917          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1918          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1919          [-1, 256, 38, 38]             512\n",
            "           ReLU-1920          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1921          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1922         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1923          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1924          [-1, 128, 38, 38]             256\n",
            "           ReLU-1925          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1926          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1927         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1928          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1929          [-1, 384, 38, 38]             768\n",
            "           ReLU-1930          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1931          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1932          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1933          [-1, 192, 38, 38]             384\n",
            "           ReLU-1934          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1935          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1936          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1937          [-1, 224, 38, 38]             448\n",
            "           ReLU-1938          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1939          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1940          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1941          [-1, 256, 38, 38]             512\n",
            "           ReLU-1942          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1943          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1944          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1945          [-1, 192, 38, 38]             384\n",
            "           ReLU-1946          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1947          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1948          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1949          [-1, 192, 38, 38]             384\n",
            "           ReLU-1950          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1951          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1952          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1953          [-1, 224, 38, 38]             448\n",
            "           ReLU-1954          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1955          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1956          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1957          [-1, 224, 38, 38]             448\n",
            "           ReLU-1958          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1959          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1960          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1961          [-1, 256, 38, 38]             512\n",
            "           ReLU-1962          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1963          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-1964         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1965          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-1966          [-1, 128, 38, 38]             256\n",
            "           ReLU-1967          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-1968          [-1, 128, 38, 38]               0\n",
            "     InceptionB-1969         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-1970          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-1971          [-1, 384, 38, 38]             768\n",
            "           ReLU-1972          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-1973          [-1, 384, 38, 38]               0\n",
            "         Conv2d-1974          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1975          [-1, 192, 38, 38]             384\n",
            "           ReLU-1976          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1977          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1978          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1979          [-1, 224, 38, 38]             448\n",
            "           ReLU-1980          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1981          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1982          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-1983          [-1, 256, 38, 38]             512\n",
            "           ReLU-1984          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-1985          [-1, 256, 38, 38]               0\n",
            "         Conv2d-1986          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-1987          [-1, 192, 38, 38]             384\n",
            "           ReLU-1988          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1989          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1990          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-1991          [-1, 192, 38, 38]             384\n",
            "           ReLU-1992          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-1993          [-1, 192, 38, 38]               0\n",
            "         Conv2d-1994          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-1995          [-1, 224, 38, 38]             448\n",
            "           ReLU-1996          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-1997          [-1, 224, 38, 38]               0\n",
            "         Conv2d-1998          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-1999          [-1, 224, 38, 38]             448\n",
            "           ReLU-2000          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-2001          [-1, 224, 38, 38]               0\n",
            "         Conv2d-2002          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-2003          [-1, 256, 38, 38]             512\n",
            "           ReLU-2004          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-2005          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-2006         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-2007          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-2008          [-1, 128, 38, 38]             256\n",
            "           ReLU-2009          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-2010          [-1, 128, 38, 38]               0\n",
            "     InceptionB-2011         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-2012          [-1, 384, 38, 38]         393,216\n",
            "    BatchNorm2d-2013          [-1, 384, 38, 38]             768\n",
            "           ReLU-2014          [-1, 384, 38, 38]               0\n",
            "    BasicConv2d-2015          [-1, 384, 38, 38]               0\n",
            "         Conv2d-2016          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-2017          [-1, 192, 38, 38]             384\n",
            "           ReLU-2018          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-2019          [-1, 192, 38, 38]               0\n",
            "         Conv2d-2020          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-2021          [-1, 224, 38, 38]             448\n",
            "           ReLU-2022          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-2023          [-1, 224, 38, 38]               0\n",
            "         Conv2d-2024          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-2025          [-1, 256, 38, 38]             512\n",
            "           ReLU-2026          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-2027          [-1, 256, 38, 38]               0\n",
            "         Conv2d-2028          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-2029          [-1, 192, 38, 38]             384\n",
            "           ReLU-2030          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-2031          [-1, 192, 38, 38]               0\n",
            "         Conv2d-2032          [-1, 192, 38, 38]         258,048\n",
            "    BatchNorm2d-2033          [-1, 192, 38, 38]             384\n",
            "           ReLU-2034          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-2035          [-1, 192, 38, 38]               0\n",
            "         Conv2d-2036          [-1, 224, 38, 38]         301,056\n",
            "    BatchNorm2d-2037          [-1, 224, 38, 38]             448\n",
            "           ReLU-2038          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-2039          [-1, 224, 38, 38]               0\n",
            "         Conv2d-2040          [-1, 224, 38, 38]         351,232\n",
            "    BatchNorm2d-2041          [-1, 224, 38, 38]             448\n",
            "           ReLU-2042          [-1, 224, 38, 38]               0\n",
            "    BasicConv2d-2043          [-1, 224, 38, 38]               0\n",
            "         Conv2d-2044          [-1, 256, 38, 38]         401,408\n",
            "    BatchNorm2d-2045          [-1, 256, 38, 38]             512\n",
            "           ReLU-2046          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-2047          [-1, 256, 38, 38]               0\n",
            "      AvgPool2d-2048         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-2049          [-1, 128, 38, 38]         131,072\n",
            "    BatchNorm2d-2050          [-1, 128, 38, 38]             256\n",
            "           ReLU-2051          [-1, 128, 38, 38]               0\n",
            "    BasicConv2d-2052          [-1, 128, 38, 38]               0\n",
            "     InceptionB-2053         [-1, 1024, 38, 38]               0\n",
            "         Conv2d-2054          [-1, 192, 38, 38]         196,608\n",
            "    BatchNorm2d-2055          [-1, 192, 38, 38]             384\n",
            "           ReLU-2056          [-1, 192, 38, 38]               0\n",
            "    BasicConv2d-2057          [-1, 192, 38, 38]               0\n",
            "         Conv2d-2058          [-1, 192, 18, 18]         331,776\n",
            "    BatchNorm2d-2059          [-1, 192, 18, 18]             384\n",
            "           ReLU-2060          [-1, 192, 18, 18]               0\n",
            "    BasicConv2d-2061          [-1, 192, 18, 18]               0\n",
            "         Conv2d-2062          [-1, 256, 38, 38]         262,144\n",
            "    BatchNorm2d-2063          [-1, 256, 38, 38]             512\n",
            "           ReLU-2064          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-2065          [-1, 256, 38, 38]               0\n",
            "         Conv2d-2066          [-1, 256, 38, 38]         458,752\n",
            "    BatchNorm2d-2067          [-1, 256, 38, 38]             512\n",
            "           ReLU-2068          [-1, 256, 38, 38]               0\n",
            "    BasicConv2d-2069          [-1, 256, 38, 38]               0\n",
            "         Conv2d-2070          [-1, 320, 38, 38]         573,440\n",
            "    BatchNorm2d-2071          [-1, 320, 38, 38]             640\n",
            "           ReLU-2072          [-1, 320, 38, 38]               0\n",
            "    BasicConv2d-2073          [-1, 320, 38, 38]               0\n",
            "         Conv2d-2074          [-1, 320, 18, 18]         921,600\n",
            "    BatchNorm2d-2075          [-1, 320, 18, 18]             640\n",
            "           ReLU-2076          [-1, 320, 18, 18]               0\n",
            "    BasicConv2d-2077          [-1, 320, 18, 18]               0\n",
            "      MaxPool2d-2078         [-1, 1024, 18, 18]               0\n",
            "     ReductionB-2079         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2080          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2081          [-1, 256, 18, 18]             512\n",
            "           ReLU-2082          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2083          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2084          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2085          [-1, 384, 18, 18]             768\n",
            "           ReLU-2086          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2087          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2088          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2089          [-1, 256, 18, 18]             512\n",
            "           ReLU-2090          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2091          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2092          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2093          [-1, 256, 18, 18]             512\n",
            "           ReLU-2094          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2095          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2096          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2097          [-1, 384, 18, 18]             768\n",
            "           ReLU-2098          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2099          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2100          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-2101          [-1, 448, 18, 18]             896\n",
            "           ReLU-2102          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-2103          [-1, 448, 18, 18]               0\n",
            "         Conv2d-2104          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-2105          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-2106          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-2107          [-1, 512, 18, 18]               0\n",
            "         Conv2d-2108          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2109          [-1, 256, 18, 18]             512\n",
            "           ReLU-2110          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2111          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2112          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2113          [-1, 256, 18, 18]             512\n",
            "           ReLU-2114          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2115          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-2116         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2117          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2118          [-1, 256, 18, 18]             512\n",
            "           ReLU-2119          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2120          [-1, 256, 18, 18]               0\n",
            "     InceptionC-2121         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2122          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2123          [-1, 256, 18, 18]             512\n",
            "           ReLU-2124          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2125          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2126          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2127          [-1, 384, 18, 18]             768\n",
            "           ReLU-2128          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2129          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2130          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2131          [-1, 256, 18, 18]             512\n",
            "           ReLU-2132          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2133          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2134          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2135          [-1, 256, 18, 18]             512\n",
            "           ReLU-2136          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2137          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2138          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2139          [-1, 384, 18, 18]             768\n",
            "           ReLU-2140          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2141          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2142          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-2143          [-1, 448, 18, 18]             896\n",
            "           ReLU-2144          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-2145          [-1, 448, 18, 18]               0\n",
            "         Conv2d-2146          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-2147          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-2148          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-2149          [-1, 512, 18, 18]               0\n",
            "         Conv2d-2150          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2151          [-1, 256, 18, 18]             512\n",
            "           ReLU-2152          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2153          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2154          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2155          [-1, 256, 18, 18]             512\n",
            "           ReLU-2156          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2157          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-2158         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2159          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2160          [-1, 256, 18, 18]             512\n",
            "           ReLU-2161          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2162          [-1, 256, 18, 18]               0\n",
            "     InceptionC-2163         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2164          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2165          [-1, 256, 18, 18]             512\n",
            "           ReLU-2166          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2167          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2168          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2169          [-1, 384, 18, 18]             768\n",
            "           ReLU-2170          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2171          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2172          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2173          [-1, 256, 18, 18]             512\n",
            "           ReLU-2174          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2175          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2176          [-1, 256, 18, 18]         294,912\n",
            "    BatchNorm2d-2177          [-1, 256, 18, 18]             512\n",
            "           ReLU-2178          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2179          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2180          [-1, 384, 18, 18]         589,824\n",
            "    BatchNorm2d-2181          [-1, 384, 18, 18]             768\n",
            "           ReLU-2182          [-1, 384, 18, 18]               0\n",
            "    BasicConv2d-2183          [-1, 384, 18, 18]               0\n",
            "         Conv2d-2184          [-1, 448, 18, 18]         516,096\n",
            "    BatchNorm2d-2185          [-1, 448, 18, 18]             896\n",
            "           ReLU-2186          [-1, 448, 18, 18]               0\n",
            "    BasicConv2d-2187          [-1, 448, 18, 18]               0\n",
            "         Conv2d-2188          [-1, 512, 18, 18]         688,128\n",
            "    BatchNorm2d-2189          [-1, 512, 18, 18]           1,024\n",
            "           ReLU-2190          [-1, 512, 18, 18]               0\n",
            "    BasicConv2d-2191          [-1, 512, 18, 18]               0\n",
            "         Conv2d-2192          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2193          [-1, 256, 18, 18]             512\n",
            "           ReLU-2194          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2195          [-1, 256, 18, 18]               0\n",
            "         Conv2d-2196          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2197          [-1, 256, 18, 18]             512\n",
            "           ReLU-2198          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2199          [-1, 256, 18, 18]               0\n",
            "      AvgPool2d-2200         [-1, 1536, 18, 18]               0\n",
            "         Conv2d-2201          [-1, 256, 18, 18]         393,216\n",
            "    BatchNorm2d-2202          [-1, 256, 18, 18]             512\n",
            "           ReLU-2203          [-1, 256, 18, 18]               0\n",
            "    BasicConv2d-2204          [-1, 256, 18, 18]               0\n",
            "     InceptionC-2205         [-1, 1536, 18, 18]               0\n",
            "AdaptiveAvgPool2d-2206           [-1, 1536, 1, 1]               0\n",
            "         Linear-2207                    [-1, 1]           1,537\n",
            " TH_InceptionV4-2208                    [-1, 6]               0\n",
            "================================================================\n",
            "Total params: 160,830,540\n",
            "Trainable params: 160,830,540\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 4.69\n",
            "Forward/backward pass size (MB): 7528.67\n",
            "Params size (MB): 613.52\n",
            "Estimated Total Size (MB): 8146.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, IMG_SIZE, IMG_SIZE), device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-vn0X8kC1r1",
        "outputId": "a130ae1f-3562-46ee-de8e-0e8b257893d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:33<00:00,  5.17s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.29s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.505095, val loss: 0.512960, accuracy: 0.85,cls_acc : {'class_1': 0.8760416507720947, 'class_2': 0.8381944894790649, 'class_3': 0.8649305701255798, 'class_4': 0.8350694179534912, 'class_5': 0.8350694179534912, 'class_6': 0.8440971374511719}, time: 1.9879 min\n",
            "Epoch 1/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:28<00:00,  4.90s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.23s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.305233, val loss: 0.521521, accuracy: 0.85,cls_acc : {'class_1': 0.904513955116272, 'class_2': 0.8381944894790649, 'class_3': 0.8701388835906982, 'class_4': 0.8350694179534912, 'class_5': 0.8319444060325623, 'class_6': 0.8118056058883667}, time: 1.8981 min\n",
            "Epoch 2/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:24<00:00,  4.71s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.256719, val loss: 0.442336, accuracy: 0.80,cls_acc : {'class_1': 0.90625, 'class_2': 0.8416666984558105, 'class_3': 0.8899306058883667, 'class_4': 0.8267361521720886, 'class_5': 0.6579861044883728, 'class_6': 0.6684027910232544}, time: 1.8242 min\n",
            "Epoch 3/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.227550, val loss: 0.439483, accuracy: 0.88,cls_acc : {'class_1': 0.9947916865348816, 'class_2': 0.887499988079071, 'class_3': 0.9680556058883667, 'class_4': 0.805555522441864, 'class_5': 0.8166667222976685, 'class_6': 0.800694465637207}, time: 1.7588 min\n",
            "Epoch 4/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.65s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.05s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.207016, val loss: 0.375702, accuracy: 0.89,cls_acc : {'class_1': 0.9947916865348816, 'class_2': 0.9215278029441833, 'class_3': 0.9628472328186035, 'class_4': 0.810763955116272, 'class_5': 0.8368055820465088, 'class_6': 0.8354166746139526}, time: 1.8060 min\n",
            "Epoch 5/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.63s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.12s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.197561, val loss: 0.372576, accuracy: 0.89,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9291666746139526, 'class_3': 0.9354166984558105, 'class_4': 0.78125, 'class_5': 0.8392361402511597, 'class_6': 0.8329861164093018}, time: 1.8074 min\n",
            "Epoch 6/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.56s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.18s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.179312, val loss: 0.318704, accuracy: 0.90,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9378471374511719, 'class_3': 0.9569444060325623, 'class_4': 0.8565971851348877, 'class_5': 0.8246527910232544, 'class_6': 0.8163194060325623}, time: 1.7915 min\n",
            "Epoch 7/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.59s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.167861, val loss: 0.247239, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9447916746139526, 'class_3': 0.9659723043441772, 'class_4': 0.9041666984558105, 'class_5': 0.8305556178092957, 'class_6': 0.7986111640930176}, time: 1.7853 min\n",
            "Epoch 8/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.59s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.161251, val loss: 0.284297, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9392361044883728, 'class_3': 0.9840278625488281, 'class_4': 0.8777777552604675, 'class_5': 0.8385416865348816, 'class_6': 0.8302083015441895}, time: 1.7766 min\n",
            "Epoch 9/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.147973, val loss: 0.333465, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.949999988079071, 'class_3': 0.9600694179534912, 'class_4': 0.8701388835906982, 'class_5': 0.8326388597488403, 'class_6': 0.8465278148651123}, time: 1.7282 min\n",
            "Epoch 10/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.13s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.140147, val loss: 0.288516, accuracy: 0.90,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9427083730697632, 'class_3': 0.9840278029441833, 'class_4': 0.8829861879348755, 'class_5': 0.8128472566604614, 'class_6': 0.7760416865348816}, time: 1.7814 min\n",
            "Epoch 11/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:25<00:00,  4.78s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.18s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.135756, val loss: 0.341097, accuracy: 0.90,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9447916746139526, 'class_3': 0.9840278029441833, 'class_4': 0.8815972208976746, 'class_5': 0.8090277910232544, 'class_6': 0.8041666746139526}, time: 1.8568 min\n",
            "Epoch 12/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.56s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.08s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.133062, val loss: 0.226402, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9465277194976807, 'class_3': 0.9697916507720947, 'class_4': 0.9003472328186035, 'class_5': 0.8309027552604675, 'class_6': 0.8045139312744141}, time: 1.7844 min\n",
            "Epoch 13/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.14s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.129074, val loss: 0.476258, accuracy: 0.89,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.949999988079071, 'class_3': 0.9802083373069763, 'class_4': 0.7378472089767456, 'class_5': 0.816319465637207, 'class_6': 0.8559028506278992}, time: 1.7809 min\n",
            "Epoch 14/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.66s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.06s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.128127, val loss: 0.285269, accuracy: 0.90,cls_acc : {'class_1': 0.9982638359069824, 'class_2': 0.9586805701255798, 'class_3': 0.9802083373069763, 'class_4': 0.8784722685813904, 'class_5': 0.7972222566604614, 'class_6': 0.8131945133209229}, time: 1.8088 min\n",
            "Epoch 15/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.55s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.123864, val loss: 0.210804, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9590277671813965, 'class_3': 0.9805556535720825, 'class_4': 0.920138955116272, 'class_5': 0.7996528148651123, 'class_6': 0.7864583730697632}, time: 1.7679 min\n",
            "Epoch 16/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.62s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.116321, val loss: 0.282073, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9552083015441895, 'class_3': 0.9857639670372009, 'class_4': 0.8791667222976685, 'class_5': 0.8156250715255737, 'class_6': 0.8177083730697632}, time: 1.7880 min\n",
            "Epoch 17/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.65s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.04s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.116257, val loss: 0.208709, accuracy: 0.92,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9590277671813965, 'class_3': 0.9822916984558105, 'class_4': 0.9041666984558105, 'class_5': 0.8277778625488281, 'class_6': 0.8444444537162781}, time: 1.8049 min\n",
            "Epoch 18/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.110994, val loss: 0.206484, accuracy: 0.92,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9659721851348877, 'class_3': 0.9819445013999939, 'class_4': 0.9156250357627869, 'class_5': 0.8194444179534912, 'class_6': 0.8451389074325562}, time: 1.7598 min\n",
            "Epoch 19/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.106845, val loss: 0.247568, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9586805105209351, 'class_3': 0.9680556058883667, 'class_4': 0.9173611402511597, 'class_5': 0.8222222328186035, 'class_6': 0.8062500357627869}, time: 1.7709 min\n",
            "Epoch 20/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.04s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.107094, val loss: 0.203988, accuracy: 0.92,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9559027552604675, 'class_3': 0.9892361164093018, 'class_4': 0.9135416746139526, 'class_5': 0.8336805105209351, 'class_6': 0.8350694179534912}, time: 1.7424 min\n",
            "Epoch 21/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.102779, val loss: 0.229781, accuracy: 0.92,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9538194537162781, 'class_3': 0.9892361164093018, 'class_4': 0.9104167222976685, 'class_5': 0.8277778029441833, 'class_6': 0.8409723043441772}, time: 1.7654 min\n",
            "Epoch 22/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.00s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.099205, val loss: 0.249160, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9607639312744141, 'class_3': 0.9798611998558044, 'class_4': 0.904513955116272, 'class_5': 0.8149306178092957, 'class_6': 0.8149306178092957}, time: 1.7341 min\n",
            "Epoch 23/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.78s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.099565, val loss: 0.242301, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9572917222976685, 'class_3': 0.9875000715255737, 'class_4': 0.9038195013999939, 'class_5': 0.8201389312744141, 'class_6': 0.8201388716697693}, time: 1.7073 min\n",
            "Epoch 24/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.100762, val loss: 0.344311, accuracy: 0.90,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9430555105209351, 'class_3': 0.9625000357627869, 'class_4': 0.8388888835906982, 'class_5': 0.8204860687255859, 'class_6': 0.840624988079071}, time: 1.7507 min\n",
            "Epoch 25/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.94s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.102745, val loss: 0.248223, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9534722566604614, 'class_3': 0.974652886390686, 'class_4': 0.8868056535720825, 'class_5': 0.8201389312744141, 'class_6': 0.8347222208976746}, time: 1.7616 min\n",
            "Epoch 26/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.79s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model weights!\n",
            "train loss: 0.106902, val loss: 0.223412, accuracy: 0.91,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9572917222976685, 'class_3': 0.9892361164093018, 'class_4': 0.903124988079071, 'class_5': 0.816319465637207, 'class_6': 0.8170139193534851}, time: 1.7214 min\n",
            "Epoch 27/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.15s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.098409, val loss: 0.186003, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9746527671813965, 'class_3': 0.9892361164093018, 'class_4': 0.9243055582046509, 'class_5': 0.8177083730697632, 'class_6': 0.8510416746139526}, time: 1.7504 min\n",
            "Epoch 28/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.67s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.14s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.094719, val loss: 0.189845, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9892361164093018, 'class_4': 0.9243055582046509, 'class_5': 0.8177083730697632, 'class_6': 0.8510416746139526}, time: 1.8186 min\n",
            "Epoch 29/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.94s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.093344, val loss: 0.192584, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9892361164093018, 'class_4': 0.9243055582046509, 'class_5': 0.8142361044883728, 'class_6': 0.8545138239860535}, time: 1.7523 min\n",
            "Epoch 30/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.71s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.092571, val loss: 0.194597, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9875000715255737, 'class_4': 0.9295139312744141, 'class_5': 0.8173611164093018, 'class_6': 0.8513889312744141}, time: 1.7359 min\n",
            "Epoch 31/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.57s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.97s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.091957, val loss: 0.195799, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9875000715255737, 'class_4': 0.9295138716697693, 'class_5': 0.8190972208976746, 'class_6': 0.849652886390686}, time: 1.7725 min\n",
            "Epoch 32/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.61s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.091441, val loss: 0.196816, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9875000715255737, 'class_4': 0.9295138716697693, 'class_5': 0.8208333849906921, 'class_6': 0.8479167222976685}, time: 1.7858 min\n",
            "Epoch 33/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model weights!\n",
            "train loss: 0.090984, val loss: 0.197693, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9875000715255737, 'class_4': 0.9295139312744141, 'class_5': 0.8208333849906921, 'class_6': 0.8479167222976685}, time: 1.7550 min\n",
            "Epoch 34/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095244, val loss: 0.187128, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7303 min\n",
            "Epoch 35/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.00s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.094974, val loss: 0.187804, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7499 min\n",
            "Epoch 36/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.04s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.094717, val loss: 0.188308, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8177083730697632, 'class_6': 0.8510416746139526}, time: 1.7477 min\n",
            "Epoch 37/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.11s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.094493, val loss: 0.188745, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8177083730697632, 'class_6': 0.8510416746139526}, time: 1.7428 min\n",
            "Epoch 38/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.094293, val loss: 0.189183, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8156250715255737, 'class_6': 0.8531250357627869}, time: 1.7620 min\n",
            "Epoch 39/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.89s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model weights!\n",
            "train loss: 0.094112, val loss: 0.189568, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9750000238418579, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8156250715255737, 'class_6': 0.8531250357627869}, time: 1.7260 min\n",
            "Epoch 40/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.55s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.01s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095271, val loss: 0.186873, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7716 min\n",
            "Epoch 41/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095235, val loss: 0.187085, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7528 min\n",
            "Epoch 42/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.65s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.11s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095196, val loss: 0.187168, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.8104 min\n",
            "Epoch 43/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095157, val loss: 0.187231, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7230 min\n",
            "Epoch 44/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095120, val loss: 0.187292, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7611 min\n",
            "Epoch 45/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.58s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.25s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model weights!\n",
            "train loss: 0.095083, val loss: 0.187354, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.8073 min\n",
            "Epoch 46/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.186836, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7439 min\n",
            "Epoch 47/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187000, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7057 min\n",
            "Epoch 48/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.13s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095271, val loss: 0.187016, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7624 min\n",
            "Epoch 49/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.54s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095267, val loss: 0.187029, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7687 min\n",
            "Epoch 50/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095263, val loss: 0.187040, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7469 min\n",
            "Epoch 51/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading best model weights!\n",
            "train loss: 0.095259, val loss: 0.187042, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7379 min\n",
            "Epoch 52/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.186829, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7140 min\n",
            "Epoch 53/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.186979, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7133 min\n",
            "Epoch 54/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.187008, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.927777886390686, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7048 min\n",
            "Epoch 55/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.50s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.04s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.186996, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7583 min\n",
            "Epoch 56/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.56s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.06s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.187003, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7779 min\n",
            "Epoch 57/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095280, val loss: 0.187003, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7027 min\n",
            "Epoch 58/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.50s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.05s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187004, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7585 min\n",
            "Epoch 59/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187006, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7235 min\n",
            "Epoch 60/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187008, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7133 min\n",
            "Epoch 61/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187007, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7201 min\n",
            "Epoch 62/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187007, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7349 min\n",
            "Epoch 63/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.186998, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7472 min\n",
            "Epoch 64/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.14s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095278, val loss: 0.187001, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7577 min\n",
            "Epoch 65/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.31s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.01s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187007, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6985 min\n",
            "Epoch 66/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.07s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095279, val loss: 0.187009, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7715 min\n",
            "Epoch 67/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:24<00:00,  4.71s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.12s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095278, val loss: 0.187005, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.8308 min\n",
            "Epoch 68/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095278, val loss: 0.187008, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7302 min\n",
            "Epoch 69/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095278, val loss: 0.187014, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7341 min\n",
            "Epoch 70/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.57s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.94s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187013, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7701 min\n",
            "Epoch 71/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.97s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187016, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7255 min\n",
            "Epoch 72/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.83s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187018, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6947 min\n",
            "Epoch 73/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187013, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6936 min\n",
            "Epoch 74/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.32s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187016, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6867 min\n",
            "Epoch 75/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:16<00:00,  4.27s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6712 min\n",
            "Epoch 76/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.32s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.01s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095277, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7038 min\n",
            "Epoch 77/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.81s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095276, val loss: 0.187005, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6980 min\n",
            "Epoch 78/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095276, val loss: 0.187018, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7582 min\n",
            "Epoch 79/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.07s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095276, val loss: 0.187017, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7507 min\n",
            "Epoch 80/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.78s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095276, val loss: 0.187011, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7140 min\n",
            "Epoch 81/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.38s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187018, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7115 min\n",
            "Epoch 82/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.56s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095276, val loss: 0.187009, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7617 min\n",
            "Epoch 83/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187014, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7305 min\n",
            "Epoch 84/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.00s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187012, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7530 min\n",
            "Epoch 85/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.47s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187013, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7389 min\n",
            "Epoch 86/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.92s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187009, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7447 min\n",
            "Epoch 87/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095275, val loss: 0.187008, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7298 min\n",
            "Epoch 88/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095274, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7497 min\n",
            "Epoch 89/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.13s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095274, val loss: 0.187012, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7633 min\n",
            "Epoch 90/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095274, val loss: 0.187022, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7261 min\n",
            "Epoch 91/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.57s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095274, val loss: 0.187014, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7639 min\n",
            "Epoch 92/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.17s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095274, val loss: 0.187007, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7491 min\n",
            "Epoch 93/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.11s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095273, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7524 min\n",
            "Epoch 94/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095273, val loss: 0.187014, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7205 min\n",
            "Epoch 95/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095272, val loss: 0.187016, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7054 min\n",
            "Epoch 96/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095272, val loss: 0.187009, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7191 min\n",
            "Epoch 97/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095272, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7167 min\n",
            "Epoch 98/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095272, val loss: 0.187010, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7025 min\n",
            "Epoch 99/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095272, val loss: 0.187013, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7184 min\n",
            "Epoch 100/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095271, val loss: 0.187018, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7377 min\n",
            "Epoch 101/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095271, val loss: 0.187016, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6956 min\n",
            "Epoch 102/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095271, val loss: 0.187024, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7348 min\n",
            "Epoch 103/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.33s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.05s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095270, val loss: 0.187026, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7096 min\n",
            "Epoch 104/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.50s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095270, val loss: 0.187021, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7500 min\n",
            "Epoch 105/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.92s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095270, val loss: 0.187033, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7028 min\n",
            "Epoch 106/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.97s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095270, val loss: 0.187028, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7248 min\n",
            "Epoch 107/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095269, val loss: 0.187018, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7507 min\n",
            "Epoch 108/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.75s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095269, val loss: 0.187024, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7056 min\n",
            "Epoch 109/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095268, val loss: 0.187021, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6944 min\n",
            "Epoch 110/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.94s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095268, val loss: 0.187026, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7429 min\n",
            "Epoch 111/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095268, val loss: 0.187022, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7439 min\n",
            "Epoch 112/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.48s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.21s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095267, val loss: 0.187020, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7713 min\n",
            "Epoch 113/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.62s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.00s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095267, val loss: 0.187024, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7906 min\n",
            "Epoch 114/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.38s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.81s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095267, val loss: 0.187021, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6998 min\n",
            "Epoch 115/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.99s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095267, val loss: 0.187027, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7275 min\n",
            "Epoch 116/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.32s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.77s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095266, val loss: 0.187027, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6778 min\n",
            "Epoch 117/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.02s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095265, val loss: 0.187023, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7152 min\n",
            "Epoch 118/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:25<00:00,  4.31s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095266, val loss: 0.187027, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7609 min\n",
            "Epoch 119/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095265, val loss: 0.187031, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7141 min\n",
            "Epoch 120/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.15s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095265, val loss: 0.187032, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7439 min\n",
            "Epoch 121/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.97s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095265, val loss: 0.187027, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7313 min\n",
            "Epoch 122/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095265, val loss: 0.187031, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7000 min\n",
            "Epoch 123/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.83s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095264, val loss: 0.187032, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6906 min\n",
            "Epoch 124/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.33s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.72s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095263, val loss: 0.187039, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6758 min\n",
            "Epoch 125/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:16<00:00,  4.26s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.05s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095263, val loss: 0.187031, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6870 min\n",
            "Epoch 126/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.65s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.82s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095263, val loss: 0.187032, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7813 min\n",
            "Epoch 127/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.82s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095262, val loss: 0.187040, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7221 min\n",
            "Epoch 128/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095262, val loss: 0.187039, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7568 min\n",
            "Epoch 129/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:16<00:00,  4.24s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.06s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095261, val loss: 0.187040, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6830 min\n",
            "Epoch 130/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:22<00:00,  4.59s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095261, val loss: 0.187044, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7677 min\n",
            "Epoch 131/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095260, val loss: 0.187044, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7229 min\n",
            "Epoch 132/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.52s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.89s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095260, val loss: 0.187045, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7487 min\n",
            "Epoch 133/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095259, val loss: 0.187045, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7132 min\n",
            "Epoch 134/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.49s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.92s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095259, val loss: 0.187040, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7434 min\n",
            "Epoch 135/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.13s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095259, val loss: 0.187046, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7783 min\n",
            "Epoch 136/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.53s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095258, val loss: 0.187046, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7483 min\n",
            "Epoch 137/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095257, val loss: 0.187049, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7217 min\n",
            "Epoch 138/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.81s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095257, val loss: 0.187051, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7022 min\n",
            "Epoch 139/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.38s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.97s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095257, val loss: 0.187057, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7178 min\n",
            "Epoch 140/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095256, val loss: 0.187045, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7256 min\n",
            "Epoch 141/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095256, val loss: 0.187055, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7239 min\n",
            "Epoch 142/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.38s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095255, val loss: 0.187059, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7186 min\n",
            "Epoch 143/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095255, val loss: 0.187051, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7187 min\n",
            "Epoch 144/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.78s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095254, val loss: 0.187052, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7048 min\n",
            "Epoch 145/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095254, val loss: 0.187053, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7326 min\n",
            "Epoch 146/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.87s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095253, val loss: 0.187045, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6962 min\n",
            "Epoch 147/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095253, val loss: 0.187048, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7213 min\n",
            "Epoch 148/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.81s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095252, val loss: 0.187049, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6955 min\n",
            "Epoch 149/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.30s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.75s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095252, val loss: 0.187048, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6697 min\n",
            "Epoch 150/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.31s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.68s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095252, val loss: 0.187055, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6673 min\n",
            "Epoch 151/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:15<00:00,  4.22s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.70s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095251, val loss: 0.187051, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6412 min\n",
            "Epoch 152/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.47s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.80s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095250, val loss: 0.187060, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7245 min\n",
            "Epoch 153/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095250, val loss: 0.187056, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7082 min\n",
            "Epoch 154/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095249, val loss: 0.187058, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6954 min\n",
            "Epoch 155/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.80s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095248, val loss: 0.187053, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6878 min\n",
            "Epoch 156/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095248, val loss: 0.187062, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7051 min\n",
            "Epoch 157/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.06s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095247, val loss: 0.187062, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7181 min\n",
            "Epoch 158/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095247, val loss: 0.187066, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7055 min\n",
            "Epoch 159/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.63s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095246, val loss: 0.187069, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7936 min\n",
            "Epoch 160/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.73s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095246, val loss: 0.187062, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6797 min\n",
            "Epoch 161/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.30s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  4.00s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095245, val loss: 0.187069, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6952 min\n",
            "Epoch 162/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095244, val loss: 0.187067, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6941 min\n",
            "Epoch 163/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.34s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095244, val loss: 0.187072, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6911 min\n",
            "Epoch 164/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.89s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095244, val loss: 0.187071, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7312 min\n",
            "Epoch 165/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.75s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095243, val loss: 0.187069, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7014 min\n",
            "Epoch 166/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:16<00:00,  4.27s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.75s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095242, val loss: 0.187082, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6613 min\n",
            "Epoch 167/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.47s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095241, val loss: 0.187081, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7370 min\n",
            "Epoch 168/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.79s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095240, val loss: 0.187070, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7174 min\n",
            "Epoch 169/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.95s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095240, val loss: 0.187073, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7261 min\n",
            "Epoch 170/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095239, val loss: 0.187077, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7039 min\n",
            "Epoch 171/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095238, val loss: 0.187079, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6997 min\n",
            "Epoch 172/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095238, val loss: 0.187080, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7551 min\n",
            "Epoch 173/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095237, val loss: 0.187081, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7296 min\n",
            "Epoch 174/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:23<00:00,  4.63s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.89s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095236, val loss: 0.187077, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7813 min\n",
            "Epoch 175/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.50s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.93s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095236, val loss: 0.187089, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7481 min\n",
            "Epoch 176/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.52s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095235, val loss: 0.187089, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7607 min\n",
            "Epoch 177/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.39s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095235, val loss: 0.187093, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7091 min\n",
            "Epoch 178/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.89s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095234, val loss: 0.187094, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7254 min\n",
            "Epoch 179/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.52s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095233, val loss: 0.187085, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7468 min\n",
            "Epoch 180/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.33s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095232, val loss: 0.187096, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6957 min\n",
            "Epoch 181/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.85s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095231, val loss: 0.187090, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7168 min\n",
            "Epoch 182/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:17<00:00,  4.28s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.90s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095231, val loss: 0.187098, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6804 min\n",
            "Epoch 183/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095230, val loss: 0.187096, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7318 min\n",
            "Epoch 184/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.37s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.94s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095229, val loss: 0.187093, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7103 min\n",
            "Epoch 185/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.40s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.03s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095228, val loss: 0.187093, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7295 min\n",
            "Epoch 186/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.10s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095228, val loss: 0.187098, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7229 min\n",
            "Epoch 187/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.50s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.15s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095227, val loss: 0.187102, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7711 min\n",
            "Epoch 188/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.41s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.84s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095226, val loss: 0.187101, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7116 min\n",
            "Epoch 189/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.43s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.77s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095225, val loss: 0.187105, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7118 min\n",
            "Epoch 190/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.36s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.86s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095225, val loss: 0.187110, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.6985 min\n",
            "Epoch 191/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:22<00:00,  3.80s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095224, val loss: 0.187107, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7110 min\n",
            "Epoch 192/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:18<00:00,  4.35s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095223, val loss: 0.187111, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7077 min\n",
            "Epoch 193/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095222, val loss: 0.187106, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7274 min\n",
            "Epoch 194/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.88s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095221, val loss: 0.187108, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7450 min\n",
            "Epoch 195/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:21<00:00,  4.51s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.98s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095220, val loss: 0.187104, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7568 min\n",
            "Epoch 196/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.46s/batch]\n",
            "100%|██████████| 6/6 [00:24<00:00,  4.09s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095220, val loss: 0.187111, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7518 min\n",
            "Epoch 197/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:20<00:00,  4.45s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.91s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095219, val loss: 0.187117, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7331 min\n",
            "Epoch 198/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.42s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.92s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095218, val loss: 0.187116, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7233 min\n",
            "Epoch 199/199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 18/18 [01:19<00:00,  4.44s/batch]\n",
            "100%|██████████| 6/6 [00:23<00:00,  3.96s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss: 0.095217, val loss: 0.187116, accuracy: 0.93,cls_acc : {'class_1': 0.9965277910232544, 'class_2': 0.9767360687255859, 'class_3': 0.9892361164093018, 'class_4': 0.9260417222976685, 'class_5': 0.8142361640930176, 'class_6': 0.8545138835906982}, time: 1.7322 min\n"
          ]
        }
      ],
      "source": [
        "traind_model, loss_hist, metric_hist, metric_cls_hist = train_val(model, device, params_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HI-p_G-C1r1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "wx_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c4f887c8c8d6fdd4a511c73e402e0744011268d8986dd2629aa484b62be6e70f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
