{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SHkim\\contactlensCC_wxpython\\wx_venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from typing import Any\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchmetrics.classification import MultilabelAccuracy, Accuracy\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
    "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
    "#######################################데이터관련 로드, 검증, 클래스정의, 데이터로더 #####################\n",
    "#image broken check\n",
    "def check_jpeg_eoi(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        f.seek(-2, 2) # 파일의 끝에서 두 바이트 전으로 이동합니다.\n",
    "        return f.read() == b'\\xff\\xd9'\n",
    "    \n",
    "\n",
    "def is_image_valid(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path) # 이미지를 열어봅니다.\n",
    "        img.verify() # verify() 메소드는 파일이 손상되었는지 확인합니다.\n",
    "        return True\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print('Invalid image: ', image_path, '\\n'+ e) # 손상된 이미지에 대한 에러 메시지를 출력합니다.\n",
    "        return False\n",
    "\n",
    "#image validation(exist and broken file)\n",
    "def validate_dataset(df, img_dir):\n",
    "    count = 0\n",
    "    df_bar = tqdm.tqdm(df.itertuples(), desc=\"validating all images\", total=len(df))\n",
    "    for rows in df_bar:\n",
    "        if os.path.isfile(img_dir+'/'+ rows.id):\n",
    "            if is_image_valid(img_dir+'/'+ rows.id) and check_jpeg_eoi(img_dir+'/'+ rows.id):\n",
    "                continue\n",
    "            else:\n",
    "                count += 1\n",
    "                df.drop(df[df['id'] == rows.id].index, inplace=True)\n",
    "        else:\n",
    "            count += 1\n",
    "            df.drop(df[df['id'] == rows.id].index, inplace=True)\n",
    "        print(\"Not founded images (Num) : \",count)\n",
    "    return df\n",
    "\n",
    "#csv에서 데이터 가져옴\n",
    "def get_data_from_csv(csv_path, train_ratio, img_dir, randoms_state=42):\n",
    "    ###### columns example : ['id', 'good', 'b_edge', 'burr', 'borken', 'b_bubble', 'etc', 'no_lens']\n",
    "    \n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = validate_dataset(df=df,img_dir=img_dir)\n",
    "    train_df , temp_df = train_test_split(df, test_size=1-train_ratio, random_state=randoms_state)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=randoms_state)\n",
    "\n",
    "\n",
    "    # 'good' 열을 데이터 프레임에서 제거 및 클래스 재정렬\n",
    "    cls_list = ['no_lens', 'etc', 'burr', 'borken', 'b_edge', 'b_bubble']\n",
    "    train_df = train_df.drop(columns=['good'])\n",
    "    train_df = train_df[['id'] + cls_list]\n",
    "    val_df = val_df.drop(columns=['good'])\n",
    "    val_df = val_df[['id'] + cls_list]\n",
    "    test_df = test_df.drop(columns=['good'])\n",
    "    test_df = test_df[['id'] + cls_list]\n",
    "\n",
    "\n",
    "    print('num of train_df',len(train_df))\n",
    "    print('num of val_df',len(val_df))\n",
    "    print('num of test_df',len(test_df))\n",
    "\n",
    "    num_cls = len(train_df.columns) - 1  # because, it is multi-label\n",
    "\n",
    "    print('number of class: ', num_cls)\n",
    "    # cls_list = list(train_df.columns)\n",
    "    # cls_list.remove('id')\n",
    "\n",
    "    print(cls_list)\n",
    "    \n",
    "    return train_df, val_df, test_df, num_cls, cls_list\n",
    "\n",
    "#데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, image_dir, num_classes, class_list, transforms=None, img_resize = False, img_dsize = (640,640)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_ids = dataframe['id'].unique() # 이미지 고유 ID\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.img_resize = img_resize\n",
    "        self.img_dsize = img_dsize\n",
    "        self.class_list = class_list\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    #데이터 길이 검증\n",
    "    def validate_data_records(self):\n",
    "        for idx, image_id in enumerate(self.image_ids):\n",
    "            records = self.df[self.df['id'] == image_id]\n",
    "            target = np.array(records[self.class_list].values).astype(np.float32)\n",
    "            if target.shape[1] != len(self.class_list):\n",
    "                print(f\"Index {idx} with image_id {image_id} has mismatched target size. Expected {len(self.class_list)}, but got {target.shape[1]}\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # 이미지 index로 아이템 불러오기\n",
    "\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['id'] == image_id]\n",
    "        \n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
    "            \n",
    "        # OpenCV가 컬러를 저장하는 방식인 BGR을 RGB로 변환\n",
    "        if self.img_resize:\n",
    "            image = cv2.resize(image, self.img_dsize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0 # 0 ~ 1로 스케일링\n",
    "\n",
    "        target = np.array(records[self.class_list].values).astype(np.float32)\n",
    "        target = target.reshape(-1)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    \n",
    "    # Find the maximum target length\n",
    "    max_len = max([len(t) for t in targets])\n",
    "    \n",
    "    # Pad each target to the maximum length\n",
    "    targets_padded = [torch.cat([torch.tensor(t), torch.zeros(max_len - len(t))]) for t in targets]\n",
    "    \n",
    "    targets = torch.stack(targets_padded, 0)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################기타####################\n",
    "def create_directory(save_path):\n",
    "    i = 1\n",
    "    while True:\n",
    "        dir_name = os.path.join('models/'+save_path+ str(i) +'/')\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "            os.makedirs(dir_name+'/result')\n",
    "            return dir_name\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################### 모델구조정의 ##########################################\n",
    "####################################### 모델구조정의 ##########################################\n",
    "####################################### 모델구조정의 ##########################################\n",
    "class TH_InceptionV4(nn.Module):\n",
    "\n",
    "    def __init__(self, k=192, l=224, m=256, n=384, num_classes=7):\n",
    "        super(TH_InceptionV4, self).__init__()\n",
    "        \n",
    "        self.stem = InceptionV4Stem(3)\n",
    "        \n",
    "        self.inceptionA1 = InceptionA(384)\n",
    "        self.inceptionA2 = InceptionA(384)\n",
    "        self.inceptionA3 = InceptionA(384)\n",
    "        self.inceptionA4 = InceptionA(384)\n",
    "        self.no_etc_output_linear = nn.Linear(384, 2)\n",
    "        \n",
    "        self.reductionA = ReductionA(384, k, l, m, n)\n",
    "        \n",
    "        self.inceptionB1 = InceptionB(1024)\n",
    "        self.inceptionB2 = InceptionB(1024)\n",
    "        self.inceptionB3 = InceptionB(1024)\n",
    "        self.inceptionB4 = InceptionB(1024)\n",
    "        self.inceptionB5 = InceptionB(1024)\n",
    "        self.inceptionB6 = InceptionB(1024)\n",
    "        self.inceptionB7 = InceptionB(1024)\n",
    "\n",
    "        self.burr_broken_output_linear = nn.Linear(1024, 2)\n",
    "        \n",
    "        self.reductionB = ReductionB(1024)\n",
    "        \n",
    "        self.inceptionC1 = InceptionC(1536)\n",
    "        self.inceptionC2 = InceptionC(1536)\n",
    "        self.inceptionC3 = InceptionC(1536)\n",
    "        \n",
    "        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(1536, 1)\n",
    "\n",
    "        # Initialize neural network weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        x = self.stem(x)\n",
    "        \n",
    "        x1 = self.inceptionA1(x)\n",
    "        x2 = self.inceptionA2(x1)\n",
    "        x3 = self.inceptionA3(x2)\n",
    "        x4 = self.inceptionA4(x3)\n",
    "\n",
    "        #no_lens와 etc 클래스 output\n",
    "        no_etc_output = self.global_average_pooling(x4)\n",
    "        no_etc_output = torch.flatten(no_etc_output, 1)\n",
    "        no_etc_output = self.no_etc_output_linear(no_etc_output)\n",
    "        outputs.append(no_etc_output)\n",
    "\n",
    "        x_redA = self.reductionA(x4)\n",
    "        \n",
    "        xB1 = self.inceptionB1(x_redA)\n",
    "        xB2 = self.inceptionB2(xB1)\n",
    "        xB3 = self.inceptionB3(xB2)\n",
    "        xB4 = self.inceptionB4(xB3)\n",
    "        xB5 = self.inceptionB5(xB4)\n",
    "        xB6 = self.inceptionB6(xB5)\n",
    "        xB7 = self.inceptionB7(xB6)\n",
    "\n",
    "        burr_broken_output = self.global_average_pooling(xB7)\n",
    "        burr_broken_output = torch.flatten(burr_broken_output, 1)\n",
    "        burr_broken_output = self.burr_broken_output_linear(burr_broken_output)\n",
    "        outputs.append(burr_broken_output)\n",
    "        \n",
    "        #b_edge분기 - broken에서 받음\n",
    "        x_redB = self.reductionB(xB7)\n",
    "        \n",
    "        xC1 = self.inceptionC1(x_redB)\n",
    "        xC2 = self.inceptionC2(xC1)\n",
    "        xC3 = self.inceptionC3(xC2)\n",
    "\n",
    "        b_edge_output = self.global_average_pooling(xC3)\n",
    "        b_edge_output = torch.flatten(b_edge_output, 1)\n",
    "        b_edge_output = self.linear(b_edge_output)\n",
    "        outputs.append(b_edge_output)\n",
    "\n",
    "        #b_bubble분기 - 완전히 따로 내려옴\n",
    "        x_redA_2 = self.reductionA(x4)\n",
    "        \n",
    "        xB1_2 = self.inceptionB1(x_redA_2)\n",
    "        xB2_2 = self.inceptionB2(xB1_2)\n",
    "        xB3_2 = self.inceptionB3(xB2_2)\n",
    "        xB4_2 = self.inceptionB4(xB3_2)\n",
    "        xB5_2 = self.inceptionB5(xB4_2)\n",
    "        xB6_2 = self.inceptionB6(xB5_2)\n",
    "        xB7_2 = self.inceptionB7(xB6_2)\n",
    "\n",
    "        x_redB_2 = self.reductionB(xB7_2)\n",
    "        \n",
    "        xC1_2 = self.inceptionC1(x_redB_2)\n",
    "        xC2_2 = self.inceptionC2(xC1_2)\n",
    "        xC3_2 = self.inceptionC3(xC2_2)\n",
    "        \n",
    "        b_bubble_output = self.global_average_pooling(xC3_2)\n",
    "        b_bubble_output = torch.flatten(b_bubble_output, 1)\n",
    "        b_bubble_output = self.linear(b_bubble_output)\n",
    "        outputs.append(b_bubble_output)\n",
    "\n",
    "        final_outputs = torch.cat(outputs, dim=1)\n",
    "        return final_outputs\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                stddev = float(module.stddev) if hasattr(module, \"stddev\") else 0.1\n",
    "                torch.nn.init.trunc_normal_(module.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class InceptionV4Stem(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(InceptionV4Stem, self).__init__()\n",
    "        self.conv2d_1a_3x3 = BasicConv2d(in_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
    "\n",
    "        self.conv2d_2a_3x3 = BasicConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv2d_2b_3x3 = BasicConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "        self.mixed_3a_branch_0 = nn.MaxPool2d((3, 3), (2, 2))\n",
    "        self.mixed_3a_branch_1 = BasicConv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
    "\n",
    "        self.mixed_4a_branch_0 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
    "        )\n",
    "        self.mixed_4a_branch_1 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
    "            BasicConv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0))\n",
    "        )\n",
    "\n",
    "        self.mixed_5a_branch_0 = BasicConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
    "        self.mixed_5a_branch_1 = nn.MaxPool2d((3, 3), (2, 2))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.conv2d_1a_3x3(x)\n",
    "        out = self.conv2d_2a_3x3(out)\n",
    "        out = self.conv2d_2b_3x3(out)\n",
    "\n",
    "        mixed_3a_branch_0 = self.mixed_3a_branch_0(out)\n",
    "        mixed_3a_branch_1 = self.mixed_3a_branch_1(out)\n",
    "        mixed_3a_out = torch.cat([mixed_3a_branch_0, mixed_3a_branch_1], 1)\n",
    "\n",
    "        mixed_4a_branch_0 = self.mixed_4a_branch_0(mixed_3a_out)\n",
    "        mixed_4a_branch_1 = self.mixed_4a_branch_1(mixed_3a_out)\n",
    "        mixed_4a_out = torch.cat([mixed_4a_branch_0, mixed_4a_branch_1], 1)\n",
    "\n",
    "        mixed_5a_branch_0 = self.mixed_5a_branch_0(mixed_4a_out)\n",
    "        mixed_5a_branch_1 = self.mixed_5a_branch_1(mixed_4a_out)\n",
    "        mixed_5a_out = torch.cat([mixed_5a_branch_0, mixed_5a_branch_1], 1)\n",
    "\n",
    "        return mixed_5a_out\n",
    "\n",
    "class InceptionV4ResNetStem(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(InceptionV4ResNetStem, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 32, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
    "            BasicConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.MaxPool2d((3, 3), (2, 2)),\n",
    "            BasicConv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0)),\n",
    "            nn.MaxPool2d((3, 3), (2, 2)),\n",
    "        )\n",
    "        self.branch_0 = BasicConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            BasicConv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            BasicConv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            BasicConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        )\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        branch_0 = self.branch_0(features)\n",
    "        branch_1 = self.branch_1(features)\n",
    "        branch_2 = self.branch_2(features)\n",
    "        branch_3 = self.branch_3(features)\n",
    "\n",
    "        out = torch.cat([branch_0, branch_1, branch_2, branch_3], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch_0 = BasicConv2d(in_channels, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            BasicConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        )\n",
    "        self.brance_3 = nn.Sequential(\n",
    "            nn.AvgPool2d((3, 3), (1, 1), (1, 1), count_include_pad=False),\n",
    "            BasicConv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch_0 = self.branch_0(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "        branch_2 = self.branch_2(x)\n",
    "        brance_3 = self.brance_3(x)\n",
    "\n",
    "        out = torch.cat([branch_0, branch_1, branch_2, brance_3], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ReductionA(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            k: int,\n",
    "            l: int,\n",
    "            m: int,\n",
    "            n: int,\n",
    "    ) -> None:\n",
    "        super(ReductionA, self).__init__()\n",
    "        self.branch_0 = BasicConv2d(in_channels, n, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0))\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, k, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(k, l, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            BasicConv2d(l, m, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
    "        )\n",
    "        self.branch_2 = nn.MaxPool2d((3, 3), (2, 2))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch_0 = self.branch_0(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "        branch_2 = self.branch_2(x)\n",
    "\n",
    "        out = torch.cat([branch_0, branch_1, branch_2], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(InceptionB, self).__init__()\n",
    "        self.branch_0 = BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
    "            BasicConv2d(224, 256, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
    "            BasicConv2d(224, 224, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
    "            BasicConv2d(224, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
    "        )\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            nn.AvgPool2d((3, 3), (1, 1), (1, 1), count_include_pad=False),\n",
    "            BasicConv2d(in_channels, 128, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch_0 = self.branch_0(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "        branch_2 = self.branch_2(x)\n",
    "        branch_3 = self.branch_3(x)\n",
    "\n",
    "        out = torch.cat([branch_0, branch_1, branch_2, branch_3], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ReductionB(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(ReductionB, self).__init__()\n",
    "        self.branch_0 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
    "        )\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(256, 256, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3)),\n",
    "            BasicConv2d(256, 320, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0)),\n",
    "            BasicConv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(0, 0)),\n",
    "        )\n",
    "        self.branch_2 = nn.MaxPool2d((3, 3), (2, 2))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch_0 = self.branch_0(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "        branch_2 = self.branch_2(x)\n",
    "\n",
    "        out = torch.cat([branch_0, branch_1, branch_2], 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "    ) -> None:\n",
    "        super(InceptionC, self).__init__()\n",
    "        self.branch_0 = BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "\n",
    "        self.branch_1 = BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.branch_1_1 = BasicConv2d(384, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
    "        self.branch_1_2 = BasicConv2d(384, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "            BasicConv2d(384, 448, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            BasicConv2d(448, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n",
    "        )\n",
    "        self.branch_2_1 = BasicConv2d(512, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
    "        self.branch_2_2 = BasicConv2d(512, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            nn.AvgPool2d((3, 3), (1, 1), (1, 1)),\n",
    "            BasicConv2d(in_channels, 256, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        branch_0 = self.branch_0(x)\n",
    "        branch_1 = self.branch_1(x)\n",
    "\n",
    "        branch_1_1 = self.branch_1_1(branch_1)\n",
    "        branch_1_2 = self.branch_1_2(branch_1)\n",
    "        x1 = torch.cat([branch_1_1, branch_1_2], 1)\n",
    "\n",
    "        branch_2 = self.branch_2(x)\n",
    "        branch_2_1 = self.branch_2_1(branch_2)\n",
    "        branch_2_2 = self.branch_2_2(branch_2)\n",
    "        x2 = torch.cat([branch_2_1, branch_2_2], 1)\n",
    "\n",
    "        x3 = self.branch_3(x)\n",
    "\n",
    "        out = torch.cat([branch_0, x1, x2, x3], 1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## 학습 매커니즘 설정 #####################################\n",
    "########################################## 학습 매커니즘 설정 #####################################\n",
    "########################################## 학습 매커니즘 설정 #####################################\n",
    "\n",
    "# get current lr\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# function to start training\n",
    "def train_val(model, device, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params['loss_func']\n",
    "    opt=params['optimizer']\n",
    "    train_dl=params['train_dl']\n",
    "    val_dl=params['val_dl']\n",
    "    sanity_check=params['sanity_check']\n",
    "    lr_scheduler=params['lr_scheduler']\n",
    "    path2weights=params['path2weights']\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "    metric_cls_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        current_lr = get_lr(opt)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric,train_cls_metric = loss_epoch_multi_output(model, device, loss_func, train_dl, sanity_check, opt)\n",
    "        \n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric.item())\n",
    "        \n",
    "        metric_cls_history['train'].append(train_cls_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric,val_cls_metric = loss_epoch_multi_output(model, device, loss_func, val_dl, sanity_check)\n",
    "        \n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric.item())\n",
    "        \n",
    "        metric_cls_history['val'].append(val_cls_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "        # model.module is the original model before DataParallel\n",
    "            torch.save(model.module.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
    "        else:\n",
    "            torch.save(model.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
    "\n",
    "        # torch.save(model.module.state_dict(), path2weights + f'{epoch}_weight.pt')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "        \n",
    "        print(f'train loss: {train_loss:.6f}, val loss: {val_loss:.6f}, accuracy: {val_metric:.2f},cls_acc : {val_cls_metric}, time: {(time.time()-start_time)/60:.4f} min')\n",
    "        lossdf = pd.DataFrame(loss_history)\n",
    "        accdf = pd.DataFrame(metric_history)\n",
    "        acc_clsdf = pd.DataFrame(metric_cls_history)\n",
    "\n",
    "        lossdf.to_csv(path2weights + 'result/loss.csv')\n",
    "        accdf.to_csv(path2weights + 'result/acc.csv')\n",
    "        acc_clsdf.to_csv(path2weights + 'result/cls_acc.csv')\n",
    "        \n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history, metric_cls_history\n",
    "\n",
    "def metric_batch_multi_output(output, target, device):\n",
    "    # output: [batch_size, num_classes], target: [batch_size, num_classes]\n",
    "    \n",
    "    pred = output.sigmoid() >= 0.5\n",
    "    \n",
    "    num_classes = target.shape[1]\n",
    "    mla_ova = MultilabelAccuracy(num_labels=num_classes).to(device=device)\n",
    "    mla = MultilabelAccuracy(num_labels=num_classes, average=None).to(device=device)\n",
    "    \n",
    "    class_accuracies = mla(pred, target)\n",
    "    overall_accuracy = mla_ova(pred, target)\n",
    "    \n",
    "    return class_accuracies, overall_accuracy\n",
    "\n",
    "\n",
    "def loss_batch_multi_output(loss_func, output, target, device, opt=None):\n",
    "    # output: [batch_size, num_classes], target: [batch_size, num_classes]\n",
    "    loss_b = loss_func(output, target)\n",
    "    class_metric_b , metric_b = metric_batch_multi_output(output, target, device)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss_b.item(), metric_b, class_metric_b\n",
    "\n",
    "def loss_epoch_multi_output(model, device, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    running_class_metrics = torch.zeros(dataset_dl.dataset.num_classes).to(device)\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "    num_classes = dataset_dl.dataset.num_classes\n",
    "    b_count = 0\n",
    "    with tqdm.tqdm(dataset_dl, unit=\"batch\") as tepoch:\n",
    "        for xb, yb in tepoch:\n",
    "            b_count+=1\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            output = model(xb)\n",
    "\n",
    "            loss_b, metric_b, class_metric_b = loss_batch_multi_output(loss_func, output, yb, device, opt)\n",
    "\n",
    "            running_loss += loss_b\n",
    "\n",
    "            if metric_b is not None:\n",
    "                running_metric += metric_b\n",
    "            \n",
    "            if class_metric_b is not None:\n",
    "                running_class_metrics += class_metric_b\n",
    "\n",
    "            if sanity_check is True:\n",
    "                break\n",
    "\n",
    "    loss = running_loss / b_count\n",
    "    metric = running_metric / b_count # 수정된 부분\n",
    "    class_metrics = {f'class_{i+1}': (running_class_metrics[i] / b_count).item() for i in range(num_classes)}\n",
    "    return loss, metric, class_metrics\n",
    "\n",
    "# check the directory to save weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except os.OSerror:\n",
    "        print('Error')\n",
    "createFolder('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.reset_max_memory_allocated(device=None)\n",
    "torch.cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# 여기는 전체 데이터셋에서 샘플만 추출하는 과정임 #################################\n",
    "\n",
    "# data_df = pd.read_csv('dataset.csv')\n",
    "# data_df.sum()\n",
    "\n",
    "# categories = ['good', 'b_edge', 'burr', 'borken', 'b_bubble', 'etc', 'no_lens']\n",
    "\n",
    "# resampled_dfs = []\n",
    "# used_indices = set()  # 이미 사용된 인덱스를 추적합니다.\n",
    "\n",
    "# for category in categories:\n",
    "#     # 이미 선택된 샘플을 제외한 데이터프레임을 생성합니다.\n",
    "#     available_data = data_df.drop(index=used_indices)\n",
    "    \n",
    "#     # 각 카테고리별로 데이터프레임을 필터링합니다.\n",
    "#     category_df = available_data[available_data[category] == 1] # 카테고리별로 적절한 필터링 조건을 적용해야 합니다.\n",
    "\n",
    "#     # 해당 카테고리에서 사용 가능한 샘플 수가 900개를 초과하는지 확인합니다.\n",
    "#     if len(category_df) > 900:\n",
    "#         category_df = category_df.sample(n=400, random_state=42) # 무작위 샘플 선택\n",
    "#         used_indices.update(category_df.index)  # 선택된 인덱스를 사용된 인덱스 집합에 추가합니다.\n",
    "#     else:\n",
    "#         used_indices.update(category_df.index)  # 남은 모든 샘플 사용\n",
    "        \n",
    "#     resampled_dfs.append(category_df)\n",
    "\n",
    "# # 모든 카테고리의 데이터프레임을 하나로 병합합니다.\n",
    "# balanced_df = pd.concat(resampled_dfs, ignore_index=True)\n",
    "\n",
    "# # 결과를 확인합니다.\n",
    "# print(balanced_df.sum())\n",
    "\n",
    "# balanced_df.to_csv('TH_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 이미지 수 :  2800\n",
      "####################### 라벨링 벨런스 ######################\n",
      "id          None_20230404100000_3_R_1.jpgNone_202304131430...\n",
      "good                                                      400\n",
      "b_edge                                                    483\n",
      "burr                                                      411\n",
      "borken                                                    431\n",
      "b_bubble                                                  427\n",
      "etc                                                       423\n",
      "no_lens                                                   400\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "balanced_df = pd.read_csv('TH_dataset.csv')\n",
    "print('전체 이미지 수 : ',len(balanced_df))\n",
    "print('####################### 라벨링 벨런스 ######################')\n",
    "print(balanced_df.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = TH_InceptionV4()\n",
    "\n",
    "################## gpu사용처리 ######################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.reset_max_memory_allocated(device=None)\n",
    "torch.cuda.empty_cache()\n",
    "num_device = torch.cuda.device_count()\n",
    "print(device)\n",
    "device_idx = []\n",
    "for i in range(num_device):\n",
    "    if torch.cuda.get_device_name(i) == \"NVIDIA DGX Display\":\n",
    "        print(f\"Device is not using : {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        device_idx.append(i)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\",num_device, \"GPUs!\")\n",
    "    if torch.cuda.device_count() > 4: #for GCT\n",
    "        model=model.to('cuda:0')\n",
    "        model = nn.DataParallel(model, device_ids=device_idx)\n",
    "    else:\n",
    "        model = model.to(device=device)\n",
    "        model = nn.DataParallel(model)\n",
    "else:\n",
    "    model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'TH_dataset.csv'\n",
    "img_dir = './data/images2/'\n",
    "train_ratio = 0.6\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 6\n",
    "EPOCH = 200\n",
    "train_name = create_directory('TH_gnet4_')\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validating all images: 100%|██████████| 2800/2800 [00:00<00:00, 3014.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_df 1680\n",
      "num of val_df 560\n",
      "num of test_df 560\n",
      "number of class:  6\n",
      "['no_lens', 'etc', 'burr', 'borken', 'b_edge', 'b_bubble']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, NUM_CLS, cls_list = get_data_from_csv(csv_path=csv_path,img_dir=img_dir, train_ratio=train_ratio, randoms_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(IMG_SIZE)\n",
    "])\n",
    "\n",
    "train_set = CustomDataset(train_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list ,img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
    "train_set.transforms = transformation\n",
    "\n",
    "val_set = CustomDataset(val_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list, img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
    "val_set.transforms = transformation\n",
    "\n",
    "test_set = CustomDataset(test_df,num_classes=NUM_CLS, image_dir=img_dir, class_list= cls_list, img_resize=True, img_dsize=(IMG_SIZE,IMG_SIZE))\n",
    "test_set.transforms = transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    'num_epochs':EPOCH,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_loader,\n",
    "    'val_dl':val_loader,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':train_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 319, 319]             864\n",
      "       BatchNorm2d-2         [-1, 32, 319, 319]              64\n",
      "              ReLU-3         [-1, 32, 319, 319]               0\n",
      "       BasicConv2d-4         [-1, 32, 319, 319]               0\n",
      "            Conv2d-5         [-1, 32, 317, 317]           9,216\n",
      "       BatchNorm2d-6         [-1, 32, 317, 317]              64\n",
      "              ReLU-7         [-1, 32, 317, 317]               0\n",
      "       BasicConv2d-8         [-1, 32, 317, 317]               0\n",
      "            Conv2d-9         [-1, 64, 317, 317]          18,432\n",
      "      BatchNorm2d-10         [-1, 64, 317, 317]             128\n",
      "             ReLU-11         [-1, 64, 317, 317]               0\n",
      "      BasicConv2d-12         [-1, 64, 317, 317]               0\n",
      "        MaxPool2d-13         [-1, 64, 158, 158]               0\n",
      "           Conv2d-14         [-1, 96, 158, 158]          55,296\n",
      "      BatchNorm2d-15         [-1, 96, 158, 158]             192\n",
      "             ReLU-16         [-1, 96, 158, 158]               0\n",
      "      BasicConv2d-17         [-1, 96, 158, 158]               0\n",
      "           Conv2d-18         [-1, 64, 158, 158]          10,240\n",
      "      BatchNorm2d-19         [-1, 64, 158, 158]             128\n",
      "             ReLU-20         [-1, 64, 158, 158]               0\n",
      "      BasicConv2d-21         [-1, 64, 158, 158]               0\n",
      "           Conv2d-22         [-1, 96, 156, 156]          55,296\n",
      "      BatchNorm2d-23         [-1, 96, 156, 156]             192\n",
      "             ReLU-24         [-1, 96, 156, 156]               0\n",
      "      BasicConv2d-25         [-1, 96, 156, 156]               0\n",
      "           Conv2d-26         [-1, 64, 158, 158]          10,240\n",
      "      BatchNorm2d-27         [-1, 64, 158, 158]             128\n",
      "             ReLU-28         [-1, 64, 158, 158]               0\n",
      "      BasicConv2d-29         [-1, 64, 158, 158]               0\n",
      "           Conv2d-30         [-1, 64, 158, 158]          28,672\n",
      "      BatchNorm2d-31         [-1, 64, 158, 158]             128\n",
      "             ReLU-32         [-1, 64, 158, 158]               0\n",
      "      BasicConv2d-33         [-1, 64, 158, 158]               0\n",
      "           Conv2d-34         [-1, 64, 158, 158]          28,672\n",
      "      BatchNorm2d-35         [-1, 64, 158, 158]             128\n",
      "             ReLU-36         [-1, 64, 158, 158]               0\n",
      "      BasicConv2d-37         [-1, 64, 158, 158]               0\n",
      "           Conv2d-38         [-1, 96, 156, 156]          55,296\n",
      "      BatchNorm2d-39         [-1, 96, 156, 156]             192\n",
      "             ReLU-40         [-1, 96, 156, 156]               0\n",
      "      BasicConv2d-41         [-1, 96, 156, 156]               0\n",
      "           Conv2d-42          [-1, 192, 77, 77]         331,776\n",
      "      BatchNorm2d-43          [-1, 192, 77, 77]             384\n",
      "             ReLU-44          [-1, 192, 77, 77]               0\n",
      "      BasicConv2d-45          [-1, 192, 77, 77]               0\n",
      "        MaxPool2d-46          [-1, 192, 77, 77]               0\n",
      "  InceptionV4Stem-47          [-1, 384, 77, 77]               0\n",
      "           Conv2d-48           [-1, 96, 77, 77]          36,864\n",
      "      BatchNorm2d-49           [-1, 96, 77, 77]             192\n",
      "             ReLU-50           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-51           [-1, 96, 77, 77]               0\n",
      "           Conv2d-52           [-1, 64, 77, 77]          24,576\n",
      "      BatchNorm2d-53           [-1, 64, 77, 77]             128\n",
      "             ReLU-54           [-1, 64, 77, 77]               0\n",
      "      BasicConv2d-55           [-1, 64, 77, 77]               0\n",
      "           Conv2d-56           [-1, 96, 77, 77]          55,296\n",
      "      BatchNorm2d-57           [-1, 96, 77, 77]             192\n",
      "             ReLU-58           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-59           [-1, 96, 77, 77]               0\n",
      "           Conv2d-60           [-1, 64, 77, 77]          24,576\n",
      "      BatchNorm2d-61           [-1, 64, 77, 77]             128\n",
      "             ReLU-62           [-1, 64, 77, 77]               0\n",
      "      BasicConv2d-63           [-1, 64, 77, 77]               0\n",
      "           Conv2d-64           [-1, 96, 77, 77]          55,296\n",
      "      BatchNorm2d-65           [-1, 96, 77, 77]             192\n",
      "             ReLU-66           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-67           [-1, 96, 77, 77]               0\n",
      "           Conv2d-68           [-1, 96, 77, 77]          82,944\n",
      "      BatchNorm2d-69           [-1, 96, 77, 77]             192\n",
      "             ReLU-70           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-71           [-1, 96, 77, 77]               0\n",
      "        AvgPool2d-72          [-1, 384, 77, 77]               0\n",
      "           Conv2d-73           [-1, 96, 77, 77]          36,864\n",
      "      BatchNorm2d-74           [-1, 96, 77, 77]             192\n",
      "             ReLU-75           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-76           [-1, 96, 77, 77]               0\n",
      "       InceptionA-77          [-1, 384, 77, 77]               0\n",
      "           Conv2d-78           [-1, 96, 77, 77]          36,864\n",
      "      BatchNorm2d-79           [-1, 96, 77, 77]             192\n",
      "             ReLU-80           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-81           [-1, 96, 77, 77]               0\n",
      "           Conv2d-82           [-1, 64, 77, 77]          24,576\n",
      "      BatchNorm2d-83           [-1, 64, 77, 77]             128\n",
      "             ReLU-84           [-1, 64, 77, 77]               0\n",
      "      BasicConv2d-85           [-1, 64, 77, 77]               0\n",
      "           Conv2d-86           [-1, 96, 77, 77]          55,296\n",
      "      BatchNorm2d-87           [-1, 96, 77, 77]             192\n",
      "             ReLU-88           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-89           [-1, 96, 77, 77]               0\n",
      "           Conv2d-90           [-1, 64, 77, 77]          24,576\n",
      "      BatchNorm2d-91           [-1, 64, 77, 77]             128\n",
      "             ReLU-92           [-1, 64, 77, 77]               0\n",
      "      BasicConv2d-93           [-1, 64, 77, 77]               0\n",
      "           Conv2d-94           [-1, 96, 77, 77]          55,296\n",
      "      BatchNorm2d-95           [-1, 96, 77, 77]             192\n",
      "             ReLU-96           [-1, 96, 77, 77]               0\n",
      "      BasicConv2d-97           [-1, 96, 77, 77]               0\n",
      "           Conv2d-98           [-1, 96, 77, 77]          82,944\n",
      "      BatchNorm2d-99           [-1, 96, 77, 77]             192\n",
      "            ReLU-100           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-101           [-1, 96, 77, 77]               0\n",
      "       AvgPool2d-102          [-1, 384, 77, 77]               0\n",
      "          Conv2d-103           [-1, 96, 77, 77]          36,864\n",
      "     BatchNorm2d-104           [-1, 96, 77, 77]             192\n",
      "            ReLU-105           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-106           [-1, 96, 77, 77]               0\n",
      "      InceptionA-107          [-1, 384, 77, 77]               0\n",
      "          Conv2d-108           [-1, 96, 77, 77]          36,864\n",
      "     BatchNorm2d-109           [-1, 96, 77, 77]             192\n",
      "            ReLU-110           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-111           [-1, 96, 77, 77]               0\n",
      "          Conv2d-112           [-1, 64, 77, 77]          24,576\n",
      "     BatchNorm2d-113           [-1, 64, 77, 77]             128\n",
      "            ReLU-114           [-1, 64, 77, 77]               0\n",
      "     BasicConv2d-115           [-1, 64, 77, 77]               0\n",
      "          Conv2d-116           [-1, 96, 77, 77]          55,296\n",
      "     BatchNorm2d-117           [-1, 96, 77, 77]             192\n",
      "            ReLU-118           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-119           [-1, 96, 77, 77]               0\n",
      "          Conv2d-120           [-1, 64, 77, 77]          24,576\n",
      "     BatchNorm2d-121           [-1, 64, 77, 77]             128\n",
      "            ReLU-122           [-1, 64, 77, 77]               0\n",
      "     BasicConv2d-123           [-1, 64, 77, 77]               0\n",
      "          Conv2d-124           [-1, 96, 77, 77]          55,296\n",
      "     BatchNorm2d-125           [-1, 96, 77, 77]             192\n",
      "            ReLU-126           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-127           [-1, 96, 77, 77]               0\n",
      "          Conv2d-128           [-1, 96, 77, 77]          82,944\n",
      "     BatchNorm2d-129           [-1, 96, 77, 77]             192\n",
      "            ReLU-130           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-131           [-1, 96, 77, 77]               0\n",
      "       AvgPool2d-132          [-1, 384, 77, 77]               0\n",
      "          Conv2d-133           [-1, 96, 77, 77]          36,864\n",
      "     BatchNorm2d-134           [-1, 96, 77, 77]             192\n",
      "            ReLU-135           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-136           [-1, 96, 77, 77]               0\n",
      "      InceptionA-137          [-1, 384, 77, 77]               0\n",
      "          Conv2d-138           [-1, 96, 77, 77]          36,864\n",
      "     BatchNorm2d-139           [-1, 96, 77, 77]             192\n",
      "            ReLU-140           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-141           [-1, 96, 77, 77]               0\n",
      "          Conv2d-142           [-1, 64, 77, 77]          24,576\n",
      "     BatchNorm2d-143           [-1, 64, 77, 77]             128\n",
      "            ReLU-144           [-1, 64, 77, 77]               0\n",
      "     BasicConv2d-145           [-1, 64, 77, 77]               0\n",
      "          Conv2d-146           [-1, 96, 77, 77]          55,296\n",
      "     BatchNorm2d-147           [-1, 96, 77, 77]             192\n",
      "            ReLU-148           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-149           [-1, 96, 77, 77]               0\n",
      "          Conv2d-150           [-1, 64, 77, 77]          24,576\n",
      "     BatchNorm2d-151           [-1, 64, 77, 77]             128\n",
      "            ReLU-152           [-1, 64, 77, 77]               0\n",
      "     BasicConv2d-153           [-1, 64, 77, 77]               0\n",
      "          Conv2d-154           [-1, 96, 77, 77]          55,296\n",
      "     BatchNorm2d-155           [-1, 96, 77, 77]             192\n",
      "            ReLU-156           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-157           [-1, 96, 77, 77]               0\n",
      "          Conv2d-158           [-1, 96, 77, 77]          82,944\n",
      "     BatchNorm2d-159           [-1, 96, 77, 77]             192\n",
      "            ReLU-160           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-161           [-1, 96, 77, 77]               0\n",
      "       AvgPool2d-162          [-1, 384, 77, 77]               0\n",
      "          Conv2d-163           [-1, 96, 77, 77]          36,864\n",
      "     BatchNorm2d-164           [-1, 96, 77, 77]             192\n",
      "            ReLU-165           [-1, 96, 77, 77]               0\n",
      "     BasicConv2d-166           [-1, 96, 77, 77]               0\n",
      "      InceptionA-167          [-1, 384, 77, 77]               0\n",
      "AdaptiveAvgPool2d-168            [-1, 384, 1, 1]               0\n",
      "          Linear-169                    [-1, 2]             770\n",
      "          Conv2d-170          [-1, 384, 38, 38]       1,327,104\n",
      "     BatchNorm2d-171          [-1, 384, 38, 38]             768\n",
      "            ReLU-172          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-173          [-1, 384, 38, 38]               0\n",
      "          Conv2d-174          [-1, 192, 77, 77]          73,728\n",
      "     BatchNorm2d-175          [-1, 192, 77, 77]             384\n",
      "            ReLU-176          [-1, 192, 77, 77]               0\n",
      "     BasicConv2d-177          [-1, 192, 77, 77]               0\n",
      "          Conv2d-178          [-1, 224, 77, 77]         387,072\n",
      "     BatchNorm2d-179          [-1, 224, 77, 77]             448\n",
      "            ReLU-180          [-1, 224, 77, 77]               0\n",
      "     BasicConv2d-181          [-1, 224, 77, 77]               0\n",
      "          Conv2d-182          [-1, 256, 38, 38]         516,096\n",
      "     BatchNorm2d-183          [-1, 256, 38, 38]             512\n",
      "            ReLU-184          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-185          [-1, 256, 38, 38]               0\n",
      "       MaxPool2d-186          [-1, 384, 38, 38]               0\n",
      "      ReductionA-187         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-188          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-189          [-1, 384, 38, 38]             768\n",
      "            ReLU-190          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-191          [-1, 384, 38, 38]               0\n",
      "          Conv2d-192          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-193          [-1, 192, 38, 38]             384\n",
      "            ReLU-194          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-195          [-1, 192, 38, 38]               0\n",
      "          Conv2d-196          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-197          [-1, 224, 38, 38]             448\n",
      "            ReLU-198          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-199          [-1, 224, 38, 38]               0\n",
      "          Conv2d-200          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-201          [-1, 256, 38, 38]             512\n",
      "            ReLU-202          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-203          [-1, 256, 38, 38]               0\n",
      "          Conv2d-204          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-205          [-1, 192, 38, 38]             384\n",
      "            ReLU-206          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-207          [-1, 192, 38, 38]               0\n",
      "          Conv2d-208          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-209          [-1, 192, 38, 38]             384\n",
      "            ReLU-210          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-211          [-1, 192, 38, 38]               0\n",
      "          Conv2d-212          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-213          [-1, 224, 38, 38]             448\n",
      "            ReLU-214          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-215          [-1, 224, 38, 38]               0\n",
      "          Conv2d-216          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-217          [-1, 224, 38, 38]             448\n",
      "            ReLU-218          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-219          [-1, 224, 38, 38]               0\n",
      "          Conv2d-220          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-221          [-1, 256, 38, 38]             512\n",
      "            ReLU-222          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-223          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-224         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-225          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-226          [-1, 128, 38, 38]             256\n",
      "            ReLU-227          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-228          [-1, 128, 38, 38]               0\n",
      "      InceptionB-229         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-230          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-231          [-1, 384, 38, 38]             768\n",
      "            ReLU-232          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-233          [-1, 384, 38, 38]               0\n",
      "          Conv2d-234          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-235          [-1, 192, 38, 38]             384\n",
      "            ReLU-236          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-237          [-1, 192, 38, 38]               0\n",
      "          Conv2d-238          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-239          [-1, 224, 38, 38]             448\n",
      "            ReLU-240          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-241          [-1, 224, 38, 38]               0\n",
      "          Conv2d-242          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-243          [-1, 256, 38, 38]             512\n",
      "            ReLU-244          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-245          [-1, 256, 38, 38]               0\n",
      "          Conv2d-246          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-247          [-1, 192, 38, 38]             384\n",
      "            ReLU-248          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-249          [-1, 192, 38, 38]               0\n",
      "          Conv2d-250          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-251          [-1, 192, 38, 38]             384\n",
      "            ReLU-252          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-253          [-1, 192, 38, 38]               0\n",
      "          Conv2d-254          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-255          [-1, 224, 38, 38]             448\n",
      "            ReLU-256          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-257          [-1, 224, 38, 38]               0\n",
      "          Conv2d-258          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-259          [-1, 224, 38, 38]             448\n",
      "            ReLU-260          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-261          [-1, 224, 38, 38]               0\n",
      "          Conv2d-262          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-263          [-1, 256, 38, 38]             512\n",
      "            ReLU-264          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-265          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-266         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-267          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-268          [-1, 128, 38, 38]             256\n",
      "            ReLU-269          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-270          [-1, 128, 38, 38]               0\n",
      "      InceptionB-271         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-272          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-273          [-1, 384, 38, 38]             768\n",
      "            ReLU-274          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-275          [-1, 384, 38, 38]               0\n",
      "          Conv2d-276          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-277          [-1, 192, 38, 38]             384\n",
      "            ReLU-278          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-279          [-1, 192, 38, 38]               0\n",
      "          Conv2d-280          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-281          [-1, 224, 38, 38]             448\n",
      "            ReLU-282          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-283          [-1, 224, 38, 38]               0\n",
      "          Conv2d-284          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-285          [-1, 256, 38, 38]             512\n",
      "            ReLU-286          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-287          [-1, 256, 38, 38]               0\n",
      "          Conv2d-288          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-289          [-1, 192, 38, 38]             384\n",
      "            ReLU-290          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-291          [-1, 192, 38, 38]               0\n",
      "          Conv2d-292          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-293          [-1, 192, 38, 38]             384\n",
      "            ReLU-294          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-295          [-1, 192, 38, 38]               0\n",
      "          Conv2d-296          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-297          [-1, 224, 38, 38]             448\n",
      "            ReLU-298          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-299          [-1, 224, 38, 38]               0\n",
      "          Conv2d-300          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-301          [-1, 224, 38, 38]             448\n",
      "            ReLU-302          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-303          [-1, 224, 38, 38]               0\n",
      "          Conv2d-304          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-305          [-1, 256, 38, 38]             512\n",
      "            ReLU-306          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-307          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-308         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-309          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-310          [-1, 128, 38, 38]             256\n",
      "            ReLU-311          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-312          [-1, 128, 38, 38]               0\n",
      "      InceptionB-313         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-314          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-315          [-1, 384, 38, 38]             768\n",
      "            ReLU-316          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-317          [-1, 384, 38, 38]               0\n",
      "          Conv2d-318          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-319          [-1, 192, 38, 38]             384\n",
      "            ReLU-320          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-321          [-1, 192, 38, 38]               0\n",
      "          Conv2d-322          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-323          [-1, 224, 38, 38]             448\n",
      "            ReLU-324          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-325          [-1, 224, 38, 38]               0\n",
      "          Conv2d-326          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-327          [-1, 256, 38, 38]             512\n",
      "            ReLU-328          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-329          [-1, 256, 38, 38]               0\n",
      "          Conv2d-330          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-331          [-1, 192, 38, 38]             384\n",
      "            ReLU-332          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-333          [-1, 192, 38, 38]               0\n",
      "          Conv2d-334          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-335          [-1, 192, 38, 38]             384\n",
      "            ReLU-336          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-337          [-1, 192, 38, 38]               0\n",
      "          Conv2d-338          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-339          [-1, 224, 38, 38]             448\n",
      "            ReLU-340          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-341          [-1, 224, 38, 38]               0\n",
      "          Conv2d-342          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-343          [-1, 224, 38, 38]             448\n",
      "            ReLU-344          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-345          [-1, 224, 38, 38]               0\n",
      "          Conv2d-346          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-347          [-1, 256, 38, 38]             512\n",
      "            ReLU-348          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-349          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-350         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-351          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-352          [-1, 128, 38, 38]             256\n",
      "            ReLU-353          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-354          [-1, 128, 38, 38]               0\n",
      "      InceptionB-355         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-356          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-357          [-1, 384, 38, 38]             768\n",
      "            ReLU-358          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-359          [-1, 384, 38, 38]               0\n",
      "          Conv2d-360          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-361          [-1, 192, 38, 38]             384\n",
      "            ReLU-362          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-363          [-1, 192, 38, 38]               0\n",
      "          Conv2d-364          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-365          [-1, 224, 38, 38]             448\n",
      "            ReLU-366          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-367          [-1, 224, 38, 38]               0\n",
      "          Conv2d-368          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-369          [-1, 256, 38, 38]             512\n",
      "            ReLU-370          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-371          [-1, 256, 38, 38]               0\n",
      "          Conv2d-372          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-373          [-1, 192, 38, 38]             384\n",
      "            ReLU-374          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-375          [-1, 192, 38, 38]               0\n",
      "          Conv2d-376          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-377          [-1, 192, 38, 38]             384\n",
      "            ReLU-378          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-379          [-1, 192, 38, 38]               0\n",
      "          Conv2d-380          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-381          [-1, 224, 38, 38]             448\n",
      "            ReLU-382          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-383          [-1, 224, 38, 38]               0\n",
      "          Conv2d-384          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-385          [-1, 224, 38, 38]             448\n",
      "            ReLU-386          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-387          [-1, 224, 38, 38]               0\n",
      "          Conv2d-388          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-389          [-1, 256, 38, 38]             512\n",
      "            ReLU-390          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-391          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-392         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-393          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-394          [-1, 128, 38, 38]             256\n",
      "            ReLU-395          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-396          [-1, 128, 38, 38]               0\n",
      "      InceptionB-397         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-398          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-399          [-1, 384, 38, 38]             768\n",
      "            ReLU-400          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-401          [-1, 384, 38, 38]               0\n",
      "          Conv2d-402          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-403          [-1, 192, 38, 38]             384\n",
      "            ReLU-404          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-405          [-1, 192, 38, 38]               0\n",
      "          Conv2d-406          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-407          [-1, 224, 38, 38]             448\n",
      "            ReLU-408          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-409          [-1, 224, 38, 38]               0\n",
      "          Conv2d-410          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-411          [-1, 256, 38, 38]             512\n",
      "            ReLU-412          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-413          [-1, 256, 38, 38]               0\n",
      "          Conv2d-414          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-415          [-1, 192, 38, 38]             384\n",
      "            ReLU-416          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-417          [-1, 192, 38, 38]               0\n",
      "          Conv2d-418          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-419          [-1, 192, 38, 38]             384\n",
      "            ReLU-420          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-421          [-1, 192, 38, 38]               0\n",
      "          Conv2d-422          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-423          [-1, 224, 38, 38]             448\n",
      "            ReLU-424          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-425          [-1, 224, 38, 38]               0\n",
      "          Conv2d-426          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-427          [-1, 224, 38, 38]             448\n",
      "            ReLU-428          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-429          [-1, 224, 38, 38]               0\n",
      "          Conv2d-430          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-431          [-1, 256, 38, 38]             512\n",
      "            ReLU-432          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-433          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-434         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-435          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-436          [-1, 128, 38, 38]             256\n",
      "            ReLU-437          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-438          [-1, 128, 38, 38]               0\n",
      "      InceptionB-439         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-440          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-441          [-1, 384, 38, 38]             768\n",
      "            ReLU-442          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-443          [-1, 384, 38, 38]               0\n",
      "          Conv2d-444          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-445          [-1, 192, 38, 38]             384\n",
      "            ReLU-446          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-447          [-1, 192, 38, 38]               0\n",
      "          Conv2d-448          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-449          [-1, 224, 38, 38]             448\n",
      "            ReLU-450          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-451          [-1, 224, 38, 38]               0\n",
      "          Conv2d-452          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-453          [-1, 256, 38, 38]             512\n",
      "            ReLU-454          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-455          [-1, 256, 38, 38]               0\n",
      "          Conv2d-456          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-457          [-1, 192, 38, 38]             384\n",
      "            ReLU-458          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-459          [-1, 192, 38, 38]               0\n",
      "          Conv2d-460          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-461          [-1, 192, 38, 38]             384\n",
      "            ReLU-462          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-463          [-1, 192, 38, 38]               0\n",
      "          Conv2d-464          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-465          [-1, 224, 38, 38]             448\n",
      "            ReLU-466          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-467          [-1, 224, 38, 38]               0\n",
      "          Conv2d-468          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-469          [-1, 224, 38, 38]             448\n",
      "            ReLU-470          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-471          [-1, 224, 38, 38]               0\n",
      "          Conv2d-472          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-473          [-1, 256, 38, 38]             512\n",
      "            ReLU-474          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-475          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-476         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-477          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-478          [-1, 128, 38, 38]             256\n",
      "            ReLU-479          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-480          [-1, 128, 38, 38]               0\n",
      "      InceptionB-481         [-1, 1024, 38, 38]               0\n",
      "AdaptiveAvgPool2d-482           [-1, 1024, 1, 1]               0\n",
      "          Linear-483                    [-1, 2]           2,050\n",
      "          Conv2d-484          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-485          [-1, 192, 38, 38]             384\n",
      "            ReLU-486          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-487          [-1, 192, 38, 38]               0\n",
      "          Conv2d-488          [-1, 192, 18, 18]         331,776\n",
      "     BatchNorm2d-489          [-1, 192, 18, 18]             384\n",
      "            ReLU-490          [-1, 192, 18, 18]               0\n",
      "     BasicConv2d-491          [-1, 192, 18, 18]               0\n",
      "          Conv2d-492          [-1, 256, 38, 38]         262,144\n",
      "     BatchNorm2d-493          [-1, 256, 38, 38]             512\n",
      "            ReLU-494          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-495          [-1, 256, 38, 38]               0\n",
      "          Conv2d-496          [-1, 256, 38, 38]         458,752\n",
      "     BatchNorm2d-497          [-1, 256, 38, 38]             512\n",
      "            ReLU-498          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-499          [-1, 256, 38, 38]               0\n",
      "          Conv2d-500          [-1, 320, 38, 38]         573,440\n",
      "     BatchNorm2d-501          [-1, 320, 38, 38]             640\n",
      "            ReLU-502          [-1, 320, 38, 38]               0\n",
      "     BasicConv2d-503          [-1, 320, 38, 38]               0\n",
      "          Conv2d-504          [-1, 320, 18, 18]         921,600\n",
      "     BatchNorm2d-505          [-1, 320, 18, 18]             640\n",
      "            ReLU-506          [-1, 320, 18, 18]               0\n",
      "     BasicConv2d-507          [-1, 320, 18, 18]               0\n",
      "       MaxPool2d-508         [-1, 1024, 18, 18]               0\n",
      "      ReductionB-509         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-510          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-511          [-1, 256, 18, 18]             512\n",
      "            ReLU-512          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-513          [-1, 256, 18, 18]               0\n",
      "          Conv2d-514          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-515          [-1, 384, 18, 18]             768\n",
      "            ReLU-516          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-517          [-1, 384, 18, 18]               0\n",
      "          Conv2d-518          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-519          [-1, 256, 18, 18]             512\n",
      "            ReLU-520          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-521          [-1, 256, 18, 18]               0\n",
      "          Conv2d-522          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-523          [-1, 256, 18, 18]             512\n",
      "            ReLU-524          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-525          [-1, 256, 18, 18]               0\n",
      "          Conv2d-526          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-527          [-1, 384, 18, 18]             768\n",
      "            ReLU-528          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-529          [-1, 384, 18, 18]               0\n",
      "          Conv2d-530          [-1, 448, 18, 18]         516,096\n",
      "     BatchNorm2d-531          [-1, 448, 18, 18]             896\n",
      "            ReLU-532          [-1, 448, 18, 18]               0\n",
      "     BasicConv2d-533          [-1, 448, 18, 18]               0\n",
      "          Conv2d-534          [-1, 512, 18, 18]         688,128\n",
      "     BatchNorm2d-535          [-1, 512, 18, 18]           1,024\n",
      "            ReLU-536          [-1, 512, 18, 18]               0\n",
      "     BasicConv2d-537          [-1, 512, 18, 18]               0\n",
      "          Conv2d-538          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-539          [-1, 256, 18, 18]             512\n",
      "            ReLU-540          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-541          [-1, 256, 18, 18]               0\n",
      "          Conv2d-542          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-543          [-1, 256, 18, 18]             512\n",
      "            ReLU-544          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-545          [-1, 256, 18, 18]               0\n",
      "       AvgPool2d-546         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-547          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-548          [-1, 256, 18, 18]             512\n",
      "            ReLU-549          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-550          [-1, 256, 18, 18]               0\n",
      "      InceptionC-551         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-552          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-553          [-1, 256, 18, 18]             512\n",
      "            ReLU-554          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-555          [-1, 256, 18, 18]               0\n",
      "          Conv2d-556          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-557          [-1, 384, 18, 18]             768\n",
      "            ReLU-558          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-559          [-1, 384, 18, 18]               0\n",
      "          Conv2d-560          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-561          [-1, 256, 18, 18]             512\n",
      "            ReLU-562          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-563          [-1, 256, 18, 18]               0\n",
      "          Conv2d-564          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-565          [-1, 256, 18, 18]             512\n",
      "            ReLU-566          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-567          [-1, 256, 18, 18]               0\n",
      "          Conv2d-568          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-569          [-1, 384, 18, 18]             768\n",
      "            ReLU-570          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-571          [-1, 384, 18, 18]               0\n",
      "          Conv2d-572          [-1, 448, 18, 18]         516,096\n",
      "     BatchNorm2d-573          [-1, 448, 18, 18]             896\n",
      "            ReLU-574          [-1, 448, 18, 18]               0\n",
      "     BasicConv2d-575          [-1, 448, 18, 18]               0\n",
      "          Conv2d-576          [-1, 512, 18, 18]         688,128\n",
      "     BatchNorm2d-577          [-1, 512, 18, 18]           1,024\n",
      "            ReLU-578          [-1, 512, 18, 18]               0\n",
      "     BasicConv2d-579          [-1, 512, 18, 18]               0\n",
      "          Conv2d-580          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-581          [-1, 256, 18, 18]             512\n",
      "            ReLU-582          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-583          [-1, 256, 18, 18]               0\n",
      "          Conv2d-584          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-585          [-1, 256, 18, 18]             512\n",
      "            ReLU-586          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-587          [-1, 256, 18, 18]               0\n",
      "       AvgPool2d-588         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-589          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-590          [-1, 256, 18, 18]             512\n",
      "            ReLU-591          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-592          [-1, 256, 18, 18]               0\n",
      "      InceptionC-593         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-594          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-595          [-1, 256, 18, 18]             512\n",
      "            ReLU-596          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-597          [-1, 256, 18, 18]               0\n",
      "          Conv2d-598          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-599          [-1, 384, 18, 18]             768\n",
      "            ReLU-600          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-601          [-1, 384, 18, 18]               0\n",
      "          Conv2d-602          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-603          [-1, 256, 18, 18]             512\n",
      "            ReLU-604          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-605          [-1, 256, 18, 18]               0\n",
      "          Conv2d-606          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-607          [-1, 256, 18, 18]             512\n",
      "            ReLU-608          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-609          [-1, 256, 18, 18]               0\n",
      "          Conv2d-610          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-611          [-1, 384, 18, 18]             768\n",
      "            ReLU-612          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-613          [-1, 384, 18, 18]               0\n",
      "          Conv2d-614          [-1, 448, 18, 18]         516,096\n",
      "     BatchNorm2d-615          [-1, 448, 18, 18]             896\n",
      "            ReLU-616          [-1, 448, 18, 18]               0\n",
      "     BasicConv2d-617          [-1, 448, 18, 18]               0\n",
      "          Conv2d-618          [-1, 512, 18, 18]         688,128\n",
      "     BatchNorm2d-619          [-1, 512, 18, 18]           1,024\n",
      "            ReLU-620          [-1, 512, 18, 18]               0\n",
      "     BasicConv2d-621          [-1, 512, 18, 18]               0\n",
      "          Conv2d-622          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-623          [-1, 256, 18, 18]             512\n",
      "            ReLU-624          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-625          [-1, 256, 18, 18]               0\n",
      "          Conv2d-626          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-627          [-1, 256, 18, 18]             512\n",
      "            ReLU-628          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-629          [-1, 256, 18, 18]               0\n",
      "       AvgPool2d-630         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-631          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-632          [-1, 256, 18, 18]             512\n",
      "            ReLU-633          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-634          [-1, 256, 18, 18]               0\n",
      "      InceptionC-635         [-1, 1536, 18, 18]               0\n",
      "AdaptiveAvgPool2d-636           [-1, 1536, 1, 1]               0\n",
      "          Linear-637                    [-1, 1]           1,537\n",
      "          Conv2d-638          [-1, 384, 38, 38]       1,327,104\n",
      "     BatchNorm2d-639          [-1, 384, 38, 38]             768\n",
      "            ReLU-640          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-641          [-1, 384, 38, 38]               0\n",
      "          Conv2d-642          [-1, 192, 77, 77]          73,728\n",
      "     BatchNorm2d-643          [-1, 192, 77, 77]             384\n",
      "            ReLU-644          [-1, 192, 77, 77]               0\n",
      "     BasicConv2d-645          [-1, 192, 77, 77]               0\n",
      "          Conv2d-646          [-1, 224, 77, 77]         387,072\n",
      "     BatchNorm2d-647          [-1, 224, 77, 77]             448\n",
      "            ReLU-648          [-1, 224, 77, 77]               0\n",
      "     BasicConv2d-649          [-1, 224, 77, 77]               0\n",
      "          Conv2d-650          [-1, 256, 38, 38]         516,096\n",
      "     BatchNorm2d-651          [-1, 256, 38, 38]             512\n",
      "            ReLU-652          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-653          [-1, 256, 38, 38]               0\n",
      "       MaxPool2d-654          [-1, 384, 38, 38]               0\n",
      "      ReductionA-655         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-656          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-657          [-1, 384, 38, 38]             768\n",
      "            ReLU-658          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-659          [-1, 384, 38, 38]               0\n",
      "          Conv2d-660          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-661          [-1, 192, 38, 38]             384\n",
      "            ReLU-662          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-663          [-1, 192, 38, 38]               0\n",
      "          Conv2d-664          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-665          [-1, 224, 38, 38]             448\n",
      "            ReLU-666          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-667          [-1, 224, 38, 38]               0\n",
      "          Conv2d-668          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-669          [-1, 256, 38, 38]             512\n",
      "            ReLU-670          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-671          [-1, 256, 38, 38]               0\n",
      "          Conv2d-672          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-673          [-1, 192, 38, 38]             384\n",
      "            ReLU-674          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-675          [-1, 192, 38, 38]               0\n",
      "          Conv2d-676          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-677          [-1, 192, 38, 38]             384\n",
      "            ReLU-678          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-679          [-1, 192, 38, 38]               0\n",
      "          Conv2d-680          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-681          [-1, 224, 38, 38]             448\n",
      "            ReLU-682          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-683          [-1, 224, 38, 38]               0\n",
      "          Conv2d-684          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-685          [-1, 224, 38, 38]             448\n",
      "            ReLU-686          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-687          [-1, 224, 38, 38]               0\n",
      "          Conv2d-688          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-689          [-1, 256, 38, 38]             512\n",
      "            ReLU-690          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-691          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-692         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-693          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-694          [-1, 128, 38, 38]             256\n",
      "            ReLU-695          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-696          [-1, 128, 38, 38]               0\n",
      "      InceptionB-697         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-698          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-699          [-1, 384, 38, 38]             768\n",
      "            ReLU-700          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-701          [-1, 384, 38, 38]               0\n",
      "          Conv2d-702          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-703          [-1, 192, 38, 38]             384\n",
      "            ReLU-704          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-705          [-1, 192, 38, 38]               0\n",
      "          Conv2d-706          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-707          [-1, 224, 38, 38]             448\n",
      "            ReLU-708          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-709          [-1, 224, 38, 38]               0\n",
      "          Conv2d-710          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-711          [-1, 256, 38, 38]             512\n",
      "            ReLU-712          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-713          [-1, 256, 38, 38]               0\n",
      "          Conv2d-714          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-715          [-1, 192, 38, 38]             384\n",
      "            ReLU-716          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-717          [-1, 192, 38, 38]               0\n",
      "          Conv2d-718          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-719          [-1, 192, 38, 38]             384\n",
      "            ReLU-720          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-721          [-1, 192, 38, 38]               0\n",
      "          Conv2d-722          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-723          [-1, 224, 38, 38]             448\n",
      "            ReLU-724          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-725          [-1, 224, 38, 38]               0\n",
      "          Conv2d-726          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-727          [-1, 224, 38, 38]             448\n",
      "            ReLU-728          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-729          [-1, 224, 38, 38]               0\n",
      "          Conv2d-730          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-731          [-1, 256, 38, 38]             512\n",
      "            ReLU-732          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-733          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-734         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-735          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-736          [-1, 128, 38, 38]             256\n",
      "            ReLU-737          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-738          [-1, 128, 38, 38]               0\n",
      "      InceptionB-739         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-740          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-741          [-1, 384, 38, 38]             768\n",
      "            ReLU-742          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-743          [-1, 384, 38, 38]               0\n",
      "          Conv2d-744          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-745          [-1, 192, 38, 38]             384\n",
      "            ReLU-746          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-747          [-1, 192, 38, 38]               0\n",
      "          Conv2d-748          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-749          [-1, 224, 38, 38]             448\n",
      "            ReLU-750          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-751          [-1, 224, 38, 38]               0\n",
      "          Conv2d-752          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-753          [-1, 256, 38, 38]             512\n",
      "            ReLU-754          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-755          [-1, 256, 38, 38]               0\n",
      "          Conv2d-756          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-757          [-1, 192, 38, 38]             384\n",
      "            ReLU-758          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-759          [-1, 192, 38, 38]               0\n",
      "          Conv2d-760          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-761          [-1, 192, 38, 38]             384\n",
      "            ReLU-762          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-763          [-1, 192, 38, 38]               0\n",
      "          Conv2d-764          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-765          [-1, 224, 38, 38]             448\n",
      "            ReLU-766          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-767          [-1, 224, 38, 38]               0\n",
      "          Conv2d-768          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-769          [-1, 224, 38, 38]             448\n",
      "            ReLU-770          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-771          [-1, 224, 38, 38]               0\n",
      "          Conv2d-772          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-773          [-1, 256, 38, 38]             512\n",
      "            ReLU-774          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-775          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-776         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-777          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-778          [-1, 128, 38, 38]             256\n",
      "            ReLU-779          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-780          [-1, 128, 38, 38]               0\n",
      "      InceptionB-781         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-782          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-783          [-1, 384, 38, 38]             768\n",
      "            ReLU-784          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-785          [-1, 384, 38, 38]               0\n",
      "          Conv2d-786          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-787          [-1, 192, 38, 38]             384\n",
      "            ReLU-788          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-789          [-1, 192, 38, 38]               0\n",
      "          Conv2d-790          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-791          [-1, 224, 38, 38]             448\n",
      "            ReLU-792          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-793          [-1, 224, 38, 38]               0\n",
      "          Conv2d-794          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-795          [-1, 256, 38, 38]             512\n",
      "            ReLU-796          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-797          [-1, 256, 38, 38]               0\n",
      "          Conv2d-798          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-799          [-1, 192, 38, 38]             384\n",
      "            ReLU-800          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-801          [-1, 192, 38, 38]               0\n",
      "          Conv2d-802          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-803          [-1, 192, 38, 38]             384\n",
      "            ReLU-804          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-805          [-1, 192, 38, 38]               0\n",
      "          Conv2d-806          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-807          [-1, 224, 38, 38]             448\n",
      "            ReLU-808          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-809          [-1, 224, 38, 38]               0\n",
      "          Conv2d-810          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-811          [-1, 224, 38, 38]             448\n",
      "            ReLU-812          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-813          [-1, 224, 38, 38]               0\n",
      "          Conv2d-814          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-815          [-1, 256, 38, 38]             512\n",
      "            ReLU-816          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-817          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-818         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-819          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-820          [-1, 128, 38, 38]             256\n",
      "            ReLU-821          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-822          [-1, 128, 38, 38]               0\n",
      "      InceptionB-823         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-824          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-825          [-1, 384, 38, 38]             768\n",
      "            ReLU-826          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-827          [-1, 384, 38, 38]               0\n",
      "          Conv2d-828          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-829          [-1, 192, 38, 38]             384\n",
      "            ReLU-830          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-831          [-1, 192, 38, 38]               0\n",
      "          Conv2d-832          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-833          [-1, 224, 38, 38]             448\n",
      "            ReLU-834          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-835          [-1, 224, 38, 38]               0\n",
      "          Conv2d-836          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-837          [-1, 256, 38, 38]             512\n",
      "            ReLU-838          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-839          [-1, 256, 38, 38]               0\n",
      "          Conv2d-840          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-841          [-1, 192, 38, 38]             384\n",
      "            ReLU-842          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-843          [-1, 192, 38, 38]               0\n",
      "          Conv2d-844          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-845          [-1, 192, 38, 38]             384\n",
      "            ReLU-846          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-847          [-1, 192, 38, 38]               0\n",
      "          Conv2d-848          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-849          [-1, 224, 38, 38]             448\n",
      "            ReLU-850          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-851          [-1, 224, 38, 38]               0\n",
      "          Conv2d-852          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-853          [-1, 224, 38, 38]             448\n",
      "            ReLU-854          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-855          [-1, 224, 38, 38]               0\n",
      "          Conv2d-856          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-857          [-1, 256, 38, 38]             512\n",
      "            ReLU-858          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-859          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-860         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-861          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-862          [-1, 128, 38, 38]             256\n",
      "            ReLU-863          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-864          [-1, 128, 38, 38]               0\n",
      "      InceptionB-865         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-866          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-867          [-1, 384, 38, 38]             768\n",
      "            ReLU-868          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-869          [-1, 384, 38, 38]               0\n",
      "          Conv2d-870          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-871          [-1, 192, 38, 38]             384\n",
      "            ReLU-872          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-873          [-1, 192, 38, 38]               0\n",
      "          Conv2d-874          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-875          [-1, 224, 38, 38]             448\n",
      "            ReLU-876          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-877          [-1, 224, 38, 38]               0\n",
      "          Conv2d-878          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-879          [-1, 256, 38, 38]             512\n",
      "            ReLU-880          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-881          [-1, 256, 38, 38]               0\n",
      "          Conv2d-882          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-883          [-1, 192, 38, 38]             384\n",
      "            ReLU-884          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-885          [-1, 192, 38, 38]               0\n",
      "          Conv2d-886          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-887          [-1, 192, 38, 38]             384\n",
      "            ReLU-888          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-889          [-1, 192, 38, 38]               0\n",
      "          Conv2d-890          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-891          [-1, 224, 38, 38]             448\n",
      "            ReLU-892          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-893          [-1, 224, 38, 38]               0\n",
      "          Conv2d-894          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-895          [-1, 224, 38, 38]             448\n",
      "            ReLU-896          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-897          [-1, 224, 38, 38]               0\n",
      "          Conv2d-898          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-899          [-1, 256, 38, 38]             512\n",
      "            ReLU-900          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-901          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-902         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-903          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-904          [-1, 128, 38, 38]             256\n",
      "            ReLU-905          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-906          [-1, 128, 38, 38]               0\n",
      "      InceptionB-907         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-908          [-1, 384, 38, 38]         393,216\n",
      "     BatchNorm2d-909          [-1, 384, 38, 38]             768\n",
      "            ReLU-910          [-1, 384, 38, 38]               0\n",
      "     BasicConv2d-911          [-1, 384, 38, 38]               0\n",
      "          Conv2d-912          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-913          [-1, 192, 38, 38]             384\n",
      "            ReLU-914          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-915          [-1, 192, 38, 38]               0\n",
      "          Conv2d-916          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-917          [-1, 224, 38, 38]             448\n",
      "            ReLU-918          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-919          [-1, 224, 38, 38]               0\n",
      "          Conv2d-920          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-921          [-1, 256, 38, 38]             512\n",
      "            ReLU-922          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-923          [-1, 256, 38, 38]               0\n",
      "          Conv2d-924          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-925          [-1, 192, 38, 38]             384\n",
      "            ReLU-926          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-927          [-1, 192, 38, 38]               0\n",
      "          Conv2d-928          [-1, 192, 38, 38]         258,048\n",
      "     BatchNorm2d-929          [-1, 192, 38, 38]             384\n",
      "            ReLU-930          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-931          [-1, 192, 38, 38]               0\n",
      "          Conv2d-932          [-1, 224, 38, 38]         301,056\n",
      "     BatchNorm2d-933          [-1, 224, 38, 38]             448\n",
      "            ReLU-934          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-935          [-1, 224, 38, 38]               0\n",
      "          Conv2d-936          [-1, 224, 38, 38]         351,232\n",
      "     BatchNorm2d-937          [-1, 224, 38, 38]             448\n",
      "            ReLU-938          [-1, 224, 38, 38]               0\n",
      "     BasicConv2d-939          [-1, 224, 38, 38]               0\n",
      "          Conv2d-940          [-1, 256, 38, 38]         401,408\n",
      "     BatchNorm2d-941          [-1, 256, 38, 38]             512\n",
      "            ReLU-942          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-943          [-1, 256, 38, 38]               0\n",
      "       AvgPool2d-944         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-945          [-1, 128, 38, 38]         131,072\n",
      "     BatchNorm2d-946          [-1, 128, 38, 38]             256\n",
      "            ReLU-947          [-1, 128, 38, 38]               0\n",
      "     BasicConv2d-948          [-1, 128, 38, 38]               0\n",
      "      InceptionB-949         [-1, 1024, 38, 38]               0\n",
      "          Conv2d-950          [-1, 192, 38, 38]         196,608\n",
      "     BatchNorm2d-951          [-1, 192, 38, 38]             384\n",
      "            ReLU-952          [-1, 192, 38, 38]               0\n",
      "     BasicConv2d-953          [-1, 192, 38, 38]               0\n",
      "          Conv2d-954          [-1, 192, 18, 18]         331,776\n",
      "     BatchNorm2d-955          [-1, 192, 18, 18]             384\n",
      "            ReLU-956          [-1, 192, 18, 18]               0\n",
      "     BasicConv2d-957          [-1, 192, 18, 18]               0\n",
      "          Conv2d-958          [-1, 256, 38, 38]         262,144\n",
      "     BatchNorm2d-959          [-1, 256, 38, 38]             512\n",
      "            ReLU-960          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-961          [-1, 256, 38, 38]               0\n",
      "          Conv2d-962          [-1, 256, 38, 38]         458,752\n",
      "     BatchNorm2d-963          [-1, 256, 38, 38]             512\n",
      "            ReLU-964          [-1, 256, 38, 38]               0\n",
      "     BasicConv2d-965          [-1, 256, 38, 38]               0\n",
      "          Conv2d-966          [-1, 320, 38, 38]         573,440\n",
      "     BatchNorm2d-967          [-1, 320, 38, 38]             640\n",
      "            ReLU-968          [-1, 320, 38, 38]               0\n",
      "     BasicConv2d-969          [-1, 320, 38, 38]               0\n",
      "          Conv2d-970          [-1, 320, 18, 18]         921,600\n",
      "     BatchNorm2d-971          [-1, 320, 18, 18]             640\n",
      "            ReLU-972          [-1, 320, 18, 18]               0\n",
      "     BasicConv2d-973          [-1, 320, 18, 18]               0\n",
      "       MaxPool2d-974         [-1, 1024, 18, 18]               0\n",
      "      ReductionB-975         [-1, 1536, 18, 18]               0\n",
      "          Conv2d-976          [-1, 256, 18, 18]         393,216\n",
      "     BatchNorm2d-977          [-1, 256, 18, 18]             512\n",
      "            ReLU-978          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-979          [-1, 256, 18, 18]               0\n",
      "          Conv2d-980          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-981          [-1, 384, 18, 18]             768\n",
      "            ReLU-982          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-983          [-1, 384, 18, 18]               0\n",
      "          Conv2d-984          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-985          [-1, 256, 18, 18]             512\n",
      "            ReLU-986          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-987          [-1, 256, 18, 18]               0\n",
      "          Conv2d-988          [-1, 256, 18, 18]         294,912\n",
      "     BatchNorm2d-989          [-1, 256, 18, 18]             512\n",
      "            ReLU-990          [-1, 256, 18, 18]               0\n",
      "     BasicConv2d-991          [-1, 256, 18, 18]               0\n",
      "          Conv2d-992          [-1, 384, 18, 18]         589,824\n",
      "     BatchNorm2d-993          [-1, 384, 18, 18]             768\n",
      "            ReLU-994          [-1, 384, 18, 18]               0\n",
      "     BasicConv2d-995          [-1, 384, 18, 18]               0\n",
      "          Conv2d-996          [-1, 448, 18, 18]         516,096\n",
      "     BatchNorm2d-997          [-1, 448, 18, 18]             896\n",
      "            ReLU-998          [-1, 448, 18, 18]               0\n",
      "     BasicConv2d-999          [-1, 448, 18, 18]               0\n",
      "         Conv2d-1000          [-1, 512, 18, 18]         688,128\n",
      "    BatchNorm2d-1001          [-1, 512, 18, 18]           1,024\n",
      "           ReLU-1002          [-1, 512, 18, 18]               0\n",
      "    BasicConv2d-1003          [-1, 512, 18, 18]               0\n",
      "         Conv2d-1004          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1005          [-1, 256, 18, 18]             512\n",
      "           ReLU-1006          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1007          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1008          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1009          [-1, 256, 18, 18]             512\n",
      "           ReLU-1010          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1011          [-1, 256, 18, 18]               0\n",
      "      AvgPool2d-1012         [-1, 1536, 18, 18]               0\n",
      "         Conv2d-1013          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1014          [-1, 256, 18, 18]             512\n",
      "           ReLU-1015          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1016          [-1, 256, 18, 18]               0\n",
      "     InceptionC-1017         [-1, 1536, 18, 18]               0\n",
      "         Conv2d-1018          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1019          [-1, 256, 18, 18]             512\n",
      "           ReLU-1020          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1021          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1022          [-1, 384, 18, 18]         589,824\n",
      "    BatchNorm2d-1023          [-1, 384, 18, 18]             768\n",
      "           ReLU-1024          [-1, 384, 18, 18]               0\n",
      "    BasicConv2d-1025          [-1, 384, 18, 18]               0\n",
      "         Conv2d-1026          [-1, 256, 18, 18]         294,912\n",
      "    BatchNorm2d-1027          [-1, 256, 18, 18]             512\n",
      "           ReLU-1028          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1029          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1030          [-1, 256, 18, 18]         294,912\n",
      "    BatchNorm2d-1031          [-1, 256, 18, 18]             512\n",
      "           ReLU-1032          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1033          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1034          [-1, 384, 18, 18]         589,824\n",
      "    BatchNorm2d-1035          [-1, 384, 18, 18]             768\n",
      "           ReLU-1036          [-1, 384, 18, 18]               0\n",
      "    BasicConv2d-1037          [-1, 384, 18, 18]               0\n",
      "         Conv2d-1038          [-1, 448, 18, 18]         516,096\n",
      "    BatchNorm2d-1039          [-1, 448, 18, 18]             896\n",
      "           ReLU-1040          [-1, 448, 18, 18]               0\n",
      "    BasicConv2d-1041          [-1, 448, 18, 18]               0\n",
      "         Conv2d-1042          [-1, 512, 18, 18]         688,128\n",
      "    BatchNorm2d-1043          [-1, 512, 18, 18]           1,024\n",
      "           ReLU-1044          [-1, 512, 18, 18]               0\n",
      "    BasicConv2d-1045          [-1, 512, 18, 18]               0\n",
      "         Conv2d-1046          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1047          [-1, 256, 18, 18]             512\n",
      "           ReLU-1048          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1049          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1050          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1051          [-1, 256, 18, 18]             512\n",
      "           ReLU-1052          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1053          [-1, 256, 18, 18]               0\n",
      "      AvgPool2d-1054         [-1, 1536, 18, 18]               0\n",
      "         Conv2d-1055          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1056          [-1, 256, 18, 18]             512\n",
      "           ReLU-1057          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1058          [-1, 256, 18, 18]               0\n",
      "     InceptionC-1059         [-1, 1536, 18, 18]               0\n",
      "         Conv2d-1060          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1061          [-1, 256, 18, 18]             512\n",
      "           ReLU-1062          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1063          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1064          [-1, 384, 18, 18]         589,824\n",
      "    BatchNorm2d-1065          [-1, 384, 18, 18]             768\n",
      "           ReLU-1066          [-1, 384, 18, 18]               0\n",
      "    BasicConv2d-1067          [-1, 384, 18, 18]               0\n",
      "         Conv2d-1068          [-1, 256, 18, 18]         294,912\n",
      "    BatchNorm2d-1069          [-1, 256, 18, 18]             512\n",
      "           ReLU-1070          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1071          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1072          [-1, 256, 18, 18]         294,912\n",
      "    BatchNorm2d-1073          [-1, 256, 18, 18]             512\n",
      "           ReLU-1074          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1075          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1076          [-1, 384, 18, 18]         589,824\n",
      "    BatchNorm2d-1077          [-1, 384, 18, 18]             768\n",
      "           ReLU-1078          [-1, 384, 18, 18]               0\n",
      "    BasicConv2d-1079          [-1, 384, 18, 18]               0\n",
      "         Conv2d-1080          [-1, 448, 18, 18]         516,096\n",
      "    BatchNorm2d-1081          [-1, 448, 18, 18]             896\n",
      "           ReLU-1082          [-1, 448, 18, 18]               0\n",
      "    BasicConv2d-1083          [-1, 448, 18, 18]               0\n",
      "         Conv2d-1084          [-1, 512, 18, 18]         688,128\n",
      "    BatchNorm2d-1085          [-1, 512, 18, 18]           1,024\n",
      "           ReLU-1086          [-1, 512, 18, 18]               0\n",
      "    BasicConv2d-1087          [-1, 512, 18, 18]               0\n",
      "         Conv2d-1088          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1089          [-1, 256, 18, 18]             512\n",
      "           ReLU-1090          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1091          [-1, 256, 18, 18]               0\n",
      "         Conv2d-1092          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1093          [-1, 256, 18, 18]             512\n",
      "           ReLU-1094          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1095          [-1, 256, 18, 18]               0\n",
      "      AvgPool2d-1096         [-1, 1536, 18, 18]               0\n",
      "         Conv2d-1097          [-1, 256, 18, 18]         393,216\n",
      "    BatchNorm2d-1098          [-1, 256, 18, 18]             512\n",
      "           ReLU-1099          [-1, 256, 18, 18]               0\n",
      "    BasicConv2d-1100          [-1, 256, 18, 18]               0\n",
      "     InceptionC-1101         [-1, 1536, 18, 18]               0\n",
      "AdaptiveAvgPool2d-1102           [-1, 1536, 1, 1]               0\n",
      "         Linear-1103                    [-1, 1]           1,537\n",
      "================================================================\n",
      "Total params: 80,415,270\n",
      "Trainable params: 80,415,270\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.69\n",
      "Forward/backward pass size (MB): 3764.34\n",
      "Params size (MB): 306.76\n",
      "Estimated Total Size (MB): 4075.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, IMG_SIZE, IMG_SIZE), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [35:57<00:00,  7.71s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.349484, val loss: 0.277743, accuracy: 0.90,cls_acc : {'class_1': 0.9911347031593323, 'class_2': 0.9361703395843506, 'class_3': 0.9503546953201294, 'class_4': 0.8439715504646301, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 37.0049 min\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:15<00:00,  6.91s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.262005, val loss: 0.215143, accuracy: 0.91,cls_acc : {'class_1': 0.9982268810272217, 'class_2': 0.9450355172157288, 'class_3': 0.964539110660553, 'class_4': 0.8918437361717224, 'class_5': 0.838652491569519, 'class_6': 0.8386525511741638}, time: 34.4250 min\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [29:13<00:00,  6.26s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.237439, val loss: 0.198912, accuracy: 0.92,cls_acc : {'class_1': 0.9982268810272217, 'class_2': 0.9503547549247742, 'class_3': 0.9716312885284424, 'class_4': 0.9042550325393677, 'class_5': 0.8439717292785645, 'class_6': 0.8297871351242065}, time: 30.2575 min\n",
      "Epoch 3/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:13<00:00,  6.91s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.217102, val loss: 0.200654, accuracy: 0.91,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9468086361885071, 'class_3': 0.9698582887649536, 'class_4': 0.8936168551445007, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 34.3896 min\n",
      "Epoch 4/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:13<00:00,  6.90s/batch]\n",
      "100%|██████████| 94/94 [02:08<00:00,  1.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.206239, val loss: 0.197927, accuracy: 0.92,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9539008140563965, 'class_3': 0.9751773476600647, 'class_4': 0.9007090926170349, 'class_5': 0.8528369069099426, 'class_6': 0.8244681358337402}, time: 34.3769 min\n",
      "Epoch 5/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:00<00:00,  1.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.203081, val loss: 0.197723, accuracy: 0.91,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9503546953201294, 'class_3': 0.9680852293968201, 'class_4': 0.8829786777496338, 'class_5': 0.8546099066734314, 'class_6': 0.8120567202568054}, time: 29.8197 min\n",
      "Epoch 6/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:12<00:00,  6.90s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.190163, val loss: 0.200250, accuracy: 0.92,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9485816359519958, 'class_3': 0.9787234663963318, 'class_4': 0.923758864402771, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 34.3646 min\n",
      "Epoch 7/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:13<00:00,  6.91s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.38s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.191329, val loss: 0.181754, accuracy: 0.92,cls_acc : {'class_1': 0.9982269406318665, 'class_2': 0.9468086361885071, 'class_3': 0.9751774072647095, 'class_4': 0.9131205677986145, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 34.3919 min\n",
      "Epoch 8/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:00<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.181093, val loss: 0.231046, accuracy: 0.91,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9414895176887512, 'class_3': 0.9734042882919312, 'class_4': 0.8705673813819885, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 29.8117 min\n",
      "Epoch 9/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.178381, val loss: 0.192037, accuracy: 0.92,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9521278738975525, 'class_3': 0.9716312885284424, 'class_4': 0.9343969821929932, 'class_5': 0.8209220170974731, 'class_6': 0.8528369069099426}, time: 29.8113 min\n",
      "Epoch 10/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:00<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.171551, val loss: 0.301250, accuracy: 0.89,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.804964542388916, 'class_3': 0.9627659916877747, 'class_4': 0.9042552709579468, 'class_5': 0.8368796110153198, 'class_6': 0.8404256701469421}, time: 29.8198 min\n",
      "Epoch 11/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:46<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.171522, val loss: 0.243418, accuracy: 0.91,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9095746278762817, 'class_3': 0.9574468731880188, 'class_4': 0.9078013300895691, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 29.8130 min\n",
      "Epoch 12/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:00<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.166558, val loss: 0.234783, accuracy: 0.91,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.8936170935630798, 'class_3': 0.9698581695556641, 'class_4': 0.9131203293800354, 'class_5': 0.8351064920425415, 'class_6': 0.8421986103057861}, time: 29.8109 min\n",
      "Epoch 13/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model weights!\n",
      "train loss: 0.167054, val loss: 0.220676, accuracy: 0.92,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9539007544517517, 'class_3': 0.966312050819397, 'class_4': 0.9237588047981262, 'class_5': 0.831560492515564, 'class_6': 0.8351064920425415}, time: 29.8169 min\n",
      "Epoch 14/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [28:47<00:00,  6.17s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.153743, val loss: 0.155126, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9592200517654419, 'class_3': 0.98758864402771, 'class_4': 0.9326242208480835, 'class_5': 0.8546099066734314, 'class_6': 0.8191490769386292}, time: 29.8208 min\n",
      "Epoch 15/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:11<00:00,  6.90s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.134922, val loss: 0.152303, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9627661108970642, 'class_3': 0.98758864402771, 'class_4': 0.9361702799797058, 'class_5': 0.8439717292785645, 'class_6': 0.8297873735427856}, time: 34.3509 min\n",
      "Epoch 16/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:40<00:00,  6.57s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.121921, val loss: 0.158071, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9609931707382202, 'class_3': 0.98758864402771, 'class_4': 0.9379432797431946, 'class_5': 0.8421986699104309, 'class_6': 0.831560492515564}, time: 31.7077 min\n",
      "Epoch 17/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:41<00:00,  6.58s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.111626, val loss: 0.159317, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9680852293968201, 'class_3': 0.9840425848960876, 'class_4': 0.9397163987159729, 'class_5': 0.8404256105422974, 'class_6': 0.836879551410675}, time: 31.7090 min\n",
      "Epoch 18/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:40<00:00,  6.57s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.106341, val loss: 0.165417, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9609930515289307, 'class_3': 0.9840425848960876, 'class_4': 0.9361701011657715, 'class_5': 0.8404256105422974, 'class_6': 0.836879551410675}, time: 31.6998 min\n",
      "Epoch 19/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:41<00:00,  6.58s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.102404, val loss: 0.176862, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9698582887649536, 'class_3': 0.9804965853691101, 'class_4': 0.9414891600608826, 'class_5': 0.8510637879371643, 'class_6': 0.8191490173339844}, time: 31.7092 min\n",
      "Epoch 20/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:41<00:00,  6.58s/batch]\n",
      "100%|██████████| 94/94 [01:00<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.097780, val loss: 0.184322, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9592200517654419, 'class_3': 0.9822695851325989, 'class_4': 0.9432623386383057, 'class_5': 0.8351064324378967, 'class_6': 0.8386525511741638}, time: 31.7181 min\n",
      "Epoch 21/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:42<00:00,  6.58s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model weights!\n",
      "train loss: 0.093715, val loss: 0.176511, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9627661108970642, 'class_3': 0.9822695851325989, 'class_4': 0.9414893388748169, 'class_5': 0.8421985507011414, 'class_6': 0.8280143737792969}, time: 31.7393 min\n",
      "Epoch 22/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [30:43<00:00,  6.58s/batch]\n",
      "100%|██████████| 94/94 [01:01<00:00,  1.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.119901, val loss: 0.150029, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9592199921607971, 'class_3': 0.98758864402771, 'class_4': 0.9414893388748169, 'class_5': 0.8297869563102722, 'class_6': 0.836879312992096}, time: 31.7425 min\n",
      "Epoch 23/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:13<00:00,  6.90s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.38s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.115937, val loss: 0.150345, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9556737542152405, 'class_3': 0.98758864402771, 'class_4': 0.9432623386383057, 'class_5': 0.8333331942558289, 'class_6': 0.8333333134651184}, time: 34.3811 min\n",
      "Epoch 24/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:13<00:00,  6.91s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.38s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.113423, val loss: 0.150665, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9592198729515076, 'class_3': 0.98758864402771, 'class_4': 0.9450353980064392, 'class_5': 0.8333331942558289, 'class_6': 0.8333332538604736}, time: 34.3877 min\n",
      "Epoch 25/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [32:14<00:00,  6.91s/batch]\n",
      "100%|██████████| 94/94 [02:09<00:00,  1.38s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.111042, val loss: 0.151087, accuracy: 0.93,cls_acc : {'class_1': 0.9999999403953552, 'class_2': 0.9592198729515076, 'class_3': 0.98758864402771, 'class_4': 0.9450353980064392, 'class_5': 0.8351061940193176, 'class_6': 0.8315602540969849}, time: 34.4038 min\n",
      "Epoch 26/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 127/280 [14:40<17:40,  6.93s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SHkim\\xeception\\TH_googlenetv4.ipynb 셀 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m traind_model, loss_hist, metric_hist, metric_cls_hist \u001b[39m=\u001b[39m train_val(model, device, params_train)\n",
      "\u001b[1;32md:\\SHkim\\xeception\\TH_googlenetv4.ipynb 셀 15\u001b[0m in \u001b[0;36mtrain_val\u001b[1;34m(model, device, params)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m train_loss, train_metric,train_cls_metric \u001b[39m=\u001b[39m loss_epoch_multi_output(model, device, loss_func, train_dl, sanity_check, opt)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m loss_history[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m metric_history[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_metric\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32md:\\SHkim\\xeception\\TH_googlenetv4.ipynb 셀 15\u001b[0m in \u001b[0;36mloss_epoch_multi_output\u001b[1;34m(model, device, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m yb \u001b[39m=\u001b[39m yb\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m output \u001b[39m=\u001b[39m model(xb)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m loss_b, metric_b, class_metric_b \u001b[39m=\u001b[39m loss_batch_multi_output(loss_func, output, yb, device, opt)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_b\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39mif\u001b[39;00m metric_b \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32md:\\SHkim\\xeception\\TH_googlenetv4.ipynb 셀 15\u001b[0m in \u001b[0;36mloss_batch_multi_output\u001b[1;34m(loss_func, output, target, device, opt)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     loss_b\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     opt\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/SHkim/xeception/TH_googlenetv4.ipynb#X15sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss_b\u001b[39m.\u001b[39mitem(), metric_b, class_metric_b\n",
      "File \u001b[1;32md:\\SHkim\\contactlensCC_wxpython\\wx_venv\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\SHkim\\contactlensCC_wxpython\\wx_venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\SHkim\\contactlensCC_wxpython\\wx_venv\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[0;32m    139\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 141\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[0;32m    142\u001b[0m            grads,\n\u001b[0;32m    143\u001b[0m            exp_avgs,\n\u001b[0;32m    144\u001b[0m            exp_avg_sqs,\n\u001b[0;32m    145\u001b[0m            max_exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m            state_steps,\n\u001b[0;32m    147\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    148\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    149\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    150\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    151\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m            maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\SHkim\\contactlensCC_wxpython\\wx_venv\\lib\\site-packages\\torch\\optim\\_functional.py:97\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m     94\u001b[0m     grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39madd(param, alpha\u001b[39m=\u001b[39mweight_decay)\n\u001b[0;32m     96\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m     98\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[0;32m    100\u001b[0m     \u001b[39m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "traind_model, loss_hist, metric_hist, metric_cls_hist = train_val(model, device, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wx_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f887c8c8d6fdd4a511c73e402e0744011268d8986dd2629aa484b62be6e70f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
