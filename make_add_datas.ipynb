{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def concat_origin_img(white_img, black_img):\n",
    "    white_img = 255 - white_img\n",
    "\n",
    "    img_sum = np.zeros((white_img.shape[0],white_img.shape[1],3), dtype=np.uint8)\n",
    "    img_sum[:,:,0] = white_img\n",
    "    img_sum[:,:,1] = black_img\n",
    "    \n",
    "    return img_sum\n",
    "\n",
    "def find_circles(img_origin):\n",
    "    try:\n",
    "        img = img_origin[:,:,1]\n",
    "        #가우시안필터\n",
    "        gaus = cv2.GaussianBlur(img, (5, 5), 7)\n",
    "\n",
    "        #적응형이진화\n",
    "        thres = cv2.adaptiveThreshold(gaus, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 5)\n",
    "        thres = cv2.GaussianBlur(thres, (5, 5), 7)\n",
    "        \n",
    "        circles = cv2.HoughCircles(thres, cv2.HOUGH_GRADIENT, 1, 1200, param1 = 250, param2 = 60, minRadius = 720, maxRadius = 800)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False, img    \n",
    "    try:\n",
    "        if len(circles) > 0:\n",
    "            for i in circles[0]:\n",
    "                cx = i[0]\n",
    "                cy = i[1]\n",
    "                radius = i[2]\n",
    "    except:\n",
    "        print('fail to find circle!')\n",
    "        cx = img_origin.shape[1]//2\n",
    "        cy = img_origin.shape[0]//2\n",
    "        radius = 740\n",
    "\n",
    "    #이미지 ROI 추출\n",
    "    margin = 40 # 여백\n",
    "    s_radius = radius\n",
    "    x_min = max(0, int(cx - s_radius - margin))  # Ensure x_min is not less than 0\n",
    "    y_min = max(0, int(cy - s_radius - margin))  # Ensure y_min is not less than 0\n",
    "    x_max = min(img_origin.shape[1], int(cx + s_radius + margin))  # Ensure x_max does not exceed image width\n",
    "    y_max = min(img_origin.shape[0], int(cy + s_radius + margin))  # Ensure y_max does not exceed image height\n",
    "\n",
    "    img_roi = img_origin[y_min:y_max,x_min:x_max]\n",
    "    if img_roi.size == 0: # If the ROI is empty, provide some error message or handle this case\n",
    "        return False, img\n",
    "    else:\n",
    "        img_roi = cv2.resize(img_roi,(1500,1500))\n",
    "\n",
    "    return True, img_roi\n",
    "\n",
    "def copy_from_nas(port_number, set_date, file_list):\n",
    "    # 나스에서 조회용\n",
    "    nas_base = r'\\\\contactlensEB/Home/contactlensEB_backup/'\n",
    "    if port_number == 1:\n",
    "        nas_path = nas_base + '/images_copy/original_images'\n",
    "    elif port_number == 2:\n",
    "        nas_path = nas_base + '/images_copy2/original_images'\n",
    "    elif port_number == 3:\n",
    "        nas_path = nas_base + '/images_copy3/original_images'\n",
    "\n",
    "    #몇호기인지\n",
    "    set_machine = nas_path\n",
    "    \n",
    "    print(set_date)\n",
    "    \n",
    "    #전처리완료된 이미지 저장용 폴더\n",
    "    save_folder = r'E:\\claassifier\\images_sec_renew\\additional_target2'\n",
    "    file_list = [x[0] for x in file_list]\n",
    "    file_list = [\"_\".join(x.split(\"_\")[1:]) for x in file_list]\n",
    "\n",
    "    for file in tqdm.tqdm(file_list):\n",
    "        file_path = set_machine + '/'+ set_date + '/' + file\n",
    "        white_path = file_path.replace('1.jpg','0.jpg')\n",
    "        b_img = cv2.imread(file_path,0)\n",
    "        w_img = cv2.imread(white_path,0)\n",
    "        \n",
    "        concated_img = concat_origin_img(white_img=w_img, black_img=b_img)\n",
    "        is_success, pic = find_circles(concated_img)\n",
    "\n",
    "        cv2.imwrite(save_folder+ '/' + file, pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 작업분류 엑셀 E:\\project\\렌즈\\작업일지\n",
    "csv_path = 'E:\\project\\렌즈\\작업일지\\work.csv'\n",
    "df = pd.read_csv(csv_path, encoding='cp949')\n",
    "\n",
    "q_df = df[['모델명', '호수', '날짜', '시작시간', '완료시간']]\n",
    "q_df\n",
    "\n",
    "conn = pymysql.connect(host='175.212.10.234', user='cgacAdmin', password='gac81-344', db='contactlensEB', charset='utf8',port=3307)\n",
    "conn2 = pymysql.connect(host='175.212.10.234', user='cgacAdmin', password='gac81-344', db='contactlensEB', charset='utf8',port=3308)\n",
    "cursor = conn.cursor()\n",
    "cursor2 = conn2.cursor()\n",
    "\n",
    "for i,row in enumerate (q_df.itertuples()):\n",
    "    date = row.날짜\n",
    "    date_obj = datetime.strptime(date, '%m월%d일')\n",
    "    month, day = date_obj.month, date_obj.day\n",
    "    start_time = row.시작시간\n",
    "    time_obj = datetime.strptime(start_time, '%H:%M')\n",
    "    hour, minute = time_obj.hour, time_obj.minute\n",
    "    start_date = datetime(year=2023, month=month, day=day, hour=hour, minute=minute)\n",
    "\n",
    "    end_time =row.완료시간\n",
    "    time_obj = datetime.strptime(end_time,'%H:%M')\n",
    "    hour, minute = time_obj.hour, time_obj.minute\n",
    "    end_date = datetime(year=2023, month=month,day=day,hour=hour, minute=minute)\n",
    "    #시간내총수량 = base_query\n",
    "\n",
    "    base_query = f'''\n",
    "                SELECT COUNT(*) FROM result\n",
    "                WHERE workDate BETWEEN '{str(start_date)}' and '{str(end_date)}'\n",
    "                '''\n",
    "    if row.호수 == 2:\n",
    "        cursor.execute(base_query)\n",
    "        b_res = cursor.fetchall()\n",
    "    else:\n",
    "        cursor2.execute(base_query)\n",
    "        b_res = cursor2.fetchall()\n",
    "    \n",
    "    total_count = int(b_res[0][0])\n",
    "    #2차분류_불량\n",
    "    query = base_query + f'''\n",
    "            AND (defectstep='1D' or defectstep = '2D')\n",
    "            '''\n",
    "    if row.호수 == 2:\n",
    "        cursor.execute(query)\n",
    "        res = cursor.fetchall()\n",
    "    else:\n",
    "        cursor2.execute(query)\n",
    "        res = cursor2.fetchall()\n",
    "    \n",
    "    defect_sec_count = int(res[0][0])\n",
    "\n",
    "    sec_f_list_query = f'''\n",
    "                    SELECT filename FROM result\n",
    "                    WHERE workDate BETWEEN '{str(start_date)}' and '{str(end_date)}'\n",
    "                    AND (defectstep='1D' or defectstep = '2D')\n",
    "                    '''\n",
    "    if row.호수 == 2:\n",
    "        cursor.execute(sec_f_list_query)\n",
    "        fres = cursor.fetchall()\n",
    "    else:\n",
    "        cursor2.execute(sec_f_list_query)\n",
    "        fres = cursor2.fetchall()\n",
    "\n",
    "    copy_from_nas(port_number=row.호수, \n",
    "                  set_date=str(start_date).replace(\"-\",\"\")[:8],\n",
    "                  file_list=list(fres))\n",
    "\n",
    "    q_df.loc[[i],['DB총수량']]=total_count\n",
    "    q_df.loc[[i],['2차분류_불량']]=defect_sec_count\n",
    "    q_df.loc[[i],['2차분류불량율']]=round(defect_sec_count/total_count, 2)\n",
    "\n",
    "conn.close()\n",
    "conn2.close()\n",
    "\n",
    "# q_df.to_csv('temp.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델명</th>\n",
       "      <th>호수</th>\n",
       "      <th>날짜</th>\n",
       "      <th>시작시간</th>\n",
       "      <th>완료시간</th>\n",
       "      <th>DB총수량</th>\n",
       "      <th>2차분류_불량</th>\n",
       "      <th>2차분류불량율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tint</td>\n",
       "      <td>2</td>\n",
       "      <td>7월27일</td>\n",
       "      <td>9:51</td>\n",
       "      <td>17:39</td>\n",
       "      <td>9895.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA6247</td>\n",
       "      <td>2</td>\n",
       "      <td>8월11일</td>\n",
       "      <td>13:29</td>\n",
       "      <td>14:13</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA4276</td>\n",
       "      <td>2</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>9:28</td>\n",
       "      <td>9:52</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA4076</td>\n",
       "      <td>2</td>\n",
       "      <td>8월11일</td>\n",
       "      <td>10:38</td>\n",
       "      <td>11:47</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA4076</td>\n",
       "      <td>2</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>9:53</td>\n",
       "      <td>10:20</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      모델명  호수     날짜   시작시간   완료시간   DB총수량  2차분류_불량  2차분류불량율\n",
       "0    tint   2  7월27일   9:51  17:39  9895.0      0.0     0.00\n",
       "1  DA6247   2  8월11일  13:29  14:13  1666.0    214.0     0.13\n",
       "2  DA4276   2  8월17일   9:28   9:52  1180.0     67.0     0.06\n",
       "3  DA4076   2  8월11일  10:38  11:47  1697.0    406.0     0.24\n",
       "4  DA4076   2  8월17일   9:53  10:20  1299.0    121.0     0.09"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델명</th>\n",
       "      <th>호수</th>\n",
       "      <th>날짜</th>\n",
       "      <th>시작시간</th>\n",
       "      <th>완료시간</th>\n",
       "      <th>DB총수량</th>\n",
       "      <th>2차분류_불량</th>\n",
       "      <th>2차분류불량율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tint</td>\n",
       "      <td>2</td>\n",
       "      <td>7월27일</td>\n",
       "      <td>9:51</td>\n",
       "      <td>17:39</td>\n",
       "      <td>9895.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA6247</td>\n",
       "      <td>2</td>\n",
       "      <td>8월11일</td>\n",
       "      <td>13:29</td>\n",
       "      <td>14:13</td>\n",
       "      <td>1666.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA4276</td>\n",
       "      <td>2</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>9:28</td>\n",
       "      <td>9:52</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA4076</td>\n",
       "      <td>2</td>\n",
       "      <td>8월11일</td>\n",
       "      <td>10:38</td>\n",
       "      <td>11:47</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA4076</td>\n",
       "      <td>2</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>9:53</td>\n",
       "      <td>10:20</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60TT</td>\n",
       "      <td>3</td>\n",
       "      <td>8월25일</td>\n",
       "      <td>11:50</td>\n",
       "      <td>13:50</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>55TT</td>\n",
       "      <td>3</td>\n",
       "      <td>8월25일</td>\n",
       "      <td>13:50</td>\n",
       "      <td>14:24</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>55TT</td>\n",
       "      <td>3</td>\n",
       "      <td>8월25일</td>\n",
       "      <td>14:25</td>\n",
       "      <td>16:45</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DA3352</td>\n",
       "      <td>3</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>13:37</td>\n",
       "      <td>14:25</td>\n",
       "      <td>280.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DA2942</td>\n",
       "      <td>3</td>\n",
       "      <td>8월17일</td>\n",
       "      <td>10:53</td>\n",
       "      <td>11:32</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       모델명  호수     날짜   시작시간   완료시간   DB총수량  2차분류_불량  2차분류불량율\n",
       "0     tint   2  7월27일   9:51  17:39  9895.0      0.0     0.00\n",
       "1   DA6247   2  8월11일  13:29  14:13  1666.0    214.0     0.13\n",
       "2   DA4276   2  8월17일   9:28   9:52  1180.0     67.0     0.06\n",
       "3   DA4076   2  8월11일  10:38  11:47  1697.0    406.0     0.24\n",
       "4   DA4076   2  8월17일   9:53  10:20  1299.0    121.0     0.09\n",
       "..     ...  ..    ...    ...    ...     ...      ...      ...\n",
       "94    60TT   3  8월25일  11:50  13:50  2200.0     23.0     0.01\n",
       "95    55TT   3  8월25일  13:50  14:24  1208.0     27.0     0.02\n",
       "96    55TT   3  8월25일  14:25  16:45  2575.0     38.0     0.01\n",
       "97  DA3352   3  8월17일  13:37  14:25   280.0      4.0     0.01\n",
       "98  DA2942   3  8월17일  10:53  11:32  1248.0     13.0     0.01\n",
       "\n",
       "[99 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "양품데이터 :  3800\n",
      "불량데이터 :  1324\n",
      "Empty DataFrame\n",
      "Columns: [id, good, defect, no_lens]\n",
      "Index: []\n",
      "중복체크된 행 :  0\n",
      "중복체크된 행 :  0\n",
      "중복체크된 행 :  0\n",
      "중복체크된 행 :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3800/3800 [03:54<00:00, 16.22it/s]\n",
      "100%|██████████| 1324/1324 [03:03<00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id good defect no_lens\n",
      "0          20230718182225_0_R_1.jpg    1      0       0\n",
      "1        lr20230718182225_0_R_1.jpg    1      0       0\n",
      "2          20230718182225_1_R_1.jpg    1      0       0\n",
      "3        lr20230718182225_1_R_1.jpg    1      0       0\n",
      "4          20230718182225_3_R_1.jpg    1      0       0\n",
      "...                             ...  ...    ...     ...\n",
      "12891  lrud20230825164802_4_R_1.jpg    0      1       0\n",
      "12892      20230825165854_4_R_1.jpg    0      1       0\n",
      "12893    lr20230825165854_4_R_1.jpg    0      1       0\n",
      "12894    ud20230825165854_4_R_1.jpg    0      1       0\n",
      "12895  lrud20230825165854_4_R_1.jpg    0      1       0\n",
      "\n",
      "[12896 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "add1_path = r'E:\\claassifier\\images_sec_renew\\additional_target'\n",
    "add2_path = r'E:\\claassifier\\images_sec_renew\\additional_target2'\n",
    "save_path = r'E:\\claassifier\\images_sec_renew\\final'\n",
    "\n",
    "add1_csv = pd.read_csv(add1_path + '/result.csv')\n",
    "add2_csv = pd.read_csv(add2_path + '/result.csv')\n",
    "\n",
    "add1_csv = add1_csv[add1_csv['good'] == 1]\n",
    "add2_csv = add2_csv[add2_csv['defect'] == 1]\n",
    "final_csv = pd.DataFrame(columns=add1_csv.columns)\n",
    "final_csv = final_csv[['id', 'good', 'defect', 'no_lens']]\n",
    "\n",
    "print('양품데이터 : ', len(add1_csv))\n",
    "print('불량데이터 : ', len(add2_csv))\n",
    "print(final_csv)\n",
    "\n",
    "#양품 과 불량이 같이 체크되어있는것 확인\n",
    "print('중복체크된 행 : ', len(add1_csv.loc[(add1_csv['good'] == 1) & (add1_csv['defect'] == 1)]))\n",
    "print('중복체크된 행 : ', len(add1_csv.loc[(add1_csv['good'] == 1) & (add1_csv['no_lens'] == 1)]))\n",
    "print('중복체크된 행 : ', len(add2_csv.loc[(add2_csv['good'] == 1) & (add2_csv['defect'] == 1)]))\n",
    "print('중복체크된 행 : ', len(add2_csv.loc[(add2_csv['good'] == 1) & (add2_csv['no_lens'] == 1)]))\n",
    "\n",
    "good_bar = tqdm.tqdm(add1_csv.itertuples(), total=len(add1_csv))\n",
    "#good은 좌우플립만 수행\n",
    "for rows in good_bar:\n",
    "    if os.path.isfile(add1_path +'/'+ rows.id) and rows.good == 1:\n",
    "        #오리지널 그대로 복사\n",
    "        shutil.copy(add1_path + '/' + rows.id, save_path +'/'+ rows.id)\n",
    "        new_row = pd.Series([rows.id, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "\n",
    "        #양품데이터는 플립1회 수행(x2)\n",
    "        img = cv2.imread(add1_path +'/'+ rows.id)\n",
    "        img_flip_lr = cv2.flip(img, 1)\n",
    "        lr_filename = 'lr'+rows.id\n",
    "        cv2.imwrite(save_path + '/' + lr_filename , img_flip_lr)\n",
    "        new_row = pd.Series([lr_filename, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "        \n",
    "defect_bar = tqdm.tqdm(add2_csv.itertuples(), total=len(add2_csv))\n",
    "for rows in defect_bar:\n",
    "    if os.path.isfile(add2_path +'/'+ rows.id) and rows.defect == 1:\n",
    "        #오리지널 그대로 복사\n",
    "        shutil.copy(add2_path + '/' + rows.id, save_path +'/'+ rows.id)\n",
    "        new_row = pd.Series([rows.id, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "\n",
    "        #불량데이터는 플립2회 수행(x4)\n",
    "        img = cv2.imread(add2_path +'/'+ rows.id)\n",
    "        img_flip_lr = cv2.flip(img, 1)\n",
    "        lr_filename = 'lr'+rows.id\n",
    "        cv2.imwrite(save_path + '/' + lr_filename , img_flip_lr)\n",
    "        new_row = pd.Series([lr_filename, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "\n",
    "        img_flip_ud = cv2.flip(img, 0)\n",
    "        ud_filename = 'ud'+rows.id\n",
    "        cv2.imwrite(save_path + '/' + ud_filename , img_flip_ud)\n",
    "        new_row = pd.Series([ud_filename, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "\n",
    "        img_flip_lrud = cv2.flip(img_flip_ud, 1)\n",
    "        lrud_filename = 'lrud'+rows.id\n",
    "        cv2.imwrite(save_path + '/' + lrud_filename , img_flip_lrud)\n",
    "        new_row = pd.Series([lrud_filename, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        final_csv = final_csv.append(new_row, ignore_index=True)\n",
    "\n",
    "print(final_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv.to_csv(\"dataset_sec_add.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_csv['sum'] = final_csv[['good', 'defect', 'no_lens']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12896\n",
      "119091\n",
      "131987\n",
      "Index(['id', 'good', 'defect', 'no_lens'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "add_dataset = pd.read_csv('dataset_sec_add.csv')\n",
    "print(len(add_dataset))\n",
    "original_dataset = pd.read_csv('dataset_sec.csv')\n",
    "print(len(original_dataset))\n",
    "con_df = pd.concat([add_dataset, original_dataset], ignore_index=True)\n",
    "\n",
    "print(len(con_df))\n",
    "print(con_df.columns)\n",
    "\n",
    "con_df.to_csv('dataset_sec_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총이미지개수 :  131987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id         20230718182225_0_R_1.jpglr20230718182225_0_R_1...\n",
       "good                                                   67600\n",
       "defect                                                 61682\n",
       "no_lens                                                 2705\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = pd.read_csv('dataset_sec_full.csv')\n",
    "print(\"총이미지개수 : \",len(full_dataset))\n",
    "full_dataset.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12896\n",
      "13139\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "add_dataset = pd.read_csv('dataset_sec_add.csv')\n",
    "print(len(add_dataset))\n",
    "asdfasf_df = pd.read_excel(r'E:\\claassifier'+'/실금.xlsx')\n",
    "addsave_path = r'E:\\claassifier\\images_sec_renew\\20231019_add'\n",
    "\n",
    "for rows in asdfasf_df.itertuples():\n",
    "    d_name = rows._1[:8]\n",
    "    d_path = r\"\\\\113.198.138.232\\Home\\contactlensEB_backup\\images_copy3\\modified_images\" + '/' + d_name\n",
    "    \n",
    "    for f in os.listdir(d_path):\n",
    "        count = 0\n",
    "        if fnmatch.fnmatch(f, '*'+rows._1+ '_1.jpg'):\n",
    "            f_name = f\n",
    "            if count != 0:\n",
    "                print('something wrong')\n",
    "                break\n",
    "            count += 1\n",
    "        \n",
    "    # '/'+ rows._1 + '_1.jpg'\n",
    "    shutil.copy(d_path+'/'+f_name, addsave_path+'/'+f_name)\n",
    "    new_row = pd.Series([f_name,0, 1, 0], index=add_dataset.columns)\n",
    "    add_dataset = add_dataset.append(new_row, ignore_index=True)\n",
    "    \n",
    "print(len(add_dataset))\n",
    "        # new_row = pd.Series([lr_filename, rows.good, rows.defect, rows.no_lens], index=final_csv.columns)\n",
    "        # final_csv = final_csv.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dataset\n",
    "add_dataset.to_csv(\"dataset_sec_add2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13139\n",
      "119091\n",
      "132230\n",
      "Index(['id', 'good', 'defect', 'no_lens'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "add_dataset = pd.read_csv('dataset_sec_add2.csv')\n",
    "print(len(add_dataset))\n",
    "original_dataset = pd.read_csv('dataset_sec.csv')\n",
    "print(len(original_dataset))\n",
    "con_df = pd.concat([add_dataset, original_dataset], ignore_index=True)\n",
    "\n",
    "print(len(con_df))\n",
    "print(con_df.columns)\n",
    "\n",
    "con_df.to_csv('dataset_sec_full2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wx_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f887c8c8d6fdd4a511c73e402e0744011268d8986dd2629aa484b62be6e70f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
